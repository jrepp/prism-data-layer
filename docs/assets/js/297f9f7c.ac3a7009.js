"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[3640],{3265:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"RFC-005-clickhouse-integration","title":"RFC-005: ClickHouse Integration for Time Series Analytics","description":"Abstract","source":"@site/../docs-cms/rfcs/RFC-005-clickhouse-integration.md","sourceDirName":".","slug":"/RFC-005-clickhouse-integration","permalink":"/prism-data-layer/rfc/RFC-005-clickhouse-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/rfcs/RFC-005-clickhouse-integration.md","tags":[],"version":"current","frontMatter":{"title":"RFC-005: ClickHouse Integration for Time Series Analytics","status":"Proposed","author":"Core Team","created":"2025-10-08T00:00:00.000Z","updated":"2025-10-08T00:00:00.000Z","related":"RFC-001, RFC-002, RFC-004"},"sidebar":"rfcSidebar","previous":{"title":"RFC-004: Redis Integration for Cache, PubSub, and Vector Search","permalink":"/prism-data-layer/rfc/RFC-004-redis-integration"},"next":{"title":"Request for Comments (RFCs)","permalink":"/prism-data-layer/rfc/"}}');var r=s(4848),t=s(8453);const a={title:"RFC-005: ClickHouse Integration for Time Series Analytics",status:"Proposed",author:"Core Team",created:new Date("2025-10-08T00:00:00.000Z"),updated:new Date("2025-10-08T00:00:00.000Z"),related:"RFC-001, RFC-002, RFC-004"},l=void 0,c={},o=[{value:"Abstract",id:"abstract",level:2},{value:"1. Introduction",id:"1-introduction",level:2},{value:"1.1 Purpose",id:"11-purpose",level:3},{value:"1.2 Goals",id:"12-goals",level:3},{value:"1.3 Non-Goals",id:"13-non-goals",level:3},{value:"2. Architecture Overview",id:"2-architecture-overview",level:2},{value:"2.1 Time Series Pipeline",id:"21-time-series-pipeline",level:3},{value:"2.2 Data Flow",id:"22-data-flow",level:3},{value:"3. Time Series Access Pattern",id:"3-time-series-access-pattern",level:2},{value:"3.1 Use Cases",id:"31-use-cases",level:3},{value:"3.2 Interface",id:"32-interface",level:3},{value:"3.3 Schema Design",id:"33-schema-design",level:3},{value:"3.4 Materialized Views for Pre-aggregations",id:"34-materialized-views-for-pre-aggregations",level:3},{value:"4. Query Patterns",id:"4-query-patterns",level:2},{value:"4.1 Time Range Queries",id:"41-time-range-queries",level:3},{value:"4.2 Aggregations",id:"42-aggregations",level:3},{value:"4.3 Top-N Queries",id:"43-top-n-queries",level:3},{value:"4.4 Time Series Bucketing",id:"44-time-series-bucketing",level:3},{value:"5. Performance Optimizations",id:"5-performance-optimizations",level:2},{value:"5.1 Partitioning Strategy",id:"51-partitioning-strategy",level:3},{value:"5.2 Compression",id:"52-compression",level:3},{value:"5.3 Async Inserts",id:"53-async-inserts",level:3},{value:"6. Configuration",id:"6-configuration",level:2},{value:"6.1 Client Configuration",id:"61-client-configuration",level:3},{value:"6.2 Server Configuration",id:"62-server-configuration",level:3},{value:"7. Operational Considerations",id:"7-operational-considerations",level:2},{value:"7.1 Capacity Planning",id:"71-capacity-planning",level:3},{value:"7.2 Monitoring",id:"72-monitoring",level:3},{value:"7.3 Data Lifecycle",id:"73-data-lifecycle",level:3},{value:"8. Migration Path",id:"8-migration-path",level:2},{value:"8.1 Phase 1: Single Node (Week 1-2)",id:"81-phase-1-single-node-week-1-2",level:3},{value:"8.2 Phase 2: Cluster Setup (Week 3-4)",id:"82-phase-2-cluster-setup-week-3-4",level:3},{value:"8.3 Phase 3: Materialized Views (Week 5-6)",id:"83-phase-3-materialized-views-week-5-6",level:3},{value:"8.4 Phase 4: Production (Week 7-8)",id:"84-phase-4-production-week-7-8",level:3},{value:"9. Use Case Recommendations",id:"9-use-case-recommendations",level:2},{value:"9.1 When to Use ClickHouse",id:"91-when-to-use-clickhouse",level:3},{value:"9.2 ClickHouse vs Alternatives",id:"92-clickhouse-vs-alternatives",level:3},{value:"10. References",id:"10-references",level:2},{value:"11. Revision History",id:"11-revision-history",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"abstract",children:"Abstract"}),"\n",(0,r.jsx)(n.p,{children:"This RFC specifies the integration of ClickHouse into Prism as a high-performance OLAP database optimized for time series analytics. ClickHouse provides columnar storage, real-time ingestion, and lightning-fast analytical queries, making it ideal for metrics, logs, events, and observability data."}),"\n",(0,r.jsx)(n.h2,{id:"1-introduction",children:"1. Introduction"}),"\n",(0,r.jsx)(n.h3,{id:"11-purpose",children:"1.1 Purpose"}),"\n",(0,r.jsx)(n.p,{children:"ClickHouse integration addresses analytical time series workloads:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Metrics Storage"}),": Application metrics, system metrics, business KPIs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Event Logging"}),": Application logs, audit logs, user activity events"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Observability"}),": Traces, spans, and distributed system telemetry"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analytics"}),": Real-time aggregations, rollups, and dashboards"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"12-goals",children:"1.2 Goals"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ingestion Rate"}),": 1M+ events/sec sustained write throughput"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Query Performance"}),": Sub-second aggregations over billions of rows"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compression"}),": 10-100x compression ratio for time series data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Retention"}),": Automatic data lifecycle with TTL and tiered storage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scalability"}),": Horizontal scaling with ReplicatedMergeTree"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"13-non-goals",children:"1.3 Non-Goals"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Not for OLTP"}),": Use Postgres for transactional workloads"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Not for full-text search"}),": Use Elasticsearch or TypeSense"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Not for updates"}),": ClickHouse is append-only (use Postgres for mutable data)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Not for joins"}),": Optimized for denormalized data, avoid complex joins"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2-architecture-overview",children:"2. Architecture Overview"}),"\n",(0,r.jsx)(n.h3,{id:"21-time-series-pipeline",children:"2.1 Time Series Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-mermaid",children:'graph TB\n    subgraph "Ingestion"\n        Client[Client Applications]\n        Proxy[Prism Proxy]\n        Buffer[Async Buffer<br/>Batching]\n    end\n\n    subgraph "ClickHouse Cluster"\n        Shard1[Shard 1<br/>ReplicatedMergeTree]\n        Shard2[Shard 2<br/>ReplicatedMergeTree]\n        Replica1[Replica 1]\n        Replica2[Replica 2]\n    end\n\n    subgraph "Query"\n        Query[Query Service]\n        Materialized[Materialized Views<br/>Pre-aggregations]\n    end\n\n    Client --\x3e|Write Batch| Proxy\n    Proxy --\x3e Buffer\n    Buffer --\x3e|Distributed Write| Shard1\n    Buffer --\x3e|Distributed Write| Shard2\n\n    Shard1 -.->|Replication| Replica1\n    Shard2 -.->|Replication| Replica2\n\n    Client --\x3e|Analytical Query| Proxy\n    Proxy --\x3e Query\n    Query --\x3e Materialized\n    Materialized --\x3e Shard1\n    Materialized --\x3e Shard2\n'})}),"\n",(0,r.jsx)(n.h3,{id:"22-data-flow",children:"2.2 Data Flow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-mermaid",children:"sequenceDiagram\n    participant App as Application\n    participant Proxy as Prism Proxy\n    participant Buffer as Async Buffer\n    participant CH as ClickHouse\n\n    App->>Proxy: AppendEvents([event1, event2, ...])\n    Proxy->>Buffer: Queue events\n    Proxy--\x3e>App: AppendResponse{queued: 1000}\n\n    Note over Buffer: Batch accumulation<br/>(1000 events or 1s)\n\n    Buffer->>CH: INSERT INTO events VALUES (...)\n    CH--\x3e>Buffer: OK (1000 rows)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"3-time-series-access-pattern",children:"3. Time Series Access Pattern"}),"\n",(0,r.jsx)(n.h3,{id:"31-use-cases",children:"3.1 Use Cases"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Metrics"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Application performance metrics (request rate, latency, errors)"}),"\n",(0,r.jsx)(n.li,{children:"Infrastructure metrics (CPU, memory, disk, network)"}),"\n",(0,r.jsx)(n.li,{children:"Business metrics (revenue, conversions, user activity)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Logs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Application logs (errors, warnings, debug)"}),"\n",(0,r.jsx)(n.li,{children:"Access logs (HTTP requests, API calls)"}),"\n",(0,r.jsx)(n.li,{children:"Audit logs (security events, compliance)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Events"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"User activity (clicks, page views, sessions)"}),"\n",(0,r.jsx)(n.li,{children:"System events (deployments, configuration changes)"}),"\n",(0,r.jsx)(n.li,{children:"IoT telemetry (sensor data, device events)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Traces"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Distributed tracing spans"}),"\n",(0,r.jsx)(n.li,{children:"Service dependencies and call graphs"}),"\n",(0,r.jsx)(n.li,{children:"Performance profiling"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"32-interface",children:"3.2 Interface"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-protobuf",children:'syntax = "proto3";\n\npackage prism.timeseries.v1;\n\nservice TimeSeriesService {\n  // Append events (batched, async)\n  rpc AppendEvents(AppendEventsRequest) returns (AppendEventsResponse);\n\n  // Stream events (for high-throughput ingestion)\n  rpc StreamEvents(stream Event) returns (StreamEventsResponse);\n\n  // Query events with time range and filters\n  rpc QueryEvents(QueryRequest) returns (QueryResponse);\n\n  // Query with aggregations\n  rpc QueryAggregates(AggregateRequest) returns (AggregateResponse);\n\n  // Stream query results (for large datasets)\n  rpc StreamQuery(QueryRequest) returns (stream Event);\n}\n\nmessage Event {\n  // Timestamp (nanosecond precision)\n  google.protobuf.Timestamp timestamp = 1;\n\n  // Event metadata\n  string event_type = 2;\n  string source = 3;\n\n  // Dimensions (indexed)\n  map<string, string> dimensions = 4;\n\n  // Metrics (columnar storage)\n  map<string, double> metrics = 5;\n\n  // Payload (compressed)\n  bytes payload = 6;\n}\n\nmessage AppendEventsRequest {\n  string session_id = 1;\n  string namespace = 2;\n  repeated Event events = 3;\n\n  // Async mode (immediate response)\n  bool async = 4;\n}\n\nmessage QueryRequest {\n  string session_id = 1;\n  string namespace = 2;\n\n  // Time range (required for partition pruning)\n  google.protobuf.Timestamp start_time = 3;\n  google.protobuf.Timestamp end_time = 4;\n\n  // Filters (WHERE clause)\n  map<string, string> filters = 5;\n\n  // SQL-like query (optional)\n  string sql = 6;\n\n  // Pagination\n  int32 limit = 7;\n  int32 offset = 8;\n}\n\nmessage AggregateRequest {\n  string session_id = 1;\n  string namespace = 2;\n\n  google.protobuf.Timestamp start_time = 3;\n  google.protobuf.Timestamp end_time = 4;\n\n  // Aggregation function\n  enum AggregateFunc {\n    COUNT = 0;\n    SUM = 1;\n    AVG = 2;\n    MIN = 3;\n    MAX = 4;\n    QUANTILE_95 = 5;\n    QUANTILE_99 = 6;\n  }\n\n  // Metrics to aggregate\n  repeated string metric_names = 5;\n  repeated AggregateFunc functions = 6;\n\n  // Group by dimensions\n  repeated string group_by = 7;\n\n  // Time bucket (for time series)\n  google.protobuf.Duration bucket_size = 8;\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"33-schema-design",children:"3.3 Schema Design"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Main events table (sharded by timestamp)\nCREATE TABLE events ON CLUSTER '{cluster}' (\n    timestamp DateTime64(9),\n    event_type LowCardinality(String),\n    source LowCardinality(String),\n    namespace LowCardinality(String),\n\n    -- Dimensions (indexed)\n    dimensions Map(String, String),\n\n    -- Metrics (columnar)\n    metrics Map(String, Float64),\n\n    -- Payload (compressed)\n    payload String CODEC(ZSTD(3))\n)\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/events', '{replica}')\nPARTITION BY toYYYYMMDD(timestamp)\nORDER BY (namespace, event_type, timestamp)\nTTL timestamp + INTERVAL 90 DAY\nSETTINGS index_granularity = 8192;\n\n-- Distributed table (query interface)\nCREATE TABLE events_distributed ON CLUSTER '{cluster}' AS events\nENGINE = Distributed('{cluster}', default, events, rand());\n"})}),"\n",(0,r.jsx)(n.h3,{id:"34-materialized-views-for-pre-aggregations",children:"3.4 Materialized Views for Pre-aggregations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- 1-minute rollups\nCREATE MATERIALIZED VIEW events_1m ON CLUSTER '{cluster}'\nENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/{shard}/events_1m', '{replica}')\nPARTITION BY toYYYYMMDD(timestamp)\nORDER BY (namespace, event_type, timestamp_1m)\nAS SELECT\n    toStartOfMinute(timestamp) AS timestamp_1m,\n    namespace,\n    event_type,\n    count() AS event_count,\n    sumMap(metrics) AS metrics_sum,\n    avgMap(metrics) AS metrics_avg\nFROM events\nGROUP BY timestamp_1m, namespace, event_type;\n\n-- 1-hour rollups (from 1-minute)\nCREATE MATERIALIZED VIEW events_1h ON CLUSTER '{cluster}'\nENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/{shard}/events_1h', '{replica}')\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (namespace, event_type, timestamp_1h)\nAS SELECT\n    toStartOfHour(timestamp_1m) AS timestamp_1h,\n    namespace,\n    event_type,\n    sum(event_count) AS event_count,\n    sumMap(metrics_sum) AS metrics_sum\nFROM events_1m\nGROUP BY timestamp_1h, namespace, event_type;\n"})}),"\n",(0,r.jsx)(n.h2,{id:"4-query-patterns",children:"4. Query Patterns"}),"\n",(0,r.jsx)(n.h3,{id:"41-time-range-queries",children:"4.1 Time Range Queries"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Recent events (last 1 hour)\nSELECT *\nFROM events_distributed\nWHERE namespace = 'app:production'\n  AND timestamp >= now() - INTERVAL 1 HOUR\nORDER BY timestamp DESC\nLIMIT 100;\n"})}),"\n",(0,r.jsx)(n.h3,{id:"42-aggregations",children:"4.2 Aggregations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Request rate per minute (last 24 hours)\nSELECT\n    toStartOfMinute(timestamp) AS minute,\n    count() AS request_count,\n    avg(metrics['duration_ms']) AS avg_duration,\n    quantile(0.95)(metrics['duration_ms']) AS p95_duration\nFROM events_distributed\nWHERE namespace = 'api:requests'\n  AND timestamp >= now() - INTERVAL 24 HOUR\nGROUP BY minute\nORDER BY minute;\n"})}),"\n",(0,r.jsx)(n.h3,{id:"43-top-n-queries",children:"4.3 Top-N Queries"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Top 10 endpoints by error rate\nSELECT\n    dimensions['endpoint'] AS endpoint,\n    countIf(dimensions['status'] >= '500') AS error_count,\n    count() AS total_count,\n    error_count / total_count AS error_rate\nFROM events_distributed\nWHERE namespace = 'api:requests'\n  AND timestamp >= now() - INTERVAL 1 HOUR\nGROUP BY endpoint\nORDER BY error_rate DESC\nLIMIT 10;\n"})}),"\n",(0,r.jsx)(n.h3,{id:"44-time-series-bucketing",children:"4.4 Time Series Bucketing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- P99 latency per 5-minute bucket\nSELECT\n    toStartOfInterval(timestamp, INTERVAL 5 MINUTE) AS bucket,\n    quantile(0.99)(metrics['latency_ms']) AS p99_latency\nFROM events_distributed\nWHERE namespace = 'service:checkout'\n  AND timestamp >= now() - INTERVAL 6 HOUR\nGROUP BY bucket\nORDER BY bucket;\n"})}),"\n",(0,r.jsx)(n.h2,{id:"5-performance-optimizations",children:"5. Performance Optimizations"}),"\n",(0,r.jsx)(n.h3,{id:"51-partitioning-strategy",children:"5.1 Partitioning Strategy"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-mermaid",children:'graph TB\n    subgraph "Partition by Day"\n        P1[2025-10-01<br/>Partition 1]\n        P2[2025-10-02<br/>Partition 2]\n        P3[2025-10-03<br/>Partition 3]\n    end\n\n    subgraph "Each Partition"\n        Data[Data Parts<br/>8K granules]\n        Index[Primary Index<br/>namespace + event_type]\n        Marks[Sparse Index<br/>Mark files]\n    end\n\n    P1 --\x3e Data\n    P2 --\x3e Data\n    P3 --\x3e Data\n\n    Data --\x3e Index\n    Index --\x3e Marks\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partition Pruning"}),": Only scan relevant days"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TTL"}),": Drop old partitions efficiently"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parallel Queries"}),": Query partitions in parallel"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"52-compression",children:"5.2 Compression"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Codec comparison\nALTER TABLE events MODIFY COLUMN payload String CODEC(ZSTD(3));  -- 10x compression\nALTER TABLE events MODIFY COLUMN dimensions Map(String, String) CODEC(LZ4);  -- 3x, faster\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Compression Ratios"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ZSTD(3)"}),": 10-15x (best compression)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LZ4"}),": 2-3x (fastest)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Delta + LZ4"}),": 20x+ for monotonic data (timestamps, counters)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"53-async-inserts",children:"5.3 Async Inserts"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Enable async inserts (client-side batching)\nSET async_insert = 1;\nSET wait_for_async_insert = 0;\nSET async_insert_max_data_size = 10000000;  -- 10MB batches\nSET async_insert_busy_timeout_ms = 1000;     -- 1s max wait\n"})}),"\n",(0,r.jsx)(n.h2,{id:"6-configuration",children:"6. Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"61-client-configuration",children:"6.1 Client Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-protobuf",children:'message ClickHouseBackendConfig {\n  // Connection\n  repeated string hosts = 1;\n  int32 port = 2;\n  string database = 3;\n  string username = 4;\n  string password = 5;\n\n  // Cluster settings\n  bool cluster_mode = 6;\n  string cluster_name = 7;\n  int32 num_shards = 8;\n  int32 num_replicas = 9;\n\n  // Performance\n  int32 batch_size = 10;             // Events per batch\n  google.protobuf.Duration batch_timeout = 11;  // Max wait time\n  bool async_insert = 12;\n  int32 insert_threads = 13;\n\n  // Retention\n  int32 ttl_days = 14;\n  bool enable_tiered_storage = 15;\n\n  // Table settings\n  string partition_by = 16;  // "toYYYYMMDD(timestamp)"\n  string order_by = 17;      // "(namespace, event_type, timestamp)"\n  int32 index_granularity = 18;\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"62-server-configuration",children:"6.2 Server Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# config/clickhouse.yaml\nclickhouse:\n  cluster:\n    name: "prism_cluster"\n    shards:\n      - hosts: ["ch-shard1-1.internal:9000", "ch-shard1-2.internal:9000"]\n      - hosts: ["ch-shard2-1.internal:9000", "ch-shard2-2.internal:9000"]\n\n  tables:\n    events:\n      engine: "ReplicatedMergeTree"\n      partition_by: "toYYYYMMDD(timestamp)"\n      order_by: "(namespace, event_type, timestamp)"\n      ttl_days: 90\n      compression: "ZSTD(3)"\n\n  performance:\n    batch_size: 10000\n    batch_timeout: "1s"\n    async_insert: true\n    insert_threads: 4\n    max_memory_usage: "10GB"\n\n  materialized_views:\n    - name: "events_1m"\n      enabled: true\n    - name: "events_1h"\n      enabled: true\n    - name: "events_1d"\n      enabled: false  # Enable for long-term storage\n'})}),"\n",(0,r.jsx)(n.h2,{id:"7-operational-considerations",children:"7. Operational Considerations"}),"\n",(0,r.jsx)(n.h3,{id:"71-capacity-planning",children:"7.1 Capacity Planning"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Storage Calculation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"daily_volume = events_per_day \xd7 avg_event_size_bytes\ncompressed_size = daily_volume / compression_ratio\nretention_storage = compressed_size \xd7 retention_days \xd7 (1 + replica_count)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1B events/day \xd7 200 bytes = 200GB/day uncompressed"}),"\n",(0,r.jsx)(n.li,{children:"200GB / 10 (ZSTD) = 20GB/day compressed"}),"\n",(0,r.jsx)(n.li,{children:"20GB \xd7 90 days \xd7 2 (replication) = 3.6TB total"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Query Performance"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1M events/sec ingestion requires ~4 shards"}),"\n",(0,r.jsx)(n.li,{children:"Sub-second queries over 1TB datasets"}),"\n",(0,r.jsx)(n.li,{children:"100 concurrent analytical queries supported"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"72-monitoring",children:"7.2 Monitoring"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"metrics:\n  ingestion:\n    - insert_rate_events_per_sec\n    - insert_throughput_bytes_per_sec\n    - async_insert_queue_size\n    - insert_latency_p99\n\n  storage:\n    - disk_usage_bytes\n    - compression_ratio\n    - parts_count\n    - partition_count\n\n  queries:\n    - query_rate_per_sec\n    - query_latency_p50\n    - query_latency_p99\n    - memory_usage_per_query\n    - running_queries_count\n\n  replication:\n    - replication_lag_seconds\n    - replica_queue_size\n"})}),"\n",(0,r.jsx)(n.h3,{id:"73-data-lifecycle",children:"7.3 Data Lifecycle"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-mermaid",children:"graph LR\n    Hot[Hot Storage<br/>SSD<br/>Last 7 days] --\x3e|TTL| Warm[Warm Storage<br/>HDD<br/>8-30 days]\n    Warm --\x3e|TTL| Cold[Cold Storage<br/>S3<br/>31-90 days]\n    Cold --\x3e|TTL| Delete[Deleted<br/>90+ days]\n\n    style Hot fill:#ff6b6b\n    style Warm fill:#feca57\n    style Cold fill:#48dbfb\n    style Delete fill:#dfe6e9\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Tiered storage with TTL\nALTER TABLE events MODIFY TTL\n    timestamp + INTERVAL 7 DAY TO VOLUME 'hot',\n    timestamp + INTERVAL 30 DAY TO VOLUME 'warm',\n    timestamp + INTERVAL 90 DAY TO VOLUME 'cold',\n    timestamp + INTERVAL 90 DAY DELETE;\n"})}),"\n",(0,r.jsx)(n.h2,{id:"8-migration-path",children:"8. Migration Path"}),"\n",(0,r.jsx)(n.h3,{id:"81-phase-1-single-node-week-1-2",children:"8.1 Phase 1: Single Node (Week 1-2)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Deploy ClickHouse standalone"}),"\n",(0,r.jsx)(n.li,{children:"Implement TimeSeriesService gRPC interface"}),"\n",(0,r.jsx)(n.li,{children:"Create basic events table"}),"\n",(0,r.jsx)(n.li,{children:"Integration tests with mock data"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"82-phase-2-cluster-setup-week-3-4",children:"8.2 Phase 2: Cluster Setup (Week 3-4)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Deploy 2-shard cluster with replication"}),"\n",(0,r.jsx)(n.li,{children:"Configure Distributed tables"}),"\n",(0,r.jsx)(n.li,{children:"Implement async batching"}),"\n",(0,r.jsx)(n.li,{children:"Load testing (1M events/sec)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"83-phase-3-materialized-views-week-5-6",children:"8.3 Phase 3: Materialized Views (Week 5-6)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Create 1-minute rollups"}),"\n",(0,r.jsx)(n.li,{children:"Create 1-hour rollups"}),"\n",(0,r.jsx)(n.li,{children:"Query optimization with pre-aggregations"}),"\n",(0,r.jsx)(n.li,{children:"Benchmarking (query latency)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"84-phase-4-production-week-7-8",children:"8.4 Phase 4: Production (Week 7-8)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Tiered storage configuration"}),"\n",(0,r.jsx)(n.li,{children:"Alerting and monitoring"}),"\n",(0,r.jsx)(n.li,{children:"Backup and disaster recovery"}),"\n",(0,r.jsx)(n.li,{children:"Documentation and runbooks"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"9-use-case-recommendations",children:"9. Use Case Recommendations"}),"\n",(0,r.jsx)(n.h3,{id:"91-when-to-use-clickhouse",children:"9.1 When to Use ClickHouse"}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Use When"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Append-only time series data"}),"\n",(0,r.jsx)(n.li,{children:"Analytical queries over large datasets"}),"\n",(0,r.jsx)(n.li,{children:"Real-time aggregations needed"}),"\n",(0,r.jsxs)(n.li,{children:["High ingestion rate (",(0,r.jsx)(n.code,{children:">100k"})," events/sec)"]}),"\n",(0,r.jsx)(n.li,{children:"Data has natural time dimension"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Avoid When"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Need updates/deletes (use Postgres)"}),"\n",(0,r.jsx)(n.li,{children:"Complex joins required (use Postgres)"}),"\n",(0,r.jsx)(n.li,{children:"Full-text search needed (use Elasticsearch)"}),"\n",(0,r.jsxs)(n.li,{children:["Small dataset (",(0,r.jsx)(n.code,{children:"<1M"})," rows, use Postgres)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"92-clickhouse-vs-alternatives",children:"9.2 ClickHouse vs Alternatives"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Use Case"}),(0,r.jsx)(n.th,{children:"ClickHouse"}),(0,r.jsx)(n.th,{children:"Postgres"}),(0,r.jsx)(n.th,{children:"Kafka"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Metrics storage"}),(0,r.jsx)(n.td,{children:"\u2705 Excellent"}),(0,r.jsx)(n.td,{children:"\u274c Poor"}),(0,r.jsx)(n.td,{children:"\u274c No analytics"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Event logging"}),(0,r.jsx)(n.td,{children:"\u2705 Excellent"}),(0,r.jsx)(n.td,{children:"\u26a0\ufe0f Limited"}),(0,r.jsx)(n.td,{children:"\u2705 Good"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Real-time dashboards"}),(0,r.jsx)(n.td,{children:"\u2705 Excellent"}),(0,r.jsx)(n.td,{children:"\u274c Slow"}),(0,r.jsx)(n.td,{children:"\u274c No queries"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Retention (90+ days)"}),(0,r.jsx)(n.td,{children:"\u2705 Efficient"}),(0,r.jsx)(n.td,{children:"\u274c Expensive"}),(0,r.jsx)(n.td,{children:"\u26a0\ufe0f Complex"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Complex aggregations"}),(0,r.jsx)(n.td,{children:"\u2705 Fast"}),(0,r.jsx)(n.td,{children:"\u26a0\ufe0f Moderate"}),(0,r.jsx)(n.td,{children:"\u274c Not supported"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"10-references",children:"10. References"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/",children:"ClickHouse Documentation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replication",children:"ReplicatedMergeTree Engine"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/en/guides/developer/cascading-materialized-views",children:"Materialized Views"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/en/sql-reference/statements/create/table#column_compression_codec",children:"Compression Codecs"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"11-revision-history",children:"11. Revision History"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"2025-10-08: Initial draft"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var i=s(6540);const r={},t=i.createContext(r);function a(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);