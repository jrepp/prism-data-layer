"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[7109],{28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var t=i(96540);const s={},r=t.createContext(s);function a(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(r.Provider,{value:n},e.children)}},41460:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"adr-030","title":"Schema Recording with Protobuf Tagging","description":"Context","source":"@site/../docs-cms/adr/adr-030-schema-recording-protobuf-tags.md","sourceDirName":".","slug":"/adr-030","permalink":"/prism-data-layer/adr/adr-030","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/adr/adr-030-schema-recording-protobuf-tags.md","tags":[{"inline":true,"label":"protobuf","permalink":"/prism-data-layer/adr/tags/protobuf"},{"inline":true,"label":"schema","permalink":"/prism-data-layer/adr/tags/schema"},{"inline":true,"label":"versioning","permalink":"/prism-data-layer/adr/tags/versioning"},{"inline":true,"label":"evolution","permalink":"/prism-data-layer/adr/tags/evolution"},{"inline":true,"label":"registry","permalink":"/prism-data-layer/adr/tags/registry"}],"version":"current","frontMatter":{"date":"2025-10-08T00:00:00.000Z","deciders":"Core Team","doc_uuid":"544db4ef-3d6f-4ca3-b651-97241748b9fd","id":"adr-030","project_id":"prism-data-layer","status":"Accepted","tags":["protobuf","schema","versioning","evolution","registry"],"title":"Schema Recording with Protobuf Tagging"},"sidebar":"adrSidebar","previous":{"title":"Protocol Recording with Protobuf Tagging \u2022 ADR-029","permalink":"/prism-data-layer/adr/adr-029"},"next":{"title":"ADR-031 TTL Defaults","permalink":"/prism-data-layer/adr/adr-031"}}');var s=i(74848),r=i(28453);const a={date:new Date("2025-10-08T00:00:00.000Z"),deciders:"Core Team",doc_uuid:"544db4ef-3d6f-4ca3-b651-97241748b9fd",id:"adr-030",project_id:"prism-data-layer",status:"Accepted",tags:["protobuf","schema","versioning","evolution","registry"],title:"Schema Recording with Protobuf Tagging"},o=void 0,l={},c=[{value:"Context",id:"context",level:2},{value:"Decision",id:"decision",level:2},{value:"Rationale",id:"rationale",level:2},{value:"Why Custom Protobuf Options",id:"why-custom-protobuf-options",level:3},{value:"Schema Option Definition",id:"schema-option-definition",level:3},{value:"Tagged Schema Examples",id:"tagged-schema-examples",level:3},{value:"Schema Registry",id:"schema-registry",level:3},{value:"Schema Registry Implementation",id:"schema-registry-implementation",level:3},{value:"Build-time Schema Registration",id:"build-time-schema-registration",level:3},{value:"Database Schema",id:"database-schema",level:3},{value:"CLI Integration",id:"cli-integration",level:3},{value:"Migration Generation",id:"migration-generation",level:3},{value:"Alternatives Considered",id:"alternatives-considered",level:3},{value:"Consequences",id:"consequences",level:2},{value:"Positive",id:"positive",level:3},{value:"Negative",id:"negative",level:3},{value:"Neutral",id:"neutral",level:3},{value:"Implementation Notes",id:"implementation-notes",level:2},{value:"Code Generation",id:"code-generation",level:3},{value:"Integration with Admin API",id:"integration-with-admin-api",level:3},{value:"References",id:"references",level:2},{value:"Revision History",id:"revision-history",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,s.jsx)(n.p,{children:"Prism uses protobuf for all data models and client configurations. Need to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Track schema evolution over time"}),"\n",(0,s.jsx)(n.li,{children:"Validate compatibility during deployments"}),"\n",(0,s.jsx)(n.li,{children:"Provide schema discovery for clients"}),"\n",(0,s.jsx)(n.li,{children:"Audit schema changes"}),"\n",(0,s.jsx)(n.li,{children:"Enable schema-aware tooling"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Requirements:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Record schema deployments automatically"}),"\n",(0,s.jsx)(n.li,{children:"Detect breaking changes"}),"\n",(0,s.jsx)(n.li,{children:"Query schema history"}),"\n",(0,s.jsx)(n.li,{children:"Generate migration scripts"}),"\n",(0,s.jsx)(n.li,{children:"Support schema branching (dev/staging/prod)"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"decision",children:"Decision"}),"\n",(0,s.jsxs)(n.p,{children:["Use ",(0,s.jsx)(n.strong,{children:"Protobuf custom options for schema metadata tagging"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Custom option ",(0,s.jsx)(n.code,{children:"(prism.schema)"})]}),": Tag messages with schema metadata"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Schema versioning"}),": Semantic versioning with compatibility rules"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Schema registry"}),": Centralized storage for all deployed schemas"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Compatibility checking"}),": Forward, backward, full compatibility modes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Migration tracking"}),": Link schemas to database migrations"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"rationale",children:"Rationale"}),"\n",(0,s.jsx)(n.h3,{id:"why-custom-protobuf-options",children:"Why Custom Protobuf Options"}),"\n",(0,s.jsxs)(n.p,{children:["Protobuf options allow ",(0,s.jsx)(n.strong,{children:"declarative schema metadata"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Version controlled alongside code"}),"\n",(0,s.jsx)(n.li,{children:"Type-safe annotations"}),"\n",(0,s.jsx)(n.li,{children:"Code generation aware"}),"\n",(0,s.jsx)(n.li,{children:"Centralized schema policy"}),"\n",(0,s.jsx)(n.li,{children:"No runtime overhead"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"schema-option-definition",children:"Schema Option Definition"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-protobuf",children:'// proto/prism/options.proto\nsyntax = "proto3";\n\npackage prism;\n\nimport "google/protobuf/descriptor.proto";\n\n// Schema metadata options\nextend google.protobuf.MessageOptions {\n  SchemaOptions schema = 50101;\n}\n\nextend google.protobuf.FieldOptions {\n  FieldSchemaOptions field_schema = 50102;\n}\n\nmessage SchemaOptions {\n  // Schema version (semantic versioning)\n  string version = 1;\n\n  // Schema category\n  string category = 2;  // "entity", "event", "config", "command"\n\n  // Compatibility mode\n  CompatibilityMode compatibility = 3;\n\n  // Storage backend\n  string backend = 4;  // "postgres", "kafka", "nats", "neptune"\n\n  // Enable schema evolution tracking\n  bool track_evolution = 5 [default = true];\n\n  // Migration script reference\n  optional string migration = 6;\n\n  // Schema owner/team\n  string owner = 7;\n\n  // Tags for discovery\n  repeated string tags = 8;\n\n  // Deprecation notice\n  optional DeprecationInfo deprecation = 9;\n}\n\nenum CompatibilityMode {\n  COMPATIBILITY_MODE_UNSPECIFIED = 0;\n  COMPATIBILITY_MODE_NONE = 1;         // No compatibility checks\n  COMPATIBILITY_MODE_BACKWARD = 2;     // New schema can read old data\n  COMPATIBILITY_MODE_FORWARD = 3;      // Old schema can read new data\n  COMPATIBILITY_MODE_FULL = 4;         // Both backward and forward\n}\n\nmessage DeprecationInfo {\n  string reason = 1;\n  string deprecated_at = 2;  // ISO 8601 date\n  string removed_at = 3;     // Planned removal date\n  string replacement = 4;    // Replacement schema name\n}\n\nmessage FieldSchemaOptions {\n  // Field-level indexing hint\n  IndexType index = 1;\n\n  // PII classification\n  PIIType pii = 2;\n\n  // Required for creation\n  bool required_for_create = 3;\n\n  // Immutable after creation\n  bool immutable = 4;\n\n  // Encryption at rest\n  bool encrypted = 5;\n\n  // Default value generation\n  optional string default_generator = 6;  // "uuid", "timestamp", "sequence"\n}\n\nenum IndexType {\n  INDEX_TYPE_UNSPECIFIED = 0;\n  INDEX_TYPE_NONE = 1;\n  INDEX_TYPE_PRIMARY = 2;\n  INDEX_TYPE_SECONDARY = 3;\n  INDEX_TYPE_UNIQUE = 4;\n  INDEX_TYPE_FULLTEXT = 5;\n}\n\nenum PIIType {\n  PII_TYPE_UNSPECIFIED = 0;\n  PII_TYPE_NONE = 1;\n  PII_TYPE_EMAIL = 2;\n  PII_TYPE_PHONE = 3;\n  PII_TYPE_NAME = 4;\n  PII_TYPE_ADDRESS = 5;\n  PII_TYPE_SSN = 6;\n  PII_TYPE_CREDIT_CARD = 7;\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"tagged-schema-examples",children:"Tagged Schema Examples"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Entity Schema:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-protobuf",children:'// proto/prism/data/v1/user.proto\nimport "prism/options.proto";\n\nmessage UserProfile {\n  option (prism.schema) = {\n    version: "1.2.0"\n    category: "entity"\n    compatibility: COMPATIBILITY_MODE_BACKWARD\n    backend: "postgres"\n    migration: "migrations/002_add_user_verified.sql"\n    owner: "identity-team"\n    tags: ["user", "identity", "core"]\n  };\n\n  string user_id = 1 [\n    (prism.field_schema) = {\n      index: INDEX_TYPE_PRIMARY\n      required_for_create: true\n      immutable: true\n      default_generator: "uuid"\n    }\n  ];\n\n  string email = 2 [\n    (prism.field_schema) = {\n      index: INDEX_TYPE_UNIQUE\n      pii: PII_TYPE_EMAIL\n      encrypted: true\n      required_for_create: true\n    }\n  ];\n\n  string name = 3 [\n    (prism.field_schema) = {\n      pii: PII_TYPE_NAME\n    }\n  ];\n\n  bool verified = 4 [\n    (prism.field_schema) = {\n      required_for_create: false\n    }\n  ];  // Added in v1.2.0\n\n  int64 created_at = 5 [\n    (prism.field_schema) = {\n      index: INDEX_TYPE_SECONDARY\n      immutable: true\n      default_generator: "timestamp"\n    }\n  ];\n\n  int64 updated_at = 6 [\n    (prism.field_schema) = {\n      default_generator: "timestamp"\n    }\n  ];\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Event Schema:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-protobuf",children:'// proto/prism/events/v1/user_events.proto\nmessage UserCreatedEvent {\n  option (prism.schema) = {\n    version: "1.0.0"\n    category: "event"\n    compatibility: COMPATIBILITY_MODE_FORWARD\n    backend: "kafka"\n    owner: "identity-team"\n    tags: ["event", "user", "lifecycle"]\n  };\n\n  string event_id = 1 [\n    (prism.field_schema) = {\n      index: INDEX_TYPE_PRIMARY\n      default_generator: "uuid"\n    }\n  ];\n\n  string user_id = 2 [\n    (prism.field_schema) = {\n      index: INDEX_TYPE_SECONDARY\n      required_for_create: true\n    }\n  ];\n\n  int64 timestamp = 3 [\n    (prism.field_schema) = {\n      index: INDEX_TYPE_SECONDARY\n      default_generator: "timestamp"\n    }\n  ];\n\n  UserProfile user_data = 4;\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Deprecated Schema:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-protobuf",children:'message UserProfileV1 {\n  option (prism.schema) = {\n    version: "1.0.0"\n    category: "entity"\n    backend: "postgres"\n    owner: "identity-team"\n    deprecation: {\n      reason: "Replaced by UserProfile with email verification"\n      deprecated_at: "2025-09-01"\n      removed_at: "2026-01-01"\n      replacement: "prism.data.v1.UserProfile"\n    }\n  };\n\n  string user_id = 1;\n  string email = 2;\n  string name = 3;\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"schema-registry",children:"Schema Registry"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Schema Registry Service:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-protobuf",children:'// proto/prism/schema/v1/registry.proto\nsyntax = "proto3";\n\npackage prism.schema.v1;\n\nimport "google/protobuf/descriptor.proto";\nimport "google/protobuf/timestamp.proto";\n\nservice SchemaRegistry {\n  // Register new schema version\n  rpc RegisterSchema(RegisterSchemaRequest) returns (RegisterSchemaResponse);\n\n  // Get schema by name and version\n  rpc GetSchema(GetSchemaRequest) returns (GetSchemaResponse);\n\n  // List all schemas\n  rpc ListSchemas(ListSchemasRequest) returns (ListSchemasResponse);\n\n  // Check compatibility\n  rpc CheckCompatibility(CheckCompatibilityRequest) returns (CheckCompatibilityResponse);\n\n  // Get schema evolution history\n  rpc GetSchemaHistory(GetSchemaHistoryRequest) returns (stream SchemaVersion);\n\n  // Search schemas by tags\n  rpc SearchSchemas(SearchSchemasRequest) returns (SearchSchemasResponse);\n}\n\nmessage RegisterSchemaRequest {\n  string name = 1;\n  string version = 2;\n  google.protobuf.FileDescriptorSet descriptor_set = 3;\n  string environment = 4;  // "dev", "staging", "production"\n  map<string, string> metadata = 5;\n}\n\nmessage RegisterSchemaResponse {\n  string schema_id = 1;\n  google.protobuf.Timestamp registered_at = 2;\n  CompatibilityResult compatibility = 3;\n}\n\nmessage GetSchemaRequest {\n  string name = 1;\n  optional string version = 2;  // If not specified, get latest\n  optional string environment = 3;\n}\n\nmessage GetSchemaResponse {\n  SchemaVersion schema = 1;\n}\n\nmessage ListSchemasRequest {\n  optional string category = 1;\n  optional string backend = 2;\n  optional string owner = 3;\n  int32 page_size = 4;\n  optional string page_token = 5;\n}\n\nmessage ListSchemasResponse {\n  repeated SchemaInfo schemas = 1;\n  optional string next_page_token = 2;\n}\n\nmessage SchemaInfo {\n  string name = 1;\n  string current_version = 2;\n  string category = 3;\n  string backend = 4;\n  string owner = 5;\n  repeated string tags = 6;\n  google.protobuf.Timestamp created_at = 7;\n  google.protobuf.Timestamp updated_at = 8;\n  int32 version_count = 9;\n  optional DeprecationInfo deprecation = 10;\n}\n\nmessage SchemaVersion {\n  string schema_id = 1;\n  string name = 2;\n  string version = 3;\n  google.protobuf.FileDescriptorSet descriptor_set = 4;\n  google.protobuf.Timestamp registered_at = 5;\n  string environment = 6;\n  map<string, string> metadata = 7;\n  CompatibilityMode compatibility_mode = 8;\n}\n\nmessage CheckCompatibilityRequest {\n  string name = 1;\n  string new_version = 2;\n  google.protobuf.FileDescriptorSet new_descriptor_set = 3;\n  optional string compare_version = 4;  // If not specified, compare with latest\n}\n\nmessage CheckCompatibilityResponse {\n  bool compatible = 1;\n  CompatibilityResult result = 2;\n}\n\nmessage CompatibilityResult {\n  bool backward_compatible = 1;\n  bool forward_compatible = 2;\n  repeated string breaking_changes = 3;\n  repeated string warnings = 4;\n}\n\nmessage GetSchemaHistoryRequest {\n  string name = 1;\n  optional string environment = 2;\n}\n\nmessage SearchSchemasRequest {\n  repeated string tags = 1;\n  optional string category = 2;\n  optional string owner = 3;\n}\n\nmessage SearchSchemasResponse {\n  repeated SchemaInfo schemas = 1;\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"schema-registry-implementation",children:"Schema Registry Implementation"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Registry Storage:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'// proxy/src/schema/registry.rs\nuse prost::Message;\nuse prost_types::FileDescriptorSet;\n\n#[async_trait]\npub trait SchemaRegistry: Send + Sync {\n    async fn register(&self, req: RegisterSchemaRequest) -> Result<RegisterSchemaResponse>;\n    async fn get(&self, name: &str, version: Option<&str>) -> Result<SchemaVersion>;\n    async fn list(&self, filter: SchemaFilter) -> Result<Vec<SchemaInfo>>;\n    async fn check_compatibility(&self, req: CheckCompatibilityRequest) -> Result<CompatibilityResult>;\n    async fn get_history(&self, name: &str) -> Result<Vec<SchemaVersion>>;\n}\n\npub struct PostgresSchemaRegistry {\n    pool: PgPool,\n}\n\nimpl SchemaRegistry for PostgresSchemaRegistry {\n    async fn register(&self, req: RegisterSchemaRequest) -> Result<RegisterSchemaResponse> {\n        // Check compatibility with existing schemas\n        let compatibility = if let Ok(existing) = self.get(&req.name, None).await {\n            self.check_compatibility(CheckCompatibilityRequest {\n                name: req.name.clone(),\n                new_version: req.version.clone(),\n                new_descriptor_set: req.descriptor_set.clone(),\n                compare_version: Some(existing.version),\n            }).await?\n        } else {\n            CompatibilityResult::default()\n        };\n\n        // Serialize descriptor set\n        let descriptor_bytes = req.descriptor_set.encode_to_vec();\n\n        // Store schema\n        let schema_id = sqlx::query_scalar::<_, String>(\n            r#"\n            INSERT INTO schemas\n            (name, version, descriptor_set, environment, metadata, registered_at)\n            VALUES ($1, $2, $3, $4, $5, NOW())\n            RETURNING id\n            "#\n        )\n        .bind(&req.name)\n        .bind(&req.version)\n        .bind(&descriptor_bytes)\n        .bind(&req.environment)\n        .bind(&req.metadata)\n        .fetch_one(&self.pool)\n        .await?;\n\n        Ok(RegisterSchemaResponse {\n            schema_id,\n            registered_at: Utc::now(),\n            compatibility,\n        })\n    }\n\n    async fn get(&self, name: &str, version: Option<&str>) -> Result<SchemaVersion> {\n        let row = if let Some(ver) = version {\n            sqlx::query_as::<_, SchemaRow>(\n                "SELECT * FROM schemas WHERE name = $1 AND version = $2"\n            )\n            .bind(name)\n            .bind(ver)\n            .fetch_one(&self.pool)\n            .await?\n        } else {\n            sqlx::query_as::<_, SchemaRow>(\n                "SELECT * FROM schemas WHERE name = $1 ORDER BY registered_at DESC LIMIT 1"\n            )\n            .bind(name)\n            .fetch_one(&self.pool)\n            .await?\n        };\n\n        Ok(row.into_schema_version()?)\n    }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Compatibility Checker:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'// proxy/src/schema/compatibility.rs\nuse prost_types::FileDescriptorSet;\n\npub struct CompatibilityChecker;\n\nimpl CompatibilityChecker {\n    pub fn check(\n        old_set: &FileDescriptorSet,\n        new_set: &FileDescriptorSet,\n        mode: CompatibilityMode,\n    ) -> CompatibilityResult {\n        let mut result = CompatibilityResult {\n            backward_compatible: true,\n            forward_compatible: true,\n            breaking_changes: vec![],\n            warnings: vec![],\n        };\n\n        // Extract message descriptors\n        let old_messages = Self::extract_messages(old_set);\n        let new_messages = Self::extract_messages(new_set);\n\n        // Check backward compatibility (new schema can read old data)\n        if matches!(mode, CompatibilityMode::Backward | CompatibilityMode::Full) {\n            for (name, old_msg) in &old_messages {\n                if let Some(new_msg) = new_messages.get(name) {\n                    // Check for removed fields\n                    for old_field in &old_msg.field {\n                        if !new_msg.field.iter().any(|f| f.number == old_field.number) {\n                            result.backward_compatible = false;\n                            result.breaking_changes.push(format!(\n                                "Field {} removed from {}",\n                                old_field.name, name\n                            ));\n                        }\n                    }\n\n                    // Check for type changes\n                    for old_field in &old_msg.field {\n                        if let Some(new_field) = new_msg.field.iter().find(|f| f.number == old_field.number) {\n                            if old_field.r#type != new_field.r#type {\n                                result.backward_compatible = false;\n                                result.breaking_changes.push(format!(\n                                    "Field {}.{} type changed",\n                                    name, old_field.name\n                                ));\n                            }\n                        }\n                    }\n                } else {\n                    result.backward_compatible = false;\n                    result.breaking_changes.push(format!("Message {} removed", name));\n                }\n            }\n        }\n\n        // Check forward compatibility (old schema can read new data)\n        if matches!(mode, CompatibilityMode::Forward | CompatibilityMode::Full) {\n            for (name, new_msg) in &new_messages {\n                if let Some(old_msg) = old_messages.get(name) {\n                    // Check for new required fields\n                    for new_field in &new_msg.field {\n                        if !old_msg.field.iter().any(|f| f.number == new_field.number) {\n                            // New field should be optional for forward compatibility\n                            if !Self::is_optional(new_field) {\n                                result.forward_compatible = false;\n                                result.breaking_changes.push(format!(\n                                    "Required field {} added to {}",\n                                    new_field.name, name\n                                ));\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        result\n    }\n\n    fn extract_messages(descriptor_set: &FileDescriptorSet) -> HashMap<String, MessageDescriptor> {\n        // Extract all message descriptors from FileDescriptorSet\n        // ...implementation details...\n        HashMap::new()\n    }\n\n    fn is_optional(field: &FieldDescriptor) -> bool {\n        // Check if field is optional (proto3 optional keyword or non-required)\n        true\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"build-time-schema-registration",children:"Build-time Schema Registration"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Automatic registration during build:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'// build.rs\nfn main() {\n    // Compile protobuf files\n    let descriptor_set_path = std::env::var("OUT_DIR").unwrap() + "/descriptor_set.bin";\n\n    prost_build::Config::new()\n        .file_descriptor_set_path(&descriptor_set_path)\n        .compile_protos(&["proto/prism/data/v1/user.proto"], &["proto/"])\n        .unwrap();\n\n    // Register schema with registry (if SCHEMA_REGISTRY_ENDPOINT is set)\n    if let Ok(registry_endpoint) = std::env::var("SCHEMA_REGISTRY_ENDPOINT") {\n        register_schema_from_descriptor(&descriptor_set_path, &registry_endpoint);\n    }\n}\n\nfn register_schema_from_descriptor(path: &str, endpoint: &str) {\n    // Read descriptor set\n    let bytes = std::fs::read(path).unwrap();\n    let descriptor_set = FileDescriptorSet::decode(&*bytes).unwrap();\n\n    // Extract schema metadata from custom options\n    let schema_info = extract_schema_metadata(&descriptor_set);\n\n    // Register with registry\n    let client = SchemaRegistryClient::connect(endpoint).unwrap();\n    client.register_schema(RegisterSchemaRequest {\n        name: schema_info.name,\n        version: schema_info.version,\n        descriptor_set,\n        environment: std::env::var("ENVIRONMENT").unwrap_or("dev".to_string()),\n        metadata: HashMap::new(),\n    }).await.unwrap();\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"database-schema",children:"Database Schema"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE schemas (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name TEXT NOT NULL,\n    version TEXT NOT NULL,\n    descriptor_set BYTEA NOT NULL,\n    environment TEXT NOT NULL,\n    metadata JSONB,\n    registered_at TIMESTAMPTZ NOT NULL,\n\n    -- Indexes\n    UNIQUE(name, version, environment),\n    INDEX idx_schemas_name ON schemas(name),\n    INDEX idx_schemas_env ON schemas(environment),\n    INDEX idx_schemas_registered ON schemas(registered_at DESC)\n);\n\n-- Schema metadata extracted from protobuf options\nCREATE TABLE schema_metadata (\n    schema_id UUID REFERENCES schemas(id) ON DELETE CASCADE,\n    category TEXT,\n    compatibility_mode TEXT,\n    backend TEXT,\n    owner TEXT,\n    tags TEXT[],\n    migration TEXT,\n    deprecated BOOLEAN DEFAULT FALSE,\n    deprecation_info JSONB,\n\n    PRIMARY KEY (schema_id),\n    INDEX idx_schema_category ON schema_metadata(category),\n    INDEX idx_schema_backend ON schema_metadata(backend),\n    INDEX idx_schema_tags ON schema_metadata USING GIN(tags)\n);\n\n-- Field-level metadata\nCREATE TABLE field_metadata (\n    schema_id UUID REFERENCES schemas(id) ON DELETE CASCADE,\n    field_number INT NOT NULL,\n    field_name TEXT NOT NULL,\n    index_type TEXT,\n    pii_type TEXT,\n    required_for_create BOOLEAN,\n    immutable BOOLEAN,\n    encrypted BOOLEAN,\n    default_generator TEXT,\n\n    PRIMARY KEY (schema_id, field_number),\n    INDEX idx_field_pii ON field_metadata(pii_type) WHERE pii_type IS NOT NULL\n);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"cli-integration",children:"CLI Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Register schema manually\nprism-admin schema register \\\n  --proto proto/prism/data/v1/user.proto \\\n  --version 1.2.0 \\\n  --environment production\n\n# Check compatibility\nprism-admin schema check \\\n  --proto proto/prism/data/v1/user.proto \\\n  --against 1.1.0\n\n# List schemas\nprism-admin schema list --category entity --backend postgres\n\n# Get schema history\nprism-admin schema history prism.data.v1.UserProfile\n\n# Search by tags\nprism-admin schema search --tags user,identity\n\n# Generate migration\nprism-admin schema migrate \\\n  --from prism.data.v1.UserProfile:1.1.0 \\\n  --to prism.data.v1.UserProfile:1.2.0 \\\n  --output migrations/\n"})}),"\n",(0,s.jsx)(n.h3,{id:"migration-generation",children:"Migration Generation"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Automatic migration script generation:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:'// proxy/src/schema/migration.rs\npub struct MigrationGenerator;\n\nimpl MigrationGenerator {\n    pub fn generate(\n        old_schema: &SchemaVersion,\n        new_schema: &SchemaVersion,\n        backend: &str,\n    ) -> Result<String> {\n        let old_messages = extract_messages(&old_schema.descriptor_set);\n        let new_messages = extract_messages(&new_schema.descriptor_set);\n\n        match backend {\n            "postgres" => Self::generate_postgres_migration(&old_messages, &new_messages),\n            "kafka" => Self::generate_kafka_migration(&old_messages, &new_messages),\n            _ => Err(anyhow!("Unsupported backend: {}", backend)),\n        }\n    }\n\n    fn generate_postgres_migration(\n        old: &HashMap<String, MessageDescriptor>,\n        new: &HashMap<String, MessageDescriptor>,\n    ) -> Result<String> {\n        let mut sql = String::new();\n\n        for (name, new_msg) in new {\n            if let Some(old_msg) = old.get(name) {\n                // Generate ALTER TABLE for changes\n                let table_name = to_snake_case(name);\n\n                for new_field in &new_msg.field {\n                    if !old_msg.field.iter().any(|f| f.number == new_field.number) {\n                        // New field added\n                        let col_type = proto_to_sql_type(new_field);\n                        sql.push_str(&format!(\n                            "ALTER TABLE {} ADD COLUMN {} {};\\n",\n                            table_name,\n                            to_snake_case(&new_field.name),\n                            col_type\n                        ));\n\n                        // Add index if specified\n                        if let Some(index_type) = get_field_option(new_field, "index") {\n                            if index_type != "INDEX_TYPE_NONE" {\n                                sql.push_str(&format!(\n                                    "CREATE INDEX idx_{}_{} ON {}({});\\n",\n                                    table_name,\n                                    to_snake_case(&new_field.name),\n                                    table_name,\n                                    to_snake_case(&new_field.name)\n                                ));\n                            }\n                        }\n                    }\n                }\n            } else {\n                // New table\n                sql.push_str(&Self::generate_create_table(name, new_msg));\n            }\n        }\n\n        Ok(sql)\n    }\n\n    fn generate_create_table(name: &str, msg: &MessageDescriptor) -> String {\n        let table_name = to_snake_case(name);\n        let mut columns = vec![];\n\n        for field in &msg.field {\n            let col_name = to_snake_case(&field.name);\n            let col_type = proto_to_sql_type(field);\n            columns.push(format!("  {} {}", col_name, col_type));\n        }\n\n        format!(\n            "CREATE TABLE {} (\\n{}\\n);\\n",\n            table_name,\n            columns.join(",\\n")\n        )\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"alternatives-considered",children:"Alternatives Considered"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Schema-less / dynamic schemas"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pros: Flexible, no registration needed"}),"\n",(0,s.jsx)(n.li,{children:"Cons: No type safety, no compatibility checking, runtime errors"}),"\n",(0,s.jsx)(n.li,{children:"Rejected: Type safety is critical for reliability"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Manual schema versioning"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pros: Simple, developer-controlled"}),"\n",(0,s.jsx)(n.li,{children:"Cons: Error-prone, no automated checks, no discovery"}),"\n",(0,s.jsx)(n.li,{children:"Rejected: Need automated compatibility checking"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Separate schema registry (Confluent Schema Registry)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pros: Battle-tested, Kafka ecosystem standard"}),"\n",(0,s.jsx)(n.li,{children:"Cons: External dependency, Kafka-centric, limited protobuf support"}),"\n",(0,s.jsx)(n.li,{children:"Deferred: May integrate for Kafka backends specifically"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"consequences",children:"Consequences"}),"\n",(0,s.jsx)(n.h3,{id:"positive",children:"Positive"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type safety"}),": Schemas validated at build time"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Automated compatibility"}),": Breaking changes caught early"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Centralized discovery"}),": All schemas queryable"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Migration support"}),": Automated script generation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Audit trail"}),": Complete schema evolution history"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PII tracking"}),": Field-level PII metadata"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"negative",children:"Negative"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Build complexity"}),": Schema registration in build process"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Registry dependency"}),": Central service required"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Storage overhead"}),": Descriptor sets stored for each version"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"neutral",children:"Neutral"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Learning curve"}),": Developers must understand compatibility modes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Versioning discipline"}),": Teams must follow semantic versioning"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"implementation-notes",children:"Implementation Notes"}),"\n",(0,s.jsx)(n.h3,{id:"code-generation",children:"Code Generation"}),"\n",(0,s.jsx)(n.p,{children:"Extract schema options during build:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-rust",children:"// build.rs\nfn extract_schema_metadata(descriptor_set: &FileDescriptorSet) -> SchemaMetadata {\n    // Parse custom options from descriptor\n    // Generate Rust code for schema info\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"integration-with-admin-api",children:"Integration with Admin API"}),"\n",(0,s.jsx)(n.p,{children:"Schema registry accessible via Admin API (ADR-027):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-protobuf",children:"service AdminService {\n  // Existing admin operations...\n\n  // Schema operations\n  rpc RegisterSchema(RegisterSchemaRequest) returns (RegisterSchemaResponse);\n  rpc ListSchemas(ListSchemasRequest) returns (ListSchemasResponse);\n  rpc CheckCompatibility(CheckCompatibilityRequest) returns (CheckCompatibilityResponse);\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://protobuf.dev/programming-guides/proto3/#options",children:"Protobuf Options"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/schema-registry/index.html",children:"Confluent Schema Registry"})}),"\n",(0,s.jsx)(n.li,{children:"ADR-003: Protobuf as Single Source of Truth"}),"\n",(0,s.jsx)(n.li,{children:"ADR-027: Admin API via gRPC"}),"\n",(0,s.jsx)(n.li,{children:"ADR-029: Protocol Recording with Protobuf Tagging"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"revision-history",children:"Revision History"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"2025-10-08: Initial draft and acceptance"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);