"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[2785],{28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var s=i(96540);const o={},t=s.createContext(o);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),s.createElement(t.Provider,{value:n},e.children)}},41268:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"adr-035","title":"Database Connection Pooling vs Direct Connections","description":"Context","source":"@site/../docs-cms/adr/adr-035-connection-pooling.md","sourceDirName":".","slug":"/adr-035","permalink":"/prism-data-layer/adr/adr-035","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/adr/adr-035-connection-pooling.md","tags":[{"inline":true,"label":"performance","permalink":"/prism-data-layer/adr/tags/performance"},{"inline":true,"label":"backend","permalink":"/prism-data-layer/adr/tags/backend"},{"inline":true,"label":"reliability","permalink":"/prism-data-layer/adr/tags/reliability"},{"inline":true,"label":"architecture","permalink":"/prism-data-layer/adr/tags/architecture"}],"version":"current","frontMatter":{"date":"2025-10-08T00:00:00.000Z","deciders":"System","doc_uuid":"0c2760b2-c974-4714-bf7f-07bc0e66c8fe","id":"adr-035","project_id":"prism-data-layer","status":"Proposed","tags":["performance","backend","reliability","architecture"],"title":"Database Connection Pooling vs Direct Connections"},"sidebar":"adrSidebar","previous":{"title":"Product/Feature Sharding Strategy \u2022 ADR-034","permalink":"/prism-data-layer/adr/adr-034"},"next":{"title":"Local SQLite Storage for Namespace Configuration \u2022 ADR-036","permalink":"/prism-data-layer/adr/adr-036"}}');var o=i(74848),t=i(28453);const l={date:new Date("2025-10-08T00:00:00.000Z"),deciders:"System",doc_uuid:"0c2760b2-c974-4714-bf7f-07bc0e66c8fe",id:"adr-035",project_id:"prism-data-layer",status:"Proposed",tags:["performance","backend","reliability","architecture"],title:"Database Connection Pooling vs Direct Connections"},r=void 0,c={},a=[{value:"Context",id:"context",level:2},{value:"The Tradeoff",id:"the-tradeoff",level:3},{value:"Why This Matters at Scale",id:"why-this-matters-at-scale",level:3},{value:"Decision",id:"decision",level:2},{value:"Connection Pool Strategy Matrix",id:"connection-pool-strategy-matrix",level:3},{value:"Pool Configuration",id:"pool-configuration",level:3},{value:"Rationale",id:"rationale",level:2},{value:"PostgreSQL: Pool Essentials",id:"postgresql-pool-essentials",level:3},{value:"Redis: Pool for Pipelining",id:"redis-pool-for-pipelining",level:3},{value:"Kafka: Producer Pooling",id:"kafka-producer-pooling",level:3},{value:"NATS: Single Connection",id:"nats-single-connection",level:3},{value:"Object Storage: Client-Level Pooling",id:"object-storage-client-level-pooling",level:3},{value:"Alternatives Considered",id:"alternatives-considered",level:2},{value:"1. Direct Connections (No Pooling)",id:"1-direct-connections-no-pooling",level:3},{value:"2. Thread-Local Connections",id:"2-thread-local-connections",level:3},{value:"3. Per-Request Connection with Caching",id:"3-per-request-connection-with-caching",level:3},{value:"Consequences",id:"consequences",level:2},{value:"Positive",id:"positive",level:3},{value:"Negative",id:"negative",level:3},{value:"Neutral",id:"neutral",level:3},{value:"Implementation Notes",id:"implementation-notes",level:2},{value:"PostgreSQL Pool Implementation (Using deadpool-postgres)",id:"postgresql-pool-implementation-using-deadpool-postgres",level:3},{value:"Health Checks",id:"health-checks",level:3},{value:"Pool Metrics",id:"pool-metrics",level:3},{value:"Configuration Tuning Guidance",id:"configuration-tuning-guidance",level:3}];function d(e){const n={code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,o.jsxs)(n.p,{children:["Prism's backend plugins need to connect to data stores (PostgreSQL, Redis, ClickHouse, etc.). Each plugin must decide: ",(0,o.jsx)(n.strong,{children:"use connection pooling or direct connections per request"}),"?"]}),"\n",(0,o.jsx)(n.h3,{id:"the-tradeoff",children:"The Tradeoff"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Connection Pooling"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Pre-established connections reused across requests"}),"\n",(0,o.jsx)(n.li,{children:"Lower latency (no TCP handshake + auth per request)"}),"\n",(0,o.jsx)(n.li,{children:"Fixed resource usage (pool size limits)"}),"\n",(0,o.jsx)(n.li,{children:"Complexity: pool management, health checks, stale connection handling"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Direct Connections"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"New connection per request"}),"\n",(0,o.jsx)(n.li,{children:"Higher latency (TCP + TLS + auth overhead: ~5-50ms)"}),"\n",(0,o.jsx)(n.li,{children:"Unbounded resource usage (connections scale with request rate)"}),"\n",(0,o.jsx)(n.li,{children:"Simplicity: no pool management needed"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"why-this-matters-at-scale",children:"Why This Matters at Scale"}),"\n",(0,o.jsx)(n.p,{children:"From Netflix's experience at 8M QPS:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Connection churn"})," kills performance at scale"]}),"\n",(0,o.jsx)(n.li,{children:"PostgreSQL max_connections: typically 100-200 (too low for high concurrency)"}),"\n",(0,o.jsx)(n.li,{children:"Redis benefits from persistent connections (pipelining, reduced latency)"}),"\n",(0,o.jsx)(n.li,{children:"But: connection pools can become bottlenecks if undersized"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"decision",children:"Decision"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Use connection pooling by default for all backends"}),", with backend-specific tuning:"]}),"\n",(0,o.jsx)(n.h3,{id:"connection-pool-strategy-matrix",children:"Connection Pool Strategy Matrix"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Backend"}),(0,o.jsx)(n.th,{children:"Pool Type"}),(0,o.jsx)(n.th,{children:"Pool Size Formula"}),(0,o.jsx)(n.th,{children:"Rationale"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"PostgreSQL"})}),(0,o.jsx)(n.td,{children:"Shared pool per namespace"}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"max(10, RPS / 100)"})}),(0,o.jsx)(n.td,{children:"Expensive connections, limited max_connections"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Redis"})}),(0,o.jsx)(n.td,{children:"Shared pool per namespace"}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"max(5, RPS / 1000)"})}),(0,o.jsx)(n.td,{children:"Cheap connections, benefits from pipelining"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Kafka"})}),(0,o.jsx)(n.td,{children:"Producer pool"}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"max(3, num_partitions / 10)"})}),(0,o.jsx)(n.td,{children:"Producers are heavyweight, batching preferred"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"ClickHouse"})}),(0,o.jsx)(n.td,{children:"Shared pool per namespace"}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"max(5, RPS / 200)"})}),(0,o.jsx)(n.td,{children:"Query-heavy, benefits from persistent HTTP/2"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"NATS"})}),(0,o.jsx)(n.td,{children:"Single persistent connection"}),(0,o.jsxs)(n.td,{children:[(0,o.jsx)(n.code,{children:"1"})," per namespace"]}),(0,o.jsx)(n.td,{children:"Multiplexing over single connection"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Object Storage (S3/MinIO)"})}),(0,o.jsx)(n.td,{children:"No pool (HTTP client reuse)"}),(0,o.jsx)(n.td,{children:"N/A"}),(0,o.jsx)(n.td,{children:"HTTP client handles pooling internally"})]})]})]}),"\n",(0,o.jsx)(n.h3,{id:"pool-configuration",children:"Pool Configuration"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"# Per-backend pool settings\nbackends:\n  postgres:\n    pool:\n      min_size: 10\n      max_size: 100\n      idle_timeout: 300s  # Close idle connections after 5 min\n      max_lifetime: 1800s  # Recycle connections after 30 min\n      connection_timeout: 5s\n      health_check_interval: 30s\n\n  redis:\n    pool:\n      min_size: 5\n      max_size: 50\n      idle_timeout: 600s  # Redis connections are cheap to keep alive\n      max_lifetime: 3600s\n      connection_timeout: 2s\n      health_check_interval: 60s\n"})}),"\n",(0,o.jsx)(n.h2,{id:"rationale",children:"Rationale"}),"\n",(0,o.jsx)(n.h3,{id:"postgresql-pool-essentials",children:"PostgreSQL: Pool Essentials"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Why pool?"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"PostgreSQL connection cost: ~10-20ms (TCP + TLS + auth)"}),"\n",(0,o.jsx)(n.li,{children:"At 1000 RPS \u2192 10-20 seconds of CPU wasted per second (unsustainable)"}),"\n",(0,o.jsxs)(n.li,{children:["PostgreSQL's ",(0,o.jsx)(n.code,{children:"max_connections"})," limit (often 100-200) too low for direct per-request"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sizing"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Rule of thumb: ",(0,o.jsx)(n.code,{children:"pool_size = (total_requests_per_second * avg_query_duration) / num_proxy_instances"})]}),"\n",(0,o.jsx)(n.li,{children:"Example: 5000 RPS * 0.005s avg query / 5 instances = 5 connections per instance"}),"\n",(0,o.jsx)(n.li,{children:"Add buffer for spikes: 5 * 2 = 10 connections"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gotchas"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Postgres transaction state: ensure proper ",(0,o.jsx)(n.code,{children:"BEGIN/COMMIT"})," handling"]}),"\n",(0,o.jsxs)(n.li,{children:["Connection reuse: always ",(0,o.jsx)(n.code,{children:"ROLLBACK"})," on error to clean state"]}),"\n",(0,o.jsx)(n.li,{children:"Prepared statements: cache per connection for efficiency"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"redis-pool-for-pipelining",children:"Redis: Pool for Pipelining"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Why pool?"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Redis connection cost: ~1-2ms (cheap, but adds up)"}),"\n",(0,o.jsx)(n.li,{children:"Pipelining benefits: batch multiple commands over single connection"}),"\n",(0,o.jsx)(n.li,{children:"At 10K RPS \u2192 1 connection can handle 100K RPS with pipelining"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sizing"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Much smaller pools than PostgreSQL (Redis is single-threaded per instance)"}),"\n",(0,o.jsx)(n.li,{children:"More connections don't help unless sharding across Redis instances"}),"\n",(0,o.jsx)(n.li,{children:"Example: 50K RPS \u2192 5-10 connections sufficient"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"kafka-producer-pooling",children:"Kafka: Producer Pooling"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Why pool producers?"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"KafkaProducer is heavyweight (metadata fetching, batching logic)"}),"\n",(0,o.jsx)(n.li,{children:"Creating per-request is extremely inefficient"}),"\n",(0,o.jsx)(n.li,{children:"One producer can handle 10K+ messages/sec"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sizing"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Typically 1-3 producers per partition"}),"\n",(0,o.jsx)(n.li,{children:"Example: 10 partitions \u2192 3 producers (round-robin)"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Key insight"}),": Kafka producers do internal batching, so pooling amplifies efficiency."]}),"\n",(0,o.jsx)(n.h3,{id:"nats-single-connection",children:"NATS: Single Connection"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Why not pool?"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"NATS protocol supports multiplexing over single connection"}),"\n",(0,o.jsx)(n.li,{children:"Creating multiple connections adds no benefit (and wastes resources)"}),"\n",(0,o.jsx)(n.li,{children:"NATS client libraries handle this internally"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Configuration"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:"// Single NATS connection per namespace\nlet nats_client = nats::connect(&config.connection_string).await?;\n// All requests multiplex over this connection\n"})}),"\n",(0,o.jsx)(n.h3,{id:"object-storage-client-level-pooling",children:"Object Storage: Client-Level Pooling"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Why not explicit pool?"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"HTTP clients (reqwest, hyper) handle connection pooling internally"}),"\n",(0,o.jsx)(n.li,{children:"S3 API is stateless, no transaction semantics"}),"\n",(0,o.jsx)(n.li,{children:"Client library's default pooling is usually optimal"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Configuration"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:"// HTTP client with built-in connection pool\nlet s3_client = aws_sdk_s3::Client::from_conf(\n    aws_sdk_s3::config::Builder::new()\n        .http_client(\n            aws_smithy_runtime::client::http::hyper_014::HyperClientBuilder::new()\n                .build_https()  // Uses hyper's connection pool\n        )\n        .build()\n);\n"})}),"\n",(0,o.jsx)(n.h2,{id:"alternatives-considered",children:"Alternatives Considered"}),"\n",(0,o.jsx)(n.h3,{id:"1-direct-connections-no-pooling",children:"1. Direct Connections (No Pooling)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:"// Create new connection per request\npub async fn execute(&self, req: ExecuteRequest) -> Result<ExecuteResponse> {\n    let conn = PostgresConnection::connect(&self.config).await?;  // 10-20ms overhead!\n    let result = conn.query(&req.query).await?;\n    Ok(result)\n}\n"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pros"}),": Simple, no pool management, no connection reuse bugs"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cons"}),": Terrible performance (10-20ms overhead per request), exhausts ",(0,o.jsx)(n.code,{children:"max_connections"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Rejected because"}),": Unsustainable at any meaningful scale"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"2-thread-local-connections",children:"2. Thread-Local Connections"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pros"}),": No contention, one connection per thread"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cons"}),": Doesn't work with async (threads != tasks), wastes connections"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Rejected because"}),": Incompatible with tokio async model"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"3-per-request-connection-with-caching",children:"3. Per-Request Connection with Caching"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pros"}),": Automatic pooling via LRU cache"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cons"}),": Complex TTL management, unclear ownership, health check challenges"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Rejected because"}),": Reinventing connection pooling poorly"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"consequences",children:"Consequences"}),"\n",(0,o.jsx)(n.h3,{id:"positive",children:"Positive"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"10-100x latency improvement"})," vs direct connections (no TCP handshake per request)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Resource efficiency"}),": Fixed connection count prevents database overload"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Predictable performance"}),": Pool size controls max concurrency"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Backend protection"}),": Prevents stampeding herd from overwhelming databases"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"negative",children:"Negative"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Stale connections"}),": Need health checks and recycling"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pool exhaustion"}),": If pool too small, requests queue (but better than overwhelming DB)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Complex configuration"}),": Need to tune pool sizes per workload"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Connection state"}),": Must ensure clean state between reuses (transactions, temp tables)"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"neutral",children:"Neutral"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Warm-up time"}),": Pools need to fill on startup (min_size connections created)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Monitoring"}),": Need metrics on pool utilization, wait times, health check failures"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Graceful shutdown"}),": Must drain pools cleanly on shutdown"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"implementation-notes",children:"Implementation Notes"}),"\n",(0,o.jsx)(n.h3,{id:"postgresql-pool-implementation-using-deadpool-postgres",children:"PostgreSQL Pool Implementation (Using deadpool-postgres)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:"use deadpool_postgres::{Config, Pool, Runtime};\n\npub struct PostgresPlugin {\n    pool: Pool,\n}\n\nimpl PostgresPlugin {\n    pub async fn new(config: PostgresConfig) -> Result<Self> {\n        let mut cfg = Config::new();\n        cfg.url = Some(config.connection_string);\n        cfg.pool = Some(deadpool::managed::PoolConfig {\n            max_size: config.pool_max_size,\n            timeouts: deadpool::managed::Timeouts {\n                wait: Some(Duration::from_secs(5)),\n                create: Some(Duration::from_secs(5)),\n                recycle: Some(Duration::from_secs(1)),\n            },\n        });\n\n        let pool = cfg.create_pool(Some(Runtime::Tokio1))?;\n\n        Ok(Self { pool })\n    }\n\n    pub async fn execute(&self, req: ExecuteRequest) -> Result<ExecuteResponse> {\n        // Get connection from pool (blocks if pool exhausted)\n        let conn = self.pool.get().await?;\n\n        // Execute query\n        let rows = conn.query(&req.query, &req.params).await?;\n\n        // Connection automatically returned to pool when dropped\n        Ok(ExecuteResponse::from_rows(rows))\n    }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"health-checks",children:"Health Checks"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:'// Periodic health check removes stale connections\nasync fn health_check_loop(pool: Pool) {\n    let mut interval = tokio::time::interval(Duration::from_secs(30));\n\n    loop {\n        interval.tick().await;\n\n        // Test a connection\n        match pool.get().await {\n            Ok(conn) => {\n                if let Err(e) = conn.simple_query("SELECT 1").await {\n                    warn!("Pool health check failed: {}", e);\n                    // Pool will recreate connection on next checkout\n                }\n            }\n            Err(e) => {\n                error!("Failed to get connection for health check: {}", e);\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"pool-metrics",children:"Pool Metrics"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-rust",children:'// Expose pool metrics to Prometheus\npub fn record_pool_metrics(pool: &Pool, namespace: &str, backend: &str) {\n    let status = pool.status();\n\n    metrics::gauge!("prism_pool_size", status.size as f64,\n        "namespace" => namespace, "backend" => backend);\n\n    metrics::gauge!("prism_pool_available", status.available as f64,\n        "namespace" => namespace, "backend" => backend);\n\n    metrics::gauge!("prism_pool_waiting", status.waiting as f64,\n        "namespace" => namespace, "backend" => backend);\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"configuration-tuning-guidance",children:"Configuration Tuning Guidance"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Start with conservative sizes"}),":\npool_size = max(min_size, expected_p99_rps * p99_query_latency_seconds)"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"\n**Example**:\n- Expected P99 RPS: 1000\n- P99 query latency: 50ms = 0.05s\n- Pool size: max(10, 1000 * 0.05) = 50 connections\n\n**Monitor and adjust**:\n- If `pool_waiting` metric > 0: pool too small, increase size\n- If `pool_available` always ~= `pool_size`: pool too large, decrease size\n- If connection errors spike: check database `max_connections` limit\n\n## References\n\n- [PostgreSQL Connection Pooling Best Practices](https://www.postgresql.org/docs/current/runtime-config-connection.html)\n- [Redis Pipelining](https://redis.io/docs/manual/pipelining/)\n- [HikariCP (Java) Connection Pool Sizing](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)\n- RFC-008: Proxy Plugin Architecture (where pools live)\n- [deadpool-postgres Documentation](https://docs.rs/deadpool-postgres/)\n\n## Revision History\n\n- 2025-10-08: Initial draft with backend-specific pooling strategies\n\n"})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);