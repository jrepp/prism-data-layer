"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[39205],{28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var t=s(96540);const i={},r=t.createContext(i);function a(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:n},e.children)}},69195:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"rfc-008","title":"Proxy Plugin Architecture","description":"Status: Draft","source":"@site/../docs-cms/rfcs/rfc-008-proxy-plugin-architecture.md","sourceDirName":".","slug":"/rfc-008","permalink":"/prism-data-layer/rfc/rfc-008","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/rfcs/rfc-008-proxy-plugin-architecture.md","tags":[],"version":"current","frontMatter":{"author":"System","created":"2025-10-08T00:00:00.000Z","doc_uuid":"3ec5e869-7c96-47af-a3b0-f69e27696900","id":"rfc-008","project_id":"prism-data-layer","sidebar_label":"RFC-008 Plugin Architecture","status":"Draft","title":"Proxy Plugin Architecture"},"sidebar":"rfcSidebar","previous":{"title":"RFC-007 Cache Strategies","permalink":"/prism-data-layer/rfc/rfc-007"},"next":{"title":"Distributed Reliability Data Patterns \u2022 RFC-009","permalink":"/prism-data-layer/rfc/rfc-009"}}');var i=s(74848),r=s(28453);const a={author:"System",created:new Date("2025-10-08T00:00:00.000Z"),doc_uuid:"3ec5e869-7c96-47af-a3b0-f69e27696900",id:"rfc-008",project_id:"prism-data-layer",sidebar_label:"RFC-008 Plugin Architecture",status:"Draft",title:"Proxy Plugin Architecture"},l="RFC-008: Proxy Plugin Architecture and Responsibility Separation",c={},o=[{value:"Abstract",id:"abstract",level:2},{value:"Motivation",id:"motivation",level:2},{value:"Current Challenges",id:"current-challenges",level:3},{value:"Desired State",id:"desired-state",level:3},{value:"Goals",id:"goals",level:2},{value:"Non-Goals",id:"non-goals",level:2},{value:"Responsibility Separation",id:"responsibility-separation",level:2},{value:"Proxy Core Responsibilities",id:"proxy-core-responsibilities",level:3},{value:"Backend Plugin Responsibilities",id:"backend-plugin-responsibilities",level:3},{value:"What Plugins Do NOT Do",id:"what-plugins-do-not-do",level:3},{value:"Plugin Interface",id:"plugin-interface",level:2},{value:"gRPC-Based Plugin Protocol",id:"grpc-based-plugin-protocol",level:3},{value:"Architecture Diagram",id:"architecture-diagram",level:2},{value:"Zero-Copy Proxying and Performance",id:"zero-copy-proxying-and-performance",level:2},{value:"Zero-Copy Data Path",id:"zero-copy-data-path",level:3},{value:"gRPC Rust Efficiency",id:"grpc-rust-efficiency",level:3},{value:"When Zero-Copy Matters",id:"when-zero-copy-matters",level:3},{value:"Plugin Deployment Models",id:"plugin-deployment-models",level:2},{value:"Recommended Default: Out-of-Process (Sidecar)",id:"recommended-default-out-of-process-sidecar",level:3},{value:"Model 1: In-Process Plugins (Shared Library)",id:"model-1-in-process-plugins-shared-library",level:3},{value:"Model 2: Sidecar Plugins (Separate Process)",id:"model-2-sidecar-plugins-separate-process",level:3},{value:"Model 3: Remote Plugins (External Service)",id:"model-3-remote-plugins-external-service",level:3},{value:"Secure Channels",id:"secure-channels",level:2},{value:"Channel Security Requirements",id:"channel-security-requirements",level:3},{value:"Unix Socket Security (Sidecar Model)",id:"unix-socket-security-sidecar-model",level:3},{value:"gRPC Channel Security (Remote Model)",id:"grpc-channel-security-remote-model",level:3},{value:"Configuration Flow",id:"configuration-flow",level:2},{value:"Proxy \u2192 Plugin Configuration",id:"proxy--plugin-configuration",level:3},{value:"Configuration Example",id:"configuration-example",level:3},{value:"Hot-Reloading Plugins",id:"hot-reloading-plugins",level:2},{value:"Reload Sequence",id:"reload-sequence",level:3},{value:"Reload Trigger",id:"reload-trigger",level:3},{value:"Metrics and Observability",id:"metrics-and-observability",level:2},{value:"Plugin-Reported Metrics",id:"plugin-reported-metrics",level:3},{value:"Proxy Aggregation",id:"proxy-aggregation",level:3},{value:"Testing Strategy",id:"testing-strategy",level:2},{value:"Plugin Testing",id:"plugin-testing",level:3},{value:"Integration Testing with Mock Proxy",id:"integration-testing-with-mock-proxy",level:3},{value:"Plugin Acceptance Test Framework",id:"plugin-acceptance-test-framework",level:2},{value:"Overview",id:"overview",level:3},{value:"Test Framework Architecture",id:"test-framework-architecture",level:3},{value:"Reusable Authentication Test Suite",id:"reusable-authentication-test-suite",level:3},{value:"Per-Backend Verification Tests",id:"per-backend-verification-tests",level:3},{value:"Test Backend Lifecycle Management",id:"test-backend-lifecycle-management",level:3},{value:"Running Acceptance Tests",id:"running-acceptance-tests",level:3}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",initializeresponse:"initializeresponse",li:"li",mermaid:"mermaid",myconfig:"myconfig",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"rfc-008-proxy-plugin-architecture-and-responsibility-separation",children:"RFC-008: Proxy Plugin Architecture and Responsibility Separation"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Status"}),": Draft\n",(0,i.jsx)(n.strong,{children:"Author"}),": System\n",(0,i.jsx)(n.strong,{children:"Created"}),": 2025-10-08\n",(0,i.jsx)(n.strong,{children:"Updated"}),": 2025-10-08"]}),"\n",(0,i.jsx)(n.h2,{id:"abstract",children:"Abstract"}),"\n",(0,i.jsxs)(n.p,{children:["This RFC defines the architectural separation between Prism's ",(0,i.jsx)(n.strong,{children:"proxy core"})," (minimal, stable, generic) and ",(0,i.jsx)(n.strong,{children:"backend plugins"})," (specialized, extensible, data-source-specific). By reducing the proxy's surface area and offloading backend-specific logic to plugins, we achieve:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Minimal Proxy Core"}),": Handles networking, configuration, authentication, observability"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backend Plugins"}),": Implement data-source-specific protocols via secure channels"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Clear Boundaries"}),": Plugins receive configuration, credentials, and tunneled connections"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Extensibility"}),": Add new backends without modifying proxy core"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Security"}),": Plugins operate in isolated contexts with limited capabilities"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["The proxy becomes a ",(0,i.jsx)(n.strong,{children:"lightweight orchestrator"})," that tunnels traffic to specialized shims, rather than a monolithic component that understands every backend protocol."]}),"\n",(0,i.jsx)(n.h2,{id:"motivation",children:"Motivation"}),"\n",(0,i.jsx)(n.h3,{id:"current-challenges",children:"Current Challenges"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Monolithic Proxy Problem"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Proxy must understand Kafka, NATS, PostgreSQL, Redis, ClickHouse, MinIO protocols"}),"\n",(0,i.jsx)(n.li,{children:"Each backend adds complexity to proxy codebase"}),"\n",(0,i.jsx)(n.li,{children:"Testing matrix grows combinatorially (N backends \xd7 M features)"}),"\n",(0,i.jsx)(n.li,{children:"Deployment coupling: Backend changes require proxy redeployment"}),"\n",(0,i.jsx)(n.li,{children:"Security surface: Proxy vulnerabilities affect all backends"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"desired-state",children:"Desired State"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Plugin-Based Architecture"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Proxy knows only about gRPC, HTTP/2, auth, config, metrics"}),"\n",(0,i.jsxs)(n.li,{children:["Backends implemented as ",(0,i.jsx)(n.strong,{children:"plugins"})," (WASM, native shared libraries, or sidecar processes)"]}),"\n",(0,i.jsxs)(n.li,{children:["Proxy provides ",(0,i.jsx)(n.strong,{children:"secure channels"})," to plugins (mTLS, Unix sockets, gRPC streams)"]}),"\n",(0,i.jsx)(n.li,{children:"Plugins handle backend-specific logic (connection pooling, query translation, caching)"}),"\n",(0,i.jsx)(n.li,{children:"Plugins receive configuration but don't manage it"}),"\n",(0,i.jsx)(n.li,{children:"Plugins report metrics but don't aggregate them"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"goals",children:"Goals"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Define clear responsibilities for proxy vs. plugins"}),"\n",(0,i.jsx)(n.li,{children:"Establish plugin interface (gRPC-based, extensible)"}),"\n",(0,i.jsx)(n.li,{children:"Support multiple plugin deployment models (in-process, sidecar, remote)"}),"\n",(0,i.jsx)(n.li,{children:"Enable hot-reloading of plugins without proxy restart"}),"\n",(0,i.jsx)(n.li,{children:"Maintain security isolation between proxy and plugins"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"non-goals",children:"Non-Goals"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Not replacing existing backends"}),": Existing backends can be wrapped as plugins"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Not a full plugin ecosystem"}),": Focus on Prism-maintained plugins initially"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Not supporting arbitrary code"}),": Plugins must conform to secure interface"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"responsibility-separation",children:"Responsibility Separation"}),"\n",(0,i.jsx)(n.h3,{id:"proxy-core-responsibilities",children:"Proxy Core Responsibilities"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Responsibility"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Network Termination"})}),(0,i.jsx)(n.td,{children:"Accept gRPC/HTTP connections from clients"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Authentication"})}),(0,i.jsx)(n.td,{children:"Validate mTLS certificates, OAuth2 tokens"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Authorization"})}),(0,i.jsx)(n.td,{children:"Enforce namespace-level access control"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Configuration Management"})}),(0,i.jsx)(n.td,{children:"Load, validate, distribute namespace configs to plugins"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Routing"})}),(0,i.jsx)(n.td,{children:"Route requests to appropriate backend plugins"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Observability"})}),(0,i.jsx)(n.td,{children:"Collect metrics, traces, logs from plugins"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Health Checking"})}),(0,i.jsx)(n.td,{children:"Monitor plugin health, restart on failure"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Rate Limiting"})}),(0,i.jsx)(n.td,{children:"Apply namespace-level rate limits"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Circuit Breaking"})}),(0,i.jsx)(n.td,{children:"Prevent cascading failures across plugins"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"backend-plugin-responsibilities",children:"Backend Plugin Responsibilities"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Responsibility"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Protocol Implementation"})}),(0,i.jsx)(n.td,{children:"Implement backend-specific wire protocols"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Connection Pooling"})}),(0,i.jsx)(n.td,{children:"Manage connections to backend (e.g., PostgreSQL pool)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Query Translation"})}),(0,i.jsx)(n.td,{children:"Translate generic requests to backend-specific queries"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Caching Logic"})}),(0,i.jsx)(n.td,{children:"Implement cache strategies (see RFC-007)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Error Handling"})}),(0,i.jsx)(n.td,{children:"Map backend errors to gRPC status codes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Schema Management"})}),(0,i.jsx)(n.td,{children:"Create tables, indexes, buckets as needed"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Performance Optimization"})}),(0,i.jsx)(n.td,{children:"Backend-specific optimizations (batching, pipelining)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Metrics Reporting"})}),(0,i.jsx)(n.td,{children:"Report plugin-level metrics to proxy"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"what-plugins-do-not-do",children:"What Plugins Do NOT Do"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No Configuration Storage"}),": Proxy provides config; plugins consume it"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No Authentication"}),": Proxy authenticates clients; plugins trust proxy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No Direct Client Access"}),": Clients always go through proxy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No Cross-Plugin Communication"}),": Plugins are isolated"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No Global State"}),": Plugins operate per-namespace"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"plugin-interface",children:"Plugin Interface"}),"\n",(0,i.jsx)(n.h3,{id:"grpc-based-plugin-protocol",children:"gRPC-Based Plugin Protocol"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:'syntax = "proto3";\n\npackage prism.plugin;\n\n// Backend Plugin Service (implemented by plugins)\nservice BackendPlugin {\n  // Initialize plugin with configuration\n  rpc Initialize(InitializeRequest) returns (InitializeResponse);\n\n  // Health check\n  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);\n\n  // Execute operation (generic interface)\n  rpc Execute(ExecuteRequest) returns (ExecuteResponse);\n\n  // Stream operations (for subscriptions, long-polls)\n  rpc ExecuteStream(stream StreamRequest) returns (stream StreamResponse);\n\n  // Shutdown gracefully\n  rpc Shutdown(ShutdownRequest) returns (ShutdownResponse);\n}\n\n// Plugin initialization\nmessage InitializeRequest {\n  string namespace = 1;\n  string backend_type = 2;  // "postgres", "redis", "kafka", etc.\n\n  // Backend-specific configuration (protobuf Any for type-safety, or bytes for zero-copy)\n  // Using google.protobuf.Any allows strongly-typed config while maintaining extensibility\n  google.protobuf.Any config = 3;\n\n  // Credentials (encrypted in transit)\n  map<string, string> credentials = 4;\n\n  // Proxy capabilities\n  ProxyCapabilities capabilities = 5;\n}\n\nmessage InitializeResponse {\n  bool success = 1;\n  string error = 2;\n\n  // Plugin metadata\n  string plugin_version = 3;\n  repeated string supported_operations = 4;\n}\n\n// Generic execute request\nmessage ExecuteRequest {\n  string operation = 1;  // "get", "set", "query", "subscribe", etc.\n\n  // Operation-specific parameters (protobuf Any for type-safety, bytes for zero-copy)\n  // Using bytes enables zero-copy optimization for large payloads (e.g., object storage)\n  oneof params {\n    google.protobuf.Any typed_params = 2;  // Strongly-typed parameters\n    bytes raw_params = 3;                   // Zero-copy binary data\n  }\n\n  // Request metadata (trace ID, user ID, etc.)\n  map<string, string> metadata = 4;\n}\n\nmessage ExecuteResponse {\n  bool success = 1;\n  string error = 2;\n  int32 error_code = 3;\n\n  // Response data (protobuf Any for type-safety, bytes for zero-copy)\n  oneof result {\n    google.protobuf.Any typed_result = 4;  // Strongly-typed response\n    bytes raw_result = 5;                   // Zero-copy binary data\n  }\n\n  // Plugin metrics\n  PluginMetrics metrics = 6;\n}\n\n// Streaming for subscriptions, long-running queries\nmessage StreamRequest {\n  string operation = 1;\n\n  oneof params {\n    google.protobuf.Any typed_params = 2;\n    bytes raw_params = 3;\n  }\n}\n\nmessage StreamResponse {\n  oneof result {\n    google.protobuf.Any typed_result = 1;\n    bytes raw_result = 2;\n  }\n  bool is_final = 3;\n}\n\n// Health check\nmessage HealthCheckRequest {\n  // Optional: check specific backend connection\n  optional string connection_id = 1;\n}\n\nmessage HealthCheckResponse {\n  enum Status {\n    HEALTHY = 0;\n    DEGRADED = 1;\n    UNHEALTHY = 2;\n  }\n  Status status = 1;\n  string message = 2;\n  map<string, string> details = 3;\n}\n\n// Plugin metrics (reported to proxy)\n// Cache metrics are interval-based: counters accumulate since last fetch, then reset\n// This enables accurate rate calculation without client-side state tracking\nmessage PluginMetrics {\n  int64 requests_total = 1;\n  int64 requests_failed = 2;\n  double latency_ms = 3;\n  int64 connections_active = 4;\n\n  // Cache metrics (interval-based: reset on fetch)\n  // Proxy fetches these periodically (e.g., every 10s), calculates hit rate,\n  // then plugin resets counters to zero for next interval\n  int64 cache_hits = 5;\n  int64 cache_misses = 6;\n\n  // Timestamp when plugin started tracking this interval (UTC nanoseconds)\n  int64 interval_start_ns = 7;\n}\n\n// Proxy capabilities (what proxy can do for plugins)\nmessage ProxyCapabilities {\n  bool supports_metrics_push = 1;\n  bool supports_distributed_tracing = 2;\n  bool supports_hot_reload = 3;\n  string proxy_version = 4;\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"architecture-diagram",children:"Architecture Diagram"}),"\n",(0,i.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Client Layer"\n        Client1[Client App 1]\n        Client2[Client App 2]\n    end\n\n    subgraph "Prism Proxy Core"\n        GRPCServer[gRPC Server<br/>Port 50051]\n        Auth[Authentication<br/>mTLS / OAuth2]\n        Router[Request Router<br/>Namespace \u2192 Plugin]\n        ConfigMgr[Config Manager<br/>Namespace Configs]\n        Metrics[Metrics Aggregator<br/>Prometheus]\n        HealthMgr[Health Manager<br/>Plugin Monitoring]\n    end\n\n    subgraph "Backend Plugins (In-Process)"\n        PGPlugin[PostgreSQL Plugin]\n        RedisPlugin[Redis Plugin]\n    end\n\n    subgraph "Backend Plugins (Sidecar)"\n        KafkaPlugin[Kafka Plugin<br/>Sidecar Process]\n        ClickHousePlugin[ClickHouse Plugin<br/>Sidecar Process]\n    end\n\n    subgraph "Data Sources"\n        Postgres[(PostgreSQL)]\n        Redis[(Redis)]\n        Kafka[(Kafka)]\n        ClickHouse[(ClickHouse)]\n    end\n\n    Client1 --\x3e|gRPC| GRPCServer\n    Client2 --\x3e|gRPC| GRPCServer\n    GRPCServer --\x3e Auth\n    Auth --\x3e Router\n    Router --\x3e ConfigMgr\n\n    Router --\x3e|Secure Channel| PGPlugin\n    Router --\x3e|Secure Channel| RedisPlugin\n    Router --\x3e|Unix Socket| KafkaPlugin\n    Router --\x3e|gRPC| ClickHousePlugin\n\n    PGPlugin --\x3e Postgres\n    RedisPlugin --\x3e Redis\n    KafkaPlugin --\x3e Kafka\n    ClickHousePlugin --\x3e ClickHouse\n\n    PGPlugin -.Metrics.-> Metrics\n    RedisPlugin -.Metrics.-> Metrics\n    KafkaPlugin -.Metrics.-> Metrics\n    ClickHousePlugin -.Metrics.-> Metrics\n\n    HealthMgr -.Health Check.-> PGPlugin\n    HealthMgr -.Health Check.-> RedisPlugin\n    HealthMgr -.Health Check.-> KafkaPlugin\n    HealthMgr -.Health Check.-> ClickHousePlugin'}),"\n",(0,i.jsx)(n.h2,{id:"zero-copy-proxying-and-performance",children:"Zero-Copy Proxying and Performance"}),"\n",(0,i.jsx)(n.h3,{id:"zero-copy-data-path",children:"Zero-Copy Data Path"}),"\n",(0,i.jsxs)(n.p,{children:["The plugin architecture is designed to enable ",(0,i.jsx)(n.strong,{children:"zero-copy proxying"})," for large payloads:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// Zero-copy example: Object storage GET request\npub async fn handle_get(&self, req: &ExecuteRequest) -> Result<ExecuteResponse> {\n    // Extract key from protobuf without copying\n    let key = match &req.params {\n        Some(params::RawParams(bytes)) => bytes.as_ref(),  // No allocation\n        _ => return Err("Invalid params".into()),\n    };\n\n    // Fetch object from backend (e.g., MinIO, S3)\n    // Returns Arc<Bytes> for reference-counted, zero-copy sharing\n    let object_data: Arc<Bytes> = self.client.get_object(key).await?;\n\n    // Return data without copying - gRPC uses the same Arc<Bytes>\n    Ok(ExecuteResponse {\n        success: true,\n        result: Some(result::RawResult(object_data.as_ref().to_vec())),  // gRPC owns bytes\n        ..Default::default()\n    })\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"grpc-rust-efficiency",children:"gRPC Rust Efficiency"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Tonic"})," (gRPC Rust implementation) provides excellent zero-copy characteristics:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tokio Integration"}),": Uses ",(0,i.jsx)(n.code,{children:"Bytes"})," type for efficient buffer management"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Streaming"}),": Server-streaming enables chunked transfers without buffering"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Arc Sharing"}),": Reference-counted buffers avoid copies between proxy and plugin"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prost Encoding"}),": Efficient protobuf encoding with minimal allocations"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance Benchmarks"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"In-process plugin: ~0.1ms overhead vs direct backend call"}),"\n",(0,i.jsx)(n.li,{children:"Sidecar plugin (Unix socket): ~1-2ms overhead"}),"\n",(0,i.jsx)(n.li,{children:"Remote plugin (gRPC/mTLS): ~5-10ms overhead"}),"\n",(0,i.jsx)(n.li,{children:"Zero-copy path (>1MB payloads): Negligible overhead regardless of size"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"when-zero-copy-matters",children:"When Zero-Copy Matters"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"High-value use cases"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Object storage (S3, MinIO): Large blobs (1MB-100MB+)"}),"\n",(0,i.jsx)(n.li,{children:"Time-series data: Bulk exports, large query results"}),"\n",(0,i.jsx)(n.li,{children:"Graph queries: Subgraph exports, path traversals"}),"\n",(0,i.jsx)(n.li,{children:"Batch operations: Multi-get, bulk inserts"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Low-value use cases"})," (protobuf Any is fine):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"KeyValue operations: Small keys/values (<10KB)"}),"\n",(0,i.jsx)(n.li,{children:"Session management: Session tokens, metadata"}),"\n",(0,i.jsx)(n.li,{children:"Configuration updates: Namespace settings"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"plugin-deployment-models",children:"Plugin Deployment Models"}),"\n",(0,i.jsx)(n.h3,{id:"recommended-default-out-of-process-sidecar",children:"Recommended Default: Out-of-Process (Sidecar)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"For most backends, use sidecar deployment as the default"})," to maximize:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fault Isolation"}),": Plugin crashes don't affect proxy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Independent Scaling"}),": Scale plugins independently of proxy (e.g., compute-heavy ClickHouse aggregations)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Language Flexibility"}),": Implement plugins in Go, Python, Java without Rust FFI constraints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Security"}),": Process-level isolation limits blast radius"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"In-process should be reserved for"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ultra-low latency requirements (<1ms P99)"}),"\n",(0,i.jsx)(n.li,{children:"Backends with minimal dependencies (Redis, Memcached)"}),"\n",(0,i.jsx)(n.li,{children:"Mature, battle-tested libraries with proven stability"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"model-1-in-process-plugins-shared-library",children:"Model 1: In-Process Plugins (Shared Library)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use Case"}),": Low latency, high throughput backends (Redis, PostgreSQL)"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// Plugin loaded as dynamic library\npub struct RedisPlugin {\n    connection_pool: RedisConnectionPool,\n    config: RedisConfig,\n}\n\n// Plugin implements standard interface\nimpl BackendPlugin for RedisPlugin {\n    async fn initialize(&mut self, req: InitializeRequest) -> Result<InitializeResponse> {\n        // Decode protobuf Any to strongly-typed RedisConfig\n        self.config = req.config.unpack::<RedisConfig>()?;\n        self.connection_pool = RedisConnectionPool::new(&self.config).await?;\n\n        Ok(InitializeResponse {\n            success: true,\n            plugin_version: env!("CARGO_PKG_VERSION").to_string(),\n            supported_operations: vec!["get", "set", "delete", "mget"],\n            ..Default::default()\n        })\n    }\n\n    async fn execute(&self, req: ExecuteRequest) -> Result<ExecuteResponse> {\n        match req.operation.as_str() {\n            "get" => self.handle_get(&req).await,\n            "set" => self.handle_set(&req).await,\n            _ => Err(format!("Unsupported operation: {}", req.operation).into()),\n        }\n    }\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Lowest latency (no IPC overhead)"}),"\n",(0,i.jsx)(n.li,{children:"Shared memory access"}),"\n",(0,i.jsx)(n.li,{children:"Simplest deployment"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Plugin crash can crash proxy"}),"\n",(0,i.jsx)(n.li,{children:"Security: Plugin has proxy's memory access"}),"\n",(0,i.jsx)(n.li,{children:"Versioning: Plugin must be compatible with proxy ABI"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"model-2-sidecar-plugins-separate-process",children:"Model 2: Sidecar Plugins (Separate Process)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use Case"}),": Complex backends with large dependencies (Kafka, ClickHouse)"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# docker-compose.yml\nservices:\n  prism-proxy:\n    image: prism/proxy:latest\n    ports:\n      - "50051:50051"\n    volumes:\n      - /var/run/plugins:/var/run/plugins\n\n  kafka-plugin:\n    image: prism/kafka-plugin:latest\n    volumes:\n      - /var/run/plugins:/var/run/plugins\n    environment:\n      PLUGIN_SOCKET: /var/run/plugins/kafka.sock\n\n  clickhouse-plugin:\n    image: prism/clickhouse-plugin:latest\n    ports:\n      - "50100:50100"\n    environment:\n      PLUGIN_GRPC_PORT: 50100\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Communication"}),": Unix socket or gRPC over localhost"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Process isolation (plugin crash doesn't affect proxy)"}),"\n",(0,i.jsx)(n.li,{children:"Independent deployment and versioning"}),"\n",(0,i.jsx)(n.li,{children:"Different runtime (e.g., plugin in Python, proxy in Rust)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"IPC latency (~1-2ms)"}),"\n",(0,i.jsx)(n.li,{children:"More complex deployment"}),"\n",(0,i.jsx)(n.li,{children:"Resource overhead (separate process)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"model-3-remote-plugins-external-service",children:"Model 3: Remote Plugins (External Service)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use Case"}),": Proprietary backends, cloud-managed plugins"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Namespace config pointing to remote plugin\nnamespaces:\n  - name: custom-backend\n    backend: remote\n    plugin:\n      type: grpc\n      endpoint: "custom-plugin.example.com:50100"\n      tls:\n        enabled: true\n        ca_cert: /path/to/ca.pem\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Maximum isolation"}),"\n",(0,i.jsx)(n.li,{children:"Can run in different regions/clusters"}),"\n",(0,i.jsx)(n.li,{children:"Proprietary plugin implementations"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Network latency (10-50ms)"}),"\n",(0,i.jsx)(n.li,{children:"Requires network security (mTLS)"}),"\n",(0,i.jsx)(n.li,{children:"Higher operational complexity"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"secure-channels",children:"Secure Channels"}),"\n",(0,i.jsx)(n.h3,{id:"channel-security-requirements",children:"Channel Security Requirements"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Encryption"}),": All plugin communication encrypted (TLS, Unix sockets with permissions)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Authentication"}),": Proxy authenticates plugins (mTLS, shared secrets)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Authorization"}),": Plugins can only access their namespace's data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isolation"}),": Plugins cannot communicate with each other"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Audit"}),": All plugin calls logged with namespace/user context"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"unix-socket-security-sidecar-model",children:"Unix Socket Security (Sidecar Model)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// Proxy creates Unix socket with restricted permissions\nlet socket_path = "/var/run/plugins/postgres.sock";\nlet listener = UnixListener::bind(socket_path)?;\n\n// Set permissions: only proxy user can access\nstd::fs::set_permissions(socket_path, Permissions::from_mode(0o600))?;\n\n// Accept plugin connection\nlet (stream, _) = listener.accept().await?;\n\n// Wrap in secure channel\nlet secure_stream = SecureChannel::new(stream, ChannelSecurity::UnixSocket);\n'})}),"\n",(0,i.jsx)(n.h3,{id:"grpc-channel-security-remote-model",children:"gRPC Channel Security (Remote Model)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// mTLS configuration for remote plugin\nlet tls = ClientTlsConfig::new()\n    .ca_certificate(Certificate::from_pem(ca_cert))\n    .identity(Identity::from_pem(client_cert, client_key));\n\nlet channel = Channel::from_static("https://".to_string() + "plugin.example.com:50100")\n    .tls_config(tls)?\n    .connect()\n    .await?;\n\nlet plugin_client = BackendPluginClient::new(channel);\n'})}),"\n",(0,i.jsx)(n.h2,{id:"configuration-flow",children:"Configuration Flow"}),"\n",(0,i.jsx)(n.h3,{id:"proxy--plugin-configuration",children:"Proxy \u2192 Plugin Configuration"}),"\n",(0,i.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Proxy as Proxy Core\n    participant ConfigMgr as Config Manager\n    participant Plugin as PostgreSQL Plugin\n    participant Postgres as PostgreSQL DB\n\n    Note over Proxy,Postgres: Startup Sequence\n\n    Proxy->>ConfigMgr: Load namespace configs\n    ConfigMgr--\x3e>Proxy: Namespaces (user-profiles, etc.)\n\n    Proxy->>Plugin: Initialize(config, credentials)\n    activate Plugin\n    Plugin->>Postgres: Connect with credentials\n    Postgres--\x3e>Plugin: Connection established\n    Plugin--\x3e>Proxy: InitializeResponse(success=true)\n    deactivate Plugin\n\n    Note over Proxy,Postgres: Runtime Request\n\n    Proxy->>Plugin: Execute(operation="get", key="user:123")\n    activate Plugin\n    Plugin->>Postgres: SELECT * FROM users WHERE id=123\n    Postgres--\x3e>Plugin: User data\n    Plugin--\x3e>Proxy: ExecuteResponse(result=<data>)\n    deactivate Plugin'}),"\n",(0,i.jsx)(n.h3,{id:"configuration-example",children:"Configuration Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Namespace configuration (managed by proxy)\nnamespaces:\n  - name: user-profiles\n    backend: postgres\n    plugin:\n      type: in_process\n      library: libprism_postgres_plugin.so\n\n    # Backend-specific config (passed to plugin)\n    config:\n      connection_string: "postgres://user:pass@localhost:5432/prism"\n      pool_size: 20\n      idle_timeout: 300\n      statement_cache_size: 100\n\n    # Credentials (encrypted, passed to plugin securely)\n    credentials:\n      username: "prism_user"\n      password: "{{ secret:postgres_password }}"\n\n  - name: event-stream\n    backend: kafka\n    plugin:\n      type: sidecar\n      socket: /var/run/plugins/kafka.sock\n\n    config:\n      brokers:\n        - kafka-1:9092\n        - kafka-2:9092\n        - kafka-3:9092\n      topic_prefix: "prism_"\n      consumer_group: "prism-proxy"\n\n    credentials:\n      sasl_username: "prism"\n      sasl_password: "{{ secret:kafka_password }}"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"hot-reloading-plugins",children:"Hot-Reloading Plugins"}),"\n",(0,i.jsx)(n.h3,{id:"reload-sequence",children:"Reload Sequence"}),"\n",(0,i.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Admin as Admin CLI\n    participant Proxy as Proxy Core\n    participant OldPlugin as Old Plugin v1.2\n    participant NewPlugin as New Plugin v1.3\n    participant Backend as PostgreSQL\n\n    Admin->>Proxy: Reload plugin(namespace="user-profiles")\n    Proxy->>NewPlugin: Initialize(config, credentials)\n    NewPlugin->>Backend: Connect\n    Backend--\x3e>NewPlugin: Connected\n    NewPlugin--\x3e>Proxy: InitializeResponse(success=true)\n\n    Note over Proxy: Drain old plugin (no new requests)\n\n    OldPlugin->>Backend: Complete in-flight requests\n    Backend--\x3e>OldPlugin: Responses\n\n    Proxy->>OldPlugin: Shutdown()\n    OldPlugin->>Backend: Close connections\n    OldPlugin--\x3e>Proxy: ShutdownResponse\n\n    Proxy->>Proxy: Swap old \u2192 new plugin\n\n    Note over Proxy: New plugin handles all requests'}),"\n",(0,i.jsx)(n.h3,{id:"reload-trigger",children:"Reload Trigger"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Admin CLI triggers plugin reload\nprism plugin reload user-profiles --version v1.3\n\n# Or via API\ncurl -X POST https://proxy:50052/admin/plugin/reload \\\n  -d \'{"namespace": "user-profiles", "version": "v1.3"}\'\n'})}),"\n",(0,i.jsx)(n.h2,{id:"metrics-and-observability",children:"Metrics and Observability"}),"\n",(0,i.jsx)(n.h3,{id:"plugin-reported-metrics",children:"Plugin-Reported Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:"message PluginMetrics {\n  // Request metrics\n  int64 requests_total = 1;\n  int64 requests_failed = 2;\n  double latency_ms = 3;\n\n  // Backend metrics\n  int64 connections_active = 4;\n  int64 connections_idle = 5;\n  int64 queries_executed = 6;\n\n  // Cache metrics (if applicable)\n  int64 cache_hits = 7;\n  int64 cache_misses = 8;\n\n  // Custom backend-specific metrics (strongly-typed via protobuf Any)\n  google.protobuf.Any custom_metrics = 9;\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"proxy-aggregation",children:"Proxy Aggregation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// Proxy aggregates plugin metrics\npub struct MetricsAggregator {\n    plugin_metrics: HashMap<String, PluginMetrics>,\n}\n\nimpl MetricsAggregator {\n    pub fn record_plugin_metrics(&mut self, namespace: &str, metrics: PluginMetrics) {\n        // Store latest metrics\n        self.plugin_metrics.insert(namespace.to_string(), metrics);\n\n        // Export to Prometheus\n        metrics::gauge!("plugin_requests_total", metrics.requests_total as f64,\n            "namespace" => namespace);\n        metrics::gauge!("plugin_connections_active", metrics.connections_active as f64,\n            "namespace" => namespace);\n        // ...\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"testing-strategy",children:"Testing Strategy"}),"\n",(0,i.jsx)(n.h3,{id:"plugin-testing",children:"Plugin Testing"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_plugin_lifecycle() {\n        let mut plugin = PostgresPlugin::new();\n\n        // Initialize with strongly-typed config\n        let config = PostgresConfig {\n            connection_string: "postgres://localhost".to_string(),\n            ..Default::default()\n        };\n        let init_req = InitializeRequest {\n            namespace: "test".to_string(),\n            config: Some(Any::pack(&config)?),\n            ..Default::default()\n        };\n        let init_resp = plugin.initialize(init_req).await.unwrap();\n        assert!(init_resp.success);\n\n        // Execute with typed params\n        let params = GetRequest {\n            key: "test:123".to_string(),\n        };\n        let exec_req = ExecuteRequest {\n            operation: "get".to_string(),\n            params: Some(params::TypedParams(Any::pack(&params)?)),\n            ..Default::default()\n        };\n        let exec_resp = plugin.execute(exec_req).await.unwrap();\n        assert!(exec_resp.success);\n\n        // Shutdown\n        let shutdown_resp = plugin.shutdown(ShutdownRequest {}).await.unwrap();\n        assert!(shutdown_resp.success);\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"integration-testing-with-mock-proxy",children:"Integration Testing with Mock Proxy"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"// Mock proxy provides plugin interface\nstruct MockProxy {\n    config: NamespaceConfig,\n}\n\nimpl MockProxy {\n    async fn test_plugin(plugin: &dyn BackendPlugin) {\n        // Initialize plugin\n        plugin.initialize(...).await.unwrap();\n\n        // Run test scenarios\n        // ...\n\n        // Shutdown\n        plugin.shutdown(...).await.unwrap();\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"plugin-acceptance-test-framework",children:"Plugin Acceptance Test Framework"}),"\n",(0,i.jsx)(n.h3,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:["The Plugin Acceptance Test Framework provides a comprehensive suite of verification tests that ensure plugins correctly implement the ",(0,i.jsx)(n.code,{children:"BackendPlugin"})," interface and behave consistently across all backend types. This framework serves two critical purposes:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Per-Backend Type Verification"}),": Test each plugin implementation against real backend instances to verify correct protocol implementation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cross-Plugin Consistency"}),": Ensure all plugins handle common concerns (authentication, connection management, error handling) identically"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"test-framework-architecture",children:"Test Framework Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"// tests/acceptance/framework.rs\n\n/// Acceptance test harness that runs plugins against real backends\npub struct PluginAcceptanceHarness {\n    backend_type: BackendType,\n    backend_instance: Box<dyn TestBackend>,\n    plugin: Box<dyn BackendPlugin>,\n    test_config: TestConfig,\n}\n\nimpl PluginAcceptanceHarness {\n    /// Create harness for specific backend type\n    pub async fn new(backend_type: BackendType) -> Result<Self> {\n        let backend_instance = spawn_test_backend(backend_type).await?;\n        let plugin = load_plugin_for_backend(backend_type)?;\n\n        Ok(Self {\n            backend_type,\n            backend_instance,\n            plugin,\n            test_config: TestConfig::default(),\n        })\n    }\n\n    /// Run full acceptance test suite\n    pub async fn run_all_tests(&mut self) -> TestResults {\n        let mut results = TestResults::new();\n\n        // Core plugin lifecycle tests\n        results.add(self.test_initialize().await);\n        results.add(self.test_health_check().await);\n        results.add(self.test_shutdown().await);\n\n        // Authentication tests (reusable across all plugins)\n        results.add(self.run_authentication_suite().await);\n\n        // Backend-specific operation tests\n        results.add(self.run_backend_operations_suite().await);\n\n        // Error handling tests\n        results.add(self.test_error_scenarios().await);\n\n        // Performance baseline tests\n        results.add(self.test_performance_baseline().await);\n\n        results\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"reusable-authentication-test-suite",children:"Reusable Authentication Test Suite"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal"}),": Verify all plugins handle credential passing, authentication failures, and credential refresh identically."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// tests/acceptance/auth_suite.rs\n\n/// Reusable authentication test suite that works across all plugin types\npub struct AuthenticationTestSuite {\n    harness: Arc<PluginAcceptanceHarness>,\n}\n\nimpl AuthenticationTestSuite {\n    pub async fn run(&self) -> Vec<TestResult> {\n        vec![\n            self.test_valid_credentials().await,\n            self.test_invalid_credentials().await,\n            self.test_missing_credentials().await,\n            self.test_expired_credentials().await,\n            self.test_credential_rotation().await,\n            self.test_connection_pool_auth().await,\n        ]\n    }\n\n    /// Test plugin initializes successfully with valid credentials\n    async fn test_valid_credentials(&self) -> TestResult {\n        let init_req = InitializeRequest {\n            namespace: "test-auth".to_string(),\n            backend_type: self.harness.backend_type.to_string(),\n            config: self.harness.test_config.clone(),\n            credentials: hashmap! {\n                "username" => "test_user",\n                "password" => "test_pass",\n            },\n            ..Default::default()\n        };\n\n        let resp = self.harness.plugin.initialize(init_req).await;\n\n        TestResult::assert_ok(resp, "Plugin should initialize with valid credentials")\n    }\n\n    /// Test plugin fails gracefully with invalid credentials\n    async fn test_invalid_credentials(&self) -> TestResult {\n        let init_req = InitializeRequest {\n            namespace: "test-auth-invalid".to_string(),\n            backend_type: self.harness.backend_type.to_string(),\n            config: self.harness.test_config.clone(),\n            credentials: hashmap! {\n                "username" => "invalid_user",\n                "password" => "wrong_pass",\n            },\n            ..Default::default()\n        };\n\n        let resp = self.harness.plugin.initialize(init_req).await;\n\n        TestResult::assert_err(\n            resp,\n            "Plugin should reject invalid credentials",\n            ErrorCode::UNAUTHENTICATED\n        )\n    }\n\n    /// Test plugin handles missing credentials\n    async fn test_missing_credentials(&self) -> TestResult {\n        let init_req = InitializeRequest {\n            namespace: "test-auth-missing".to_string(),\n            backend_type: self.harness.backend_type.to_string(),\n            config: self.harness.test_config.clone(),\n            credentials: hashmap! {},  // Empty credentials\n            ..Default::default()\n        };\n\n        let resp = self.harness.plugin.initialize(init_req).await;\n\n        TestResult::assert_err(\n            resp,\n            "Plugin should detect missing credentials",\n            ErrorCode::INVALID_ARGUMENT\n        )\n    }\n\n    /// Test plugin handles credential expiration/rotation\n    async fn test_credential_rotation(&self) -> TestResult {\n        // Initialize with valid credentials\n        self.harness.plugin.initialize(valid_creds()).await?;\n\n        // Simulate credential rotation in backend\n        self.harness.backend_instance.rotate_credentials().await?;\n\n        // Execute operation - should fail with auth error\n        let exec_req = ExecuteRequest {\n            operation: "get".to_string(),\n            params: test_params(),\n            ..Default::default()\n        };\n\n        let resp = self.harness.plugin.execute(exec_req).await;\n\n        // Plugin should detect expired credentials\n        assert_eq!(resp.error_code, ErrorCode::UNAUTHENTICATED);\n\n        // Reinitialize with new credentials\n        self.harness.plugin.initialize(rotated_creds()).await?;\n\n        // Operation should now succeed\n        let resp = self.harness.plugin.execute(exec_req.clone()).await;\n        TestResult::assert_ok(resp, "Plugin should work after credential rotation")\n    }\n\n    /// Test connection pool handles authentication per-connection\n    async fn test_connection_pool_auth(&self) -> TestResult {\n        // Initialize plugin with pool size > 1\n        let init_req = InitializeRequest {\n            config: ConnectionPoolConfig {\n                pool_size: 5,\n                ..Default::default()\n            },\n            credentials: valid_creds(),\n            ..Default::default()\n        };\n\n        self.harness.plugin.initialize(init_req).await?;\n\n        // Execute multiple concurrent operations\n        let operations: Vec<_> = (0..10)\n            .map(|i| {\n                let plugin = self.harness.plugin.clone();\n                tokio::spawn(async move {\n                    plugin.execute(ExecuteRequest {\n                        operation: "get".to_string(),\n                        params: test_params_for_key(i),\n                        ..Default::default()\n                    }).await\n                })\n            })\n            .collect();\n\n        // All operations should succeed (each connection authenticated)\n        let results: Vec<_> = futures::future::join_all(operations).await;\n\n        TestResult::assert_all_ok(\n            results,\n            "All pooled connections should authenticate successfully"\n        )\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"per-backend-verification-tests",children:"Per-Backend Verification Tests"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal"}),": Verify each plugin correctly implements backend-specific protocols using actual backend instances."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// tests/acceptance/backend_verification.rs\n\n/// Backend-specific verification tests\npub trait BackendVerificationSuite {\n    async fn test_basic_operations(&self) -> Vec<TestResult>;\n    async fn test_error_handling(&self) -> Vec<TestResult>;\n    async fn test_concurrency(&self) -> Vec<TestResult>;\n    async fn test_backend_specific_features(&self) -> Vec<TestResult>;\n}\n\n/// PostgreSQL plugin verification\npub struct PostgresVerificationSuite {\n    harness: Arc<PluginAcceptanceHarness>,\n    postgres: PostgresTestInstance,\n}\n\nimpl BackendVerificationSuite for PostgresVerificationSuite {\n    async fn test_basic_operations(&self) -> Vec<TestResult> {\n        vec![\n            self.test_insert().await,\n            self.test_select().await,\n            self.test_update().await,\n            self.test_delete().await,\n            self.test_transaction().await,\n        ]\n    }\n\n    async fn test_backend_specific_features(&self) -> Vec<TestResult> {\n        vec![\n            self.test_prepared_statements().await,\n            self.test_json_types().await,\n            self.test_array_types().await,\n            self.test_listen_notify().await,\n        ]\n    }\n}\n\nimpl PostgresVerificationSuite {\n    async fn test_insert(&self) -> TestResult {\n        // Insert data via plugin\n        let exec_req = ExecuteRequest {\n            operation: "insert".to_string(),\n            params: InsertParams {\n                table: "users".to_string(),\n                data: json!({"id": 1, "name": "Alice"}),\n            },\n            ..Default::default()\n        };\n\n        let resp = self.harness.plugin.execute(exec_req).await?;\n\n        // Verify data exists in actual PostgreSQL instance\n        let row = self.postgres.query_one("SELECT * FROM users WHERE id = 1").await?;\n        assert_eq!(row.get::<_, String>("name"), "Alice");\n\n        TestResult::pass("PostgreSQL plugin correctly inserts data")\n    }\n\n    async fn test_prepared_statements(&self) -> TestResult {\n        // Execute same query multiple times\n        for i in 0..100 {\n            let exec_req = ExecuteRequest {\n                operation: "query".to_string(),\n                params: QueryParams {\n                    sql: "SELECT * FROM users WHERE id = $1".to_string(),\n                    params: vec![i.into()],\n                },\n                ..Default::default()\n            };\n\n            self.harness.plugin.execute(exec_req).await?;\n        }\n\n        // Verify plugin uses prepared statements (check metrics)\n        let metrics = self.harness.plugin.get_metrics().await?;\n        assert!(\n            metrics.prepared_statements_cached > 0,\n            "Plugin should cache prepared statements"\n        );\n\n        TestResult::pass("PostgreSQL plugin uses prepared statements")\n    }\n}\n\n/// Kafka plugin verification\npub struct KafkaVerificationSuite {\n    harness: Arc<PluginAcceptanceHarness>,\n    kafka: KafkaTestCluster,\n}\n\nimpl BackendVerificationSuite for KafkaVerificationSuite {\n    async fn test_basic_operations(&self) -> Vec<TestResult> {\n        vec![\n            self.test_produce().await,\n            self.test_consume().await,\n            self.test_subscribe().await,\n        ]\n    }\n\n    async fn test_backend_specific_features(&self) -> Vec<TestResult> {\n        vec![\n            self.test_partitioning().await,\n            self.test_consumer_groups().await,\n            self.test_exactly_once_semantics().await,\n            self.test_transactions().await,\n        ]\n    }\n}\n\nimpl KafkaVerificationSuite {\n    async fn test_produce(&self) -> TestResult {\n        // Produce message via plugin\n        let exec_req = ExecuteRequest {\n            operation: "produce".to_string(),\n            params: ProduceParams {\n                topic: "test-topic".to_string(),\n                key: "key1".to_string(),\n                value: b"test message".to_vec(),\n            },\n            ..Default::default()\n        };\n\n        let resp = self.harness.plugin.execute(exec_req).await?;\n\n        // Verify message in actual Kafka cluster\n        let consumer = self.kafka.create_consumer("test-group").await?;\n        consumer.subscribe(&["test-topic"]).await?;\n\n        let message = consumer.recv().await?;\n        assert_eq!(message.payload(), b"test message");\n\n        TestResult::pass("Kafka plugin correctly produces messages")\n    }\n\n    async fn test_consumer_groups(&self) -> TestResult {\n        // Create multiple consumers in same group\n        let consumers = vec![\n            self.create_plugin_consumer("group1").await?,\n            self.create_plugin_consumer("group1").await?,\n            self.create_plugin_consumer("group1").await?,\n        ];\n\n        // Produce 100 messages\n        for i in 0..100 {\n            self.produce_via_plugin(&format!("msg-{}", i)).await?;\n        }\n\n        // Each consumer should receive ~33 messages (partitioned)\n        let counts: Vec<_> = consumers.iter()\n            .map(|c| c.message_count())\n            .collect();\n\n        // Verify messages distributed across consumers\n        assert!(counts.iter().all(|&c| c > 20 && c < 50));\n\n        TestResult::pass("Kafka plugin correctly partitions messages across consumer group")\n    }\n}\n\n/// Redis plugin verification\npub struct RedisVerificationSuite {\n    harness: Arc<PluginAcceptanceHarness>,\n    redis: RedisTestInstance,\n}\n\nimpl BackendVerificationSuite for RedisVerificationSuite {\n    async fn test_basic_operations(&self) -> Vec<TestResult> {\n        vec![\n            self.test_get_set().await,\n            self.test_delete().await,\n            self.test_exists().await,\n            self.test_expire().await,\n        ]\n    }\n\n    async fn test_backend_specific_features(&self) -> Vec<TestResult> {\n        vec![\n            self.test_pub_sub().await,\n            self.test_lua_scripts().await,\n            self.test_pipelining().await,\n            self.test_transactions().await,\n        ]\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"test-backend-lifecycle-management",children:"Test Backend Lifecycle Management"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal"}),": Automatically spin up/tear down real backend instances for acceptance tests."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// tests/acceptance/test_backends.rs\n\n/// Trait for managing test backend instances\n#[async_trait]\npub trait TestBackend: Send + Sync {\n    async fn start(&mut self) -> Result<()>;\n    async fn stop(&mut self) -> Result<()>;\n    async fn reset(&mut self) -> Result<()>;\n    fn connection_config(&self) -> ConnectionConfig;\n    fn credentials(&self) -> Credentials;\n}\n\n/// Spawn test backend using Docker/Testcontainers\npub async fn spawn_test_backend(backend_type: BackendType) -> Result<Box<dyn TestBackend>> {\n    match backend_type {\n        BackendType::Postgres => Ok(Box::new(PostgresTestInstance::new().await?)),\n        BackendType::Redis => Ok(Box::new(RedisTestInstance::new().await?)),\n        BackendType::Kafka => Ok(Box::new(KafkaTestCluster::new().await?)),\n        BackendType::ClickHouse => Ok(Box::new(ClickHouseTestInstance::new().await?)),\n    }\n}\n\n/// PostgreSQL test instance using testcontainers\npub struct PostgresTestInstance {\n    container: Container<Postgres>,\n    connection_pool: PgPool,\n}\n\nimpl PostgresTestInstance {\n    pub async fn new() -> Result<Self> {\n        let container = Postgres::default()\n            .with_tag("16")\n            .with_env("POSTGRES_PASSWORD", "test")\n            .start()\n            .await?;\n\n        let connection_string = format!(\n            "postgres://postgres:test@localhost:{}",\n            container.get_host_port(5432).await?\n        );\n\n        let pool = PgPool::connect(&connection_string).await?;\n\n        // Initialize test schema\n        sqlx::query(\n            "CREATE TABLE IF NOT EXISTS users (\n                id SERIAL PRIMARY KEY,\n                name TEXT NOT NULL,\n                email TEXT UNIQUE\n            )"\n        )\n        .execute(&pool)\n        .await?;\n\n        Ok(Self {\n            container,\n            connection_pool: pool,\n        })\n    }\n\n    pub async fn query_one(&self, sql: &str) -> Result<PgRow> {\n        sqlx::query(sql).fetch_one(&self.connection_pool).await\n    }\n}\n\n#[async_trait]\nimpl TestBackend for PostgresTestInstance {\n    async fn start(&mut self) -> Result<()> {\n        // Container already started in new()\n        Ok(())\n    }\n\n    async fn stop(&mut self) -> Result<()> {\n        self.container.stop().await\n    }\n\n    async fn reset(&mut self) -> Result<()> {\n        // Truncate all tables\n        sqlx::query("TRUNCATE TABLE users RESTART IDENTITY CASCADE")\n            .execute(&self.connection_pool)\n            .await?;\n        Ok(())\n    }\n\n    fn connection_config(&self) -> ConnectionConfig {\n        ConnectionConfig {\n            host: "localhost".to_string(),\n            port: self.container.get_host_port_blocking(5432),\n            database: "postgres".to_string(),\n        }\n    }\n\n    fn credentials(&self) -> Credentials {\n        Credentials {\n            username: "postgres".to_string(),\n            password: "test".to_string(),\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"running-acceptance-tests",children:"Running Acceptance Tests"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Test organization"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"tests/\n\u251c\u2500\u2500 acceptance/\n\u2502   \u251c\u2500\u2500 framework.rs              # Test harness\n\u2502   \u251c\u2500\u2500 auth_suite.rs             # Reusable auth tests\n\u2502   \u251c\u2500\u2500 backend_verification.rs   # Per-backend test traits\n\u2502   \u251c\u2500\u2500 test_backends.rs          # Docker backend management\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 postgres_test.rs          # PostgreSQL acceptance tests\n\u2502   \u251c\u2500\u2500 redis_test.rs             # Redis acceptance tests\n\u2502   \u251c\u2500\u2500 kafka_test.rs             # Kafka acceptance tests\n\u2502   \u2514\u2500\u2500 clickhouse_test.rs        # ClickHouse acceptance tests\n\u2502\n\u2514\u2500\u2500 fixtures/\n    \u251c\u2500\u2500 test_data.sql              # Seed data for PostgreSQL\n    \u251c\u2500\u2500 test_messages.json         # Seed data for Kafka\n    \u2514\u2500\u2500 test_keys.txt              # Seed data for Redis\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Running tests"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run all acceptance tests\ncargo test --test acceptance\n\n# Run only PostgreSQL plugin acceptance tests\ncargo test --test acceptance postgres\n\n# Run only authentication suite across all plugins\ncargo test --test acceptance auth_suite\n\n# Run with real backend instances (requires Docker)\nPRISM_TEST_MODE=integration cargo test --test acceptance\n\n# Run against specific backend version\nPOSTGRES_VERSION=15 cargo test --test acceptance postgres\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Test output"}),":"]}),"\n",(0,i.jsx)(n.p,{children:"running 45 tests\ntest acceptance::postgres::auth_suite ... ok (2.3s)\ntest acceptance::postgres::basic_operations ... ok (1.8s)\ntest acceptance::postgres::prepared_statements ... ok (3.2s)\ntest acceptance::redis::auth_suite ... ok (0.9s)\ntest acceptance::redis::pub_sub ... ok (1.2s)\ntest acceptance::kafka::auth_suite ... ok (4.5s)\ntest acceptance::kafka::consumer_groups ... ok (8.1s)"}),"\n",(0,i.jsx)(n.p,{children:"Authentication Suite Results:\nPostgreSQL: \u2713 6/6 tests passed\nRedis:      \u2713 6/6 tests passed\nKafka:      \u2713 6/6 tests passed\nClickHouse: \u2713 6/6 tests passed"}),"\n",(0,i.jsx)(n.p,{children:"Backend-Specific Results:\nPostgreSQL: \u2713 15/15 tests passed\nRedis:      \u2713 12/12 tests passed\nKafka:      \u2713 18/18 tests passed\nClickHouse: \u2713 10/10 tests passed"}),"\n",(0,i.jsx)(n.p,{children:"test result: ok. 45 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### CI/CD Integration\n\n**GitHub Actions workflow**:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"githubworkflowsplugin-acceptanceyml",children:".github/workflows/plugin-acceptance.yml"}),"\n",(0,i.jsx)(n.p,{children:"name: Plugin Acceptance Tests"}),"\n",(0,i.jsx)(n.p,{children:"on: [push, pull_request]"}),"\n",(0,i.jsx)(n.p,{children:'jobs:\nacceptance:\nruns-on: ubuntu-latest\nstrategy:\nmatrix:\nbackend: [postgres, redis, kafka, clickhouse]\nbackend_version:\n- postgres: ["14", "15", "16"]\n- redis: ["7.0", "7.2"]\n- kafka: ["3.5", "3.6"]\n- clickhouse: ["23.8", "24.1"]'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"steps:\n  - uses: actions/checkout@v3\n\n  - name: Setup Rust\n    uses: actions-rs/toolchain@v1\n    with:\n      toolchain: stable\n\n  - name: Start Docker\n    run: docker compose up -d\n\n  - name: Run acceptance tests\n    run: |\n      BACKEND_TYPE=${{ matrix.backend }} \\\n      BACKEND_VERSION=${{ matrix.backend_version }} \\\n      cargo test --test acceptance ${{ matrix.backend }}\n\n  - name: Upload test results\n    if: always()\n    uses: actions/upload-artifact@v3\n    with:\n      name: acceptance-test-results-${{ matrix.backend }}\n      path: target/test-results/\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Benefits of Acceptance Test Framework\n\n1. **Consistency**: All plugins tested with same authentication suite\n2. **Real Backends**: Tests use actual backend instances (not mocks)\n3. **Confidence**: Comprehensive verification before production deployment\n4. **CI/CD Ready**: Automated testing on every commit\n5. **Version Matrix**: Test against multiple backend versions\n6. **Reusability**: Authentication tests reused across all plugins\n7. **Documentation**: Tests serve as examples for plugin developers\n\n## Migration Path\n\n### Phase 1: Plugin Interface Definition (Week 1-2)\n\n1. **Protobuf Service**: Define BackendPlugin gRPC service\n2. **Rust Trait**: Define `BackendPlugin` trait for in-process plugins\n3. **Plugin Manager**: Proxy component to load/manage plugins\n4. **Documentation**: Plugin development guide\n\n**Deliverable**: Plugin interface specification\n\n### Phase 2: First Plugin (PostgreSQL) (Week 3-4)\n\n1. **Wrap Existing Backend**: Convert PostgreSQL backend to plugin\n2. **In-Process Loading**: Dynamic library loading in proxy\n3. **Testing**: Integration tests with plugin model\n4. **Metrics**: Plugin metrics reporting\n\n**Deliverable**: PostgreSQL plugin (backward compatible)\n\n### Phase 3: Sidecar Model (Week 5-6)\n\n1. **Unix Socket Channel**: Proxy \u2194 Plugin communication\n2. **Kafka Plugin**: Implement as sidecar\n3. **Docker Compose**: Multi-container deployment\n4. **Health Checks**: Plugin health monitoring\n\n**Deliverable**: Sidecar plugin deployment\n\n### Phase 4: Hot-Reload and Remote Plugins (Week 7-8)\n\n1. **Hot-Reload**: Swap plugins without proxy restart\n2. **gRPC Remote Plugins**: Support external plugin services\n3. **Security Hardening**: mTLS, credential encryption\n4. **Admin CLI**: Plugin management commands\n\n**Deliverable**: Production-ready plugin system\n\n## Security Considerations\n\n### Plugin Isolation\n\n- **Process Isolation**: Sidecar plugins run in separate processes\n- **Resource Limits**: cgroups for CPU/memory limits per plugin\n- **Network Isolation**: Plugins can only access their backend\n- **Credential Encryption**: Credentials encrypted in transit to plugins\n- **Audit Logging**: All plugin operations logged with namespace context\n\n### Plugin Verification\n\n"})}),"\n",(0,i.jsx)(n.p,{children:'// Verify plugin before loading\npub fn verify_plugin(plugin_path: &Path) -> Result<()> {\n// 1. Check file permissions (must be owned by prism user)\nlet metadata = std::fs::metadata(plugin_path)?;\nlet permissions = metadata.permissions();\nif permissions.mode() & 0o002 != 0 {\nreturn Err("Plugin is world-writable".into());\n}'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'// 2. Verify signature (if applicable)\nlet signature = std::fs::read(format!("{}.sig", plugin_path.display()))?;\nverify_signature(plugin_path, &signature)?;\n\n// 3. Load and check version compatibility\nlet plugin = load_plugin(plugin_path)?;\nif !is_compatible_version(&plugin.version()) {\n    return Err("Plugin version incompatible".into());\n}\n\nOk(())\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n## Netflix Architecture Comparison\n\n### Netflix Data Gateway Architecture\n\nNetflix's Data Gateway provides valuable insights for plugin architecture design:\n\n**Netflix Approach**:\n- **Monolithic Gateway**: Single JVM process with all backend clients embedded\n- **Library-Based Backends**: Each backend (Cassandra, EVCache, etc.) as JVM library\n- **Shared Resource Pool**: Thread pools, connection pools shared across backends\n- **Tight Coupling**: Backend updates require gateway redeployment\n\n**Netflix Strengths** (we adopt):\n- **Unified Interface**: Single API for all data access \u2713\n- **Namespace Abstraction**: Logical separation of tenants \u2713\n- **Shadow Traffic**: Enable zero-downtime migrations \u2713\n- **Client-Driven Config**: Applications declare requirements \u2713\n\n**Netflix Limitations** (we improve):\n- **JVM Performance**: 10-100x slower than Rust for proxying\n- **Deployment Coupling**: Backend changes require full gateway redeploy\n- **Language Lock-In**: All backends must be JVM-compatible\n- **Fault Isolation**: One backend crash can affect entire gateway\n- **Scaling Granularity**: Can't scale individual backends independently\n\n### Prism Improvements\n\n| Aspect | Netflix | Prism |\n|--------|---------|-------|\n| **Runtime** | JVM (high latency, GC pauses) | Rust (microsecond latency, no GC) |\n| **Backend Coupling** | Tight (library-based) | Loose (plugin-based) |\n| **Fault Isolation** | Shared process | Separate processes (sidecar) |\n| **Language Flexibility** | JVM only | Any language (gRPC interface) |\n| **Deployment** | Monolithic | Independent plugin deployment |\n| **Scaling** | Gateway-level only | Per-plugin scaling |\n| **Performance** | ~5-10ms overhead | &lt;1ms (in-process), ~1-2ms (sidecar) |\n\n### Lessons from Other DAL Implementations\n\n**Vitess (YouTube)**: MySQL proxy with query rewriting\n- \u2705 **Plugin model**: VTGate routes to VTTablet plugins\n- \u2705 **gRPC-based**: Same approach as Prism\n- \u274c **MySQL-specific**: Limited to one backend type\n\n**Envoy Proxy**: L7 proxy with filter chains\n- \u2705 **WASM plugins**: Sandboxed extension model\n- \u2705 **Zero-copy**: Efficient buffer management\n- \u274c **HTTP-focused**: Not designed for data access patterns\n\n**Linkerd Service Mesh**: Rust-based proxy\n- \u2705 **Rust performance**: Similar performance characteristics\n- \u2705 **Process isolation**: Sidecar model\n- \u274c **L4/L7 only**: Not data-access aware\n\n**Prism's Unique Position**:\n- Combines Netflix's data access abstraction\n- With Envoy's performance and extensibility\n- Purpose-built for heterogeneous data backends\n- Rust performance + plugin flexibility\n\n## Related RFCs and ADRs\n\n- RFC-003: Admin gRPC API (proxy management)\n- RFC-004: Redis Integration (example backend \u2192 plugin)\n- RFC-007: Cache Strategies (plugin-level caching)\n- ADR-010: Redis Integration (backend implementation)\n- See `docs-cms/netflix/` for Netflix Data Gateway analysis\n\n## References\n\n- [gRPC Plugin System Design](https://grpc.io/docs/what-is-grpc/introduction/)\n- [HashiCorp go-plugin](https://github.com/hashicorp/go-plugin)\n- [WebAssembly Component Model](https://github.com/WebAssembly/component-model)\n- [Linux Capabilities](https://man7.org/linux/man-pages/man7/capabilities.7.html)\n\n## Plugin Development Experience\n\n### Design Goals for Plugin Authors\n\nMaking plugins easy to create is critical for Prism's success. We prioritize:\n\n1. **Minimal Boilerplate**: Plugin shell generates 80% of code\n2. **Strong Typing**: Protobuf schemas prevent API mismatches\n3. **Local Testing**: Test plugins without full Prism deployment\n4. **Fast Iteration**: Hot-reload during development\n5. **Clear Documentation**: Examples for common patterns\n\n### Plugin Shell: `prism-plugin-init`\n\n**Quick Start** - Create a new plugin in 30 seconds:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"create-new-plugin-from-template",children:"Create new plugin from template"}),"\n",(0,i.jsx)(n.p,{children:"prism-plugin-init --name mongodb --language rust"}),"\n",(0,i.jsx)(n.h1,{id:"generated-structure",children:"Generated structure:"}),"\n",(0,i.jsx)(n.p,{children:"mongodb-plugin/\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 lib.rs          # Plugin entry point (implements BackendPlugin trait)\n\u2502   \u251c\u2500\u2500 config.rs       # Backend configuration (auto-generated from proto)\n\u2502   \u251c\u2500\u2500 client.rs       # MongoDB client wrapper\n\u2502   \u2514\u2500\u2500 operations/     # Operation handlers\n\u2502       \u251c\u2500\u2500 get.rs\n\u2502       \u251c\u2500\u2500 set.rs\n\u2502       \u2514\u2500\u2500 query.rs\n\u251c\u2500\u2500 proto/\n\u2502   \u2514\u2500\u2500 mongodb_config.proto  # Configuration schema\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 integration_test.rs\n\u2502   \u2514\u2500\u2500 fixtures/\n\u2514\u2500\u2500 README.md"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n**Template provides**:\n- gRPC service implementation skeleton\n- Configuration parsing (protobuf \u2192 struct)\n- Connection pool setup\n- Health check implementation\n- Metrics reporting\n- Error handling patterns\n- Integration test scaffolding\n\n### Plugin SDK (`prism-plugin-sdk`)\n\nRust SDK provides helpers for common patterns:\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"use prism_plugin_sdk::prelude::*;"}),"\n",(0,i.jsx)(n.p,{children:"#[plugin]\npub struct MongoDbPlugin {\n#[config]\nconfig: MongoDbConfig,  // Auto-parsed from InitializeRequest"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"#[client]\nclient: MongoClient,  // Auto-initialized from config\n\n#[pool(size = 20)]\npool: ConnectionPool,  // Connection pooling helper\n"})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.p,{children:"#[async_trait]\nimpl BackendPlugin for MongoDbPlugin {\n// SDK provides default implementations for health_check, metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'#[operation("get")]\nasync fn handle_get(&self, params: GetParams) -> PluginResult<GetResponse> {\n    // SDK handles:\n    // - Protobuf deserialization (params)\n    // - Error mapping (PluginResult \u2192 gRPC status codes)\n    // - Metrics recording (latency, errors)\n    // - Tracing context propagation\n\n    let doc = self.client.find_one(params.key).await?;\n    Ok(GetResponse { value: doc })\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n**SDK Features**:\n- **Macros**: `#[plugin]`, `#[operation]` reduce boilerplate\n- **Connection Pooling**: Automatic pool management\n- **Metrics**: Auto-record latency, errors, throughput\n- **Health Checks**: Default implementation with customization hooks\n- **Testing Utilities**: Mock proxy, request builders\n\n### Development Workflow\n\n**Local Testing Without Prism**:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"1-start-plugin-in-standalone-mode",children:"1. Start plugin in standalone mode"}),"\n",(0,i.jsx)(n.p,{children:"cargo run --bin mongodb-plugin-server"}),"\n",(0,i.jsx)(n.h1,{id:"2-test-with-grpcurl",children:"2. Test with grpcurl"}),"\n",(0,i.jsxs)(n.p,{children:['grpcurl -plaintext -d \'{"namespace": "test", "config": {...}}\' ',(0,i.jsx)(n.br,{}),"\nlocalhost:50100 prism.plugin.BackendPlugin/Initialize"]}),"\n",(0,i.jsx)(n.h1,{id:"3-send-operations",children:"3. Send operations"}),"\n",(0,i.jsxs)(n.p,{children:['grpcurl -plaintext -d \'{"operation": "get", "params": {"key": "foo"}}\' ',(0,i.jsx)(n.br,{}),"\nlocalhost:50100 prism.plugin.BackendPlugin/Execute"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n**Integration Testing**:\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"#[tokio::test]\nasync fn test_get_operation() {\n// SDK provides test harness\nlet mut plugin = MongoDbPlugin::test_instance().await;"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'// Initialize with test config\nplugin.initialize(test_config()).await.unwrap();\n\n// Execute operation\nlet response = plugin.get("test-key").await.unwrap();\n\nassert_eq!(response.value, expected_value);\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n**Hot-Reload During Development**:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"watch-for-changes-and-reload-plugin",children:"Watch for changes and reload plugin"}),"\n",(0,i.jsx)(n.p,{children:"cargo watch -x 'build --release' -s 'prism plugin reload mongodb'"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Language Support Strategy\n\n**Priority 1: Rust** (Best Performance + Isolation)\n- In-process: Shared library (cdylib)\n- Out-of-process: Standalone binary with gRPC server\n- **Best for**: High-performance backends (Redis, PostgreSQL)\n\n**Priority 2: Go** (Good Performance + Ecosystem)\n- Out-of-process only: gRPC server\n- **Best for**: Kafka, ClickHouse (existing Go SDKs)\n\n**Priority 3: Python** (Rapid Development)\n- Out-of-process only: gRPC server\n- **Best for**: Prototyping, ML backends, custom integrations\n\n**Template Availability**:\n"})}),"\n",(0,i.jsx)(n.p,{children:"prism-plugin-init --name mybackend --language [rust|go|python]"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\nEach template includes:\n- gRPC service implementation\n- Connection pool patterns\n- Configuration management\n- Testing framework\n- Dockerfile for containerization\n\n### Plugin Isolation Strategy\n\n**Security Isolation** (Prevents malicious plugins):\n\n| Mechanism | In-Process | Sidecar | Remote |\n|-----------|-----------|---------|--------|\n| **Process Boundary** | \u274c Shared | \u2705 Separate | \u2705 Separate |\n| **Memory Isolation** | \u274c Shared | \u2705 Isolated | \u2705 Isolated |\n| **Resource Limits** | \u274c Shared | \u2705 cgroups | \u2705 K8s limits |\n| **Credential Access** | \u26a0\ufe0f Restricted | \u2705 Isolated | \u2705 Isolated |\n\n**Recommendation**: Use sidecar/remote for untrusted plugins.\n\n**Performance Isolation** (Prevents noisy neighbor):\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"kubernetes-resource-limits-per-plugin",children:"Kubernetes resource limits per plugin"}),"\n",(0,i.jsx)(n.p,{children:"apiVersion: v1\nkind: Pod\nmetadata:\nname: clickhouse-plugin\nspec:\ncontainers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:'name: plugin\nimage: prism/clickhouse-plugin\nresources:\nrequests:\ncpu: "1"\nmemory: "2Gi"\nlimits:\ncpu: "4"        # Prevent CPU starvation of other plugins\nmemory: "8Gi"   # Prevent OOM affecting proxy'}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n**Network Isolation** (Prevents cross-plugin communication):\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"networkpolicy-plugin-can-only-talk-to-proxy-and-backend",children:"NetworkPolicy: Plugin can only talk to proxy and backend"}),"\n",(0,i.jsx)(n.p,{children:"apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\nname: clickhouse-plugin-netpol\nspec:\npodSelector:\nmatchLabels:\napp: clickhouse-plugin\npolicyTypes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ingress"}),"\n",(0,i.jsx)(n.li,{children:"Egress\ningress:"}),"\n",(0,i.jsxs)(n.li,{children:["from:\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"podSelector:\nmatchLabels:\napp: prism-proxy  # Only proxy can call plugin\negress:"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["to:\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"podSelector:\nmatchLabels:\napp: clickhouse  # Plugin can only call ClickHouse"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Plugin Administration\n\nPlugin management commands are provided via the Prism Admin CLI. See [RFC-006 Plugin Administration](#) for full CLI specification.\n\n**Quick examples**:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"list-installed-plugins",children:"List installed plugins"}),"\n",(0,i.jsx)(n.p,{children:"prism plugin list"}),"\n",(0,i.jsx)(n.h1,{id:"install-plugin-from-registry",children:"Install plugin from registry"}),"\n",(0,i.jsx)(n.p,{children:"prism plugin install mongodb --version 1.2.0"}),"\n",(0,i.jsx)(n.h1,{id:"update-plugin",children:"Update plugin"}),"\n",(0,i.jsx)(n.p,{children:"prism plugin update mongodb --version 1.3.0"}),"\n",(0,i.jsx)(n.h1,{id:"enabledisable-plugin",children:"Enable/disable plugin"}),"\n",(0,i.jsx)(n.p,{children:"prism plugin disable kafka\nprism plugin enable kafka"}),"\n",(0,i.jsx)(n.h1,{id:"view-plugin-health-and-metrics",children:"View plugin health and metrics"}),"\n",(0,i.jsx)(n.p,{children:"prism plugin status mongodb"}),"\n",(0,i.jsx)(n.h1,{id:"hot-reload-plugin-code",children:"Hot-reload plugin code"}),"\n",(0,i.jsx)(n.p,{children:"prism plugin reload mongodb"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\nFor detailed plugin admin commands, see [RFC-006 Section: Plugin Management](/rfc/rfc-006.md#plugin-management).\n\n## Appendix: Plugin Development Guide\n\n### Creating a New Plugin\n\n1. **Implement BackendPlugin Trait**:\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"use prism_plugin::{BackendPlugin, InitializeRequest, ExecuteRequest};"}),"\n",(0,i.jsx)(n.p,{children:"pub struct MyBackendPlugin {\nconfig: MyConfig,\nclient: MyBackendClient,\n}"}),"\n",(0,i.jsxs)(n.p,{children:["#[async_trait]\nimpl BackendPlugin for MyBackendPlugin {\nasync fn initialize(&mut self, req: InitializeRequest) -> Result",(0,i.jsxs)(n.initializeresponse,{children:[" {\n// Decode protobuf Any to strongly-typed config\nself.config = req.config.unpack::",(0,i.jsx)(n.myconfig,{children:"()?;\nself.client = MyBackendClient::connect(&self.config).await?;"})]})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'    Ok(InitializeResponse {\n        success: true,\n        plugin_version: "0.1.0".to_string(),\n        supported_operations: vec!["get", "set"],\n        ..Default::default()\n    })\n}\n\nasync fn execute(&self, req: ExecuteRequest) -> Result<ExecuteResponse> {\n    match req.operation.as_str() {\n        "get" => self.handle_get(&req).await,\n        "set" => self.handle_set(&req).await,\n        _ => Err(format!("Unsupported: {}", req.operation).into()),\n    }\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n2. **Build as Shared Library**:\n\n"})}),"\n",(0,i.jsx)(n.p,{children:'[lib]\ncrate-type = ["cdylib"]  # Dynamic library'}),"\n",(0,i.jsx)(n.p,{children:'[dependencies]\nprism-plugin-sdk = "0.1"'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n3. **Register Plugin**:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"add-to-proxy-configuration",children:"Add to proxy configuration"}),"\n",(0,i.jsx)(n.p,{children:"plugins:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"name: my-backend\nlibrary: /path/to/libmy_backend_plugin.so\ntype: in_process"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n---\n\n**Status**: Draft\n**Next Steps**:\n1. Define BackendPlugin gRPC service in protobuf\n2. Implement plugin trait in Rust\n3. Convert PostgreSQL backend to plugin architecture\n4. Document plugin development process\n5. Implement sidecar plugin support with Unix sockets\n\n"})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);