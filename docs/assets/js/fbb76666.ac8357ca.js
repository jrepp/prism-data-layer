"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[53830],{28453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>c});var t=r(96540);const a={},i=t.createContext(a);function s(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(i.Provider,{value:n},e.children)}},86353:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>m,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"rfc-033","title":"RFC-033: Claim Check Pattern for Large Payloads","description":"Status","source":"@site/../docs-cms/rfcs/RFC-033-claim-check-pattern.md","sourceDirName":".","slug":"/rfc-033","permalink":"/prism-data-layer/rfc/rfc-033","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/rfcs/RFC-033-claim-check-pattern.md","tags":[{"inline":true,"label":"patterns","permalink":"/prism-data-layer/rfc/tags/patterns"},{"inline":true,"label":"claim-check","permalink":"/prism-data-layer/rfc/tags/claim-check"},{"inline":true,"label":"object-storage","permalink":"/prism-data-layer/rfc/tags/object-storage"},{"inline":true,"label":"performance","permalink":"/prism-data-layer/rfc/tags/performance"},{"inline":true,"label":"architecture","permalink":"/prism-data-layer/rfc/tags/architecture"},{"inline":true,"label":"producer","permalink":"/prism-data-layer/rfc/tags/producer"},{"inline":true,"label":"consumer","permalink":"/prism-data-layer/rfc/tags/consumer"},{"inline":true,"label":"minio","permalink":"/prism-data-layer/rfc/tags/minio"},{"inline":true,"label":"s3","permalink":"/prism-data-layer/rfc/tags/s-3"}],"version":"current","frontMatter":{"title":"RFC-033: Claim Check Pattern for Large Payloads","status":"Proposed","author":"Prism Team","created":"2025-10-14T00:00:00.000Z","updated":"2025-10-14T00:00:00.000Z","tags":["patterns","claim-check","object-storage","performance","architecture","producer","consumer","minio","s3"],"id":"rfc-033","project_id":"prism-data-layer","doc_uuid":"7660cafd-abcf-44f3-82d8-e612a7cf6630"},"sidebar":"rfcSidebar","previous":{"title":"Minimal Prism Schema Registry for Local Testing \u2022 RFC-032","permalink":"/prism-data-layer/rfc/rfc-032"},"next":{"title":"Robust Process Manager Package Inspired by Kubelet \u2022 RFC-034","permalink":"/prism-data-layer/rfc/rfc-034"}}');var a=r(74848),i=r(28453);const s={title:"RFC-033: Claim Check Pattern for Large Payloads",status:"Proposed",author:"Prism Team",created:new Date("2025-10-14T00:00:00.000Z"),updated:new Date("2025-10-14T00:00:00.000Z"),tags:["patterns","claim-check","object-storage","performance","architecture","producer","consumer","minio","s3"],id:"rfc-033",project_id:"prism-data-layer",doc_uuid:"7660cafd-abcf-44f3-82d8-e612a7cf6630"},c="RFC-033: Claim Check Pattern for Large Payloads",o={},l=[{value:"Status",id:"status",level:2},{value:"Context",id:"context",level:2},{value:"Proposal",id:"proposal",level:2},{value:"Architecture",id:"architecture",level:3},{value:"Namespace-Level Coordination",id:"namespace-level-coordination",level:3},{value:"Producer Behavior",id:"producer-behavior",level:3},{value:"Consumer Behavior",id:"consumer-behavior",level:3},{value:"Message Format",id:"message-format",level:3},{value:"Proxy Validation",id:"proxy-validation",level:3},{value:"Object Store Interface",id:"object-store-interface",level:3},{value:"MinIO Driver for Testing",id:"minio-driver-for-testing",level:3},{value:"Acceptance Test Scenarios",id:"acceptance-test-scenarios",level:3},{value:"Benefits",id:"benefits",level:2},{value:"Trade-offs",id:"trade-offs",level:2},{value:"Advantages",id:"advantages",level:3},{value:"Disadvantages",id:"disadvantages",level:3},{value:"Migration Path",id:"migration-path",level:2},{value:"Alternatives Considered",id:"alternatives-considered",level:2},{value:"1. Inline Chunking",id:"1-inline-chunking",level:3},{value:"2. Separate Large Message Queue",id:"2-separate-large-message-queue",level:3},{value:"3. Always Use Object Store",id:"3-always-use-object-store",level:3},{value:"Open Questions",id:"open-questions",level:2},{value:"References",id:"references",level:2},{value:"Related Documents",id:"related-documents",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"rfc-033-claim-check-pattern-for-large-payloads",children:"RFC-033: Claim Check Pattern for Large Payloads"})}),"\n",(0,a.jsx)(n.h2,{id:"status",children:"Status"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Proposed"})," - Design phase, awaiting review"]}),"\n",(0,a.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,a.jsx)(n.p,{children:"Messaging systems typically have message size limits (NATS: 1MB default, Kafka: 1MB default, Redis: 512MB max). Sending large payloads (videos, images, ML models, datasets) through message queues creates several problems:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance Degradation"}),": Large messages slow down message brokers and increase network congestion"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Memory Pressure"}),": Brokers must buffer large messages, causing memory issues"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Increased Latency"}),": Large message serialization/deserialization adds latency"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Size Limits"}),": Hard limits prevent sending certain payloads"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cost"}),": Cloud message brokers charge per GB transferred"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.strong,{children:"Claim Check Pattern"})," solves this by:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Storing large payloads in object storage (S3, MinIO)"}),"\n",(0,a.jsx)(n.li,{children:"Sending only a reference (claim check) through the message queue"}),"\n",(0,a.jsx)(n.li,{children:"Consumer retrieves payload from object storage using the claim check"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"This is a standard enterprise integration pattern (EIP) used by Azure Service Bus, AWS EventBridge, and Google Pub/Sub."}),"\n",(0,a.jsx)(n.h2,{id:"proposal",children:"Proposal"}),"\n",(0,a.jsxs)(n.p,{children:["Add optional ",(0,a.jsx)(n.strong,{children:"Claim Check slot"})," to Producer and Consumer patterns, coordinating through namespace-level requirements."]}),"\n",(0,a.jsx)(n.h3,{id:"architecture",children:"Architecture"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Producer   \u2502\n\u2502             \u2502\n\u2502 1. Check    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    payload  \u2502      \u2502\n\u2502    size     \u2502      \u2502\n\u2502             \u2502      \u25bc\n\u2502 2. Upload   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    if > X   \u2502\u2500\u25b6\u2502 Object Store \u2502\n\u2502             \u2502  \u2502  (MinIO/S3)  \u2502\n\u2502 3. Send     \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502    claim    \u2502      \u2502\n\u2502    check    \u2502      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n       \u2502             \u2502\n       \u2502 Message     \u2502\n       \u2502 (small)     \u2502\n       \u25bc             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   Message   \u2502      \u2502\n\u2502   Broker    \u2502      \u2502\n\u2502  (NATS/     \u2502      \u2502\n\u2502   Kafka)    \u2502      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n       \u2502             \u2502\n       \u2502             \u2502\n       \u25bc             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  Consumer   \u2502      \u2502\n\u2502             \u2502      \u2502\n\u2502 1. Receive  \u2502      \u2502\n\u2502    message  \u2502      \u2502\n\u2502             \u2502      \u2502\n\u2502 2. Check    \u2502      \u2502\n\u2502    claim    \u2502      \u2502\n\u2502             \u2502      \u2502\n\u2502 3. Download \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502    if claim \u2502\n\u2502    exists   \u2502\n\u2502             \u2502\n\u2502 4. Process  \u2502\n\u2502    payload  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h3,{id:"namespace-level-coordination",children:"Namespace-Level Coordination"}),"\n",(0,a.jsx)(n.p,{children:"Producers and consumers in the same namespace share claim check requirements:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"namespace: video-processing\nclaim_check:\n  enabled: true\n  threshold: 1048576  # 1MB - messages larger trigger claim check\n  backend: minio\n  bucket: prism-claims-video-processing\n  ttl: 3600  # Claim expires after 1 hour\n  compression: gzip  # Optional compression before upload\n"})}),"\n",(0,a.jsx)(n.p,{children:"The proxy validates that:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Producer and consumer claim check configurations match"}),"\n",(0,a.jsx)(n.li,{children:"Both have access to the same object store backend"}),"\n",(0,a.jsx)(n.li,{children:"Bucket exists and is accessible"}),"\n",(0,a.jsx)(n.li,{children:"TTL policies are compatible"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"producer-behavior",children:"Producer Behavior"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'// Producer configuration with claim check slot\ntype Config struct {\n    Name        string\n    Behavior    BehaviorConfig\n    Slots       SlotConfig\n    ClaimCheck  *ClaimCheckConfig  // NEW: Optional claim check\n}\n\ntype ClaimCheckConfig struct {\n    Enabled       bool\n    Threshold     int64   // Bytes - payloads > threshold use claim check\n    Backend       string  // "minio", "s3", "gcs", etc.\n    Bucket        string\n    TTL           int     // Seconds - how long claim is valid\n    Compression   string  // "none", "gzip", "zstd"\n}\n\n// Producer slots with optional object store\ntype SlotConfig struct {\n    MessageSink string   // Required: NATS, Kafka, Redis\n    StateStore  string   // Optional: for deduplication\n    ObjectStore string   // Optional: for claim check\n}\n'})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Publish Flow"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'func (p *Producer) Publish(ctx context.Context, topic string, payload []byte, metadata map[string]string) error {\n    // Check if payload exceeds threshold\n    if p.claimCheck != nil && int64(len(payload)) > p.claimCheck.Threshold {\n        // 1. Compress if configured\n        data := payload\n        if p.claimCheck.Compression != "none" {\n            data = compress(payload, p.claimCheck.Compression)\n        }\n\n        // 2. Upload to object store\n        claimID := generateClaimID()\n        objectKey := fmt.Sprintf("%s/%s/%s", p.namespace, topic, claimID)\n\n        if err := p.objectStore.Put(ctx, p.claimCheck.Bucket, objectKey, data); err != nil {\n            return fmt.Errorf("claim check upload failed: %w", err)\n        }\n\n        // 3. Set TTL for automatic cleanup\n        if p.claimCheck.TTL > 0 {\n            if err := p.objectStore.SetTTL(ctx, p.claimCheck.Bucket, objectKey, p.claimCheck.TTL); err != nil {\n                // Non-fatal: log warning and continue\n                slog.Warn("failed to set claim check TTL", "error", err)\n            }\n        }\n\n        // 4. Send small message with claim reference\n        claimPayload := ClaimCheckMessage{\n            ClaimID:     claimID,\n            Bucket:      p.claimCheck.Bucket,\n            ObjectKey:   objectKey,\n            OriginalSize: len(payload),\n            Compression: p.claimCheck.Compression,\n            ContentType: metadata["content-type"],\n            Checksum:    sha256.Sum256(payload),\n        }\n\n        smallPayload, _ := json.Marshal(claimPayload)\n        metadata["prism-claim-check"] = "true"\n\n        return p.messageSink.Publish(ctx, topic, smallPayload, metadata)\n    }\n\n    // Normal path: small payload sent directly\n    return p.messageSink.Publish(ctx, topic, payload, metadata)\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"consumer-behavior",children:"Consumer Behavior"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:"// Consumer configuration with claim check slot\ntype Config struct {\n    Name        string\n    Behavior    BehaviorConfig\n    Slots       SlotConfig\n    ClaimCheck  *ClaimCheckConfig  // NEW: Optional claim check\n}\n\n// Consumer slots with optional object store\ntype SlotConfig struct {\n    MessageSource string  // Required: NATS, Kafka, Redis\n    StateStore    string  // Optional: for offset tracking\n    ObjectStore   string  // Optional: for claim check\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Consumption Flow"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'func (c *Consumer) processMessage(ctx context.Context, msg *plugin.PubSubMessage) error {\n    // Check if message is a claim check\n    if msg.Metadata["prism-claim-check"] == "true" {\n        // 1. Deserialize claim check\n        var claim ClaimCheckMessage\n        if err := json.Unmarshal(msg.Payload, &claim); err != nil {\n            return fmt.Errorf("invalid claim check message: %w", err)\n        }\n\n        // 2. Download from object store\n        data, err := c.objectStore.Get(ctx, claim.Bucket, claim.ObjectKey)\n        if err != nil {\n            return fmt.Errorf("claim check download failed: %w", err)\n        }\n\n        // 3. Verify checksum\n        actualChecksum := sha256.Sum256(data)\n        if !bytes.Equal(actualChecksum[:], claim.Checksum[:]) {\n            return fmt.Errorf("claim check checksum mismatch")\n        }\n\n        // 4. Decompress if needed\n        if claim.Compression != "none" {\n            data, err = decompress(data, claim.Compression)\n            if err != nil {\n                return fmt.Errorf("claim check decompression failed: %w", err)\n            }\n        }\n\n        // 5. Replace payload with actual data\n        msg.Payload = data\n        msg.Metadata["content-type"] = claim.ContentType\n        delete(msg.Metadata, "prism-claim-check")\n\n        // 6. Optional: Delete claim after successful retrieval\n        if c.claimCheck.DeleteAfterRead {\n            go func() {\n                if err := c.objectStore.Delete(ctx, claim.Bucket, claim.ObjectKey); err != nil {\n                    slog.Warn("failed to delete claim after read", "error", err)\n                }\n            }()\n        }\n    }\n\n    // Process message (with original or retrieved payload)\n    return c.processor(ctx, msg)\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"message-format",children:"Message Format"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Claim Check Message"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-protobuf",children:'message ClaimCheckMessage {\n  // Unique claim identifier\n  string claim_id = 1;\n\n  // Object store location\n  string bucket = 2;\n  string object_key = 3;\n\n  // Metadata about original payload\n  int64 original_size = 4;\n  string content_type = 5;\n  bytes checksum = 6;  // SHA-256 of uncompressed payload\n\n  // Compression info\n  string compression = 7;  // "none", "gzip", "zstd"\n\n  // Expiration\n  int64 expires_at = 8;  // Unix timestamp\n\n  // Optional: multipart for very large files\n  optional MultipartInfo multipart = 9;\n}\n\nmessage MultipartInfo {\n  int32 part_count = 1;\n  repeated string part_keys = 2;\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"proxy-validation",children:"Proxy Validation"}),"\n",(0,a.jsx)(n.p,{children:"The proxy validates claim check coordination at pattern registration:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'// When producer registers\nfunc (p *Proxy) RegisterProducer(ctx context.Context, req *RegisterRequest) error {\n    // Load namespace configuration\n    ns := p.getNamespace(req.Namespace)\n\n    // If namespace requires claim check, validate producer config\n    if ns.ClaimCheck.Required {\n        if req.Config.ClaimCheck == nil {\n            return status.Error(codes.FailedPrecondition,\n                "namespace requires claim check but producer does not support it")\n        }\n\n        // Validate configuration matches namespace requirements\n        if err := validateClaimCheckConfig(req.Config.ClaimCheck, ns.ClaimCheck); err != nil {\n            return status.Errorf(codes.InvalidArgument,\n                "claim check config mismatch: %v", err)\n        }\n\n        // Verify object store backend is accessible\n        if err := p.verifyObjectStoreAccess(ctx, req.Config.ClaimCheck); err != nil {\n            return status.Errorf(codes.FailedPrecondition,\n                "object store not accessible: %v", err)\n        }\n    }\n\n    return nil\n}\n\n// Similar validation for consumer registration\n'})}),"\n",(0,a.jsx)(n.h3,{id:"object-store-interface",children:"Object Store Interface"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:"// ObjectStoreInterface defines operations needed for claim check\ntype ObjectStoreInterface interface {\n    // Put stores an object\n    Put(ctx context.Context, bucket, key string, data []byte) error\n\n    // Get retrieves an object\n    Get(ctx context.Context, bucket, key string) ([]byte, error)\n\n    // Delete removes an object\n    Delete(ctx context.Context, bucket, key string) error\n\n    // SetTTL sets object expiration\n    SetTTL(ctx context.Context, bucket, key string, ttlSeconds int) error\n\n    // Exists checks if object exists\n    Exists(ctx context.Context, bucket, key string) (bool, error)\n\n    // GetMetadata retrieves object metadata without downloading\n    GetMetadata(ctx context.Context, bucket, key string) (*ObjectMetadata, error)\n}\n\ntype ObjectMetadata struct {\n    Size         int64\n    ContentType  string\n    LastModified time.Time\n    ETag         string\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"minio-driver-for-testing",children:"MinIO Driver for Testing"}),"\n",(0,a.jsx)(n.p,{children:"For acceptance testing, we'll use MinIO (S3-compatible) via testcontainers:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:"// pkg/drivers/minio/driver.go\ntype MinioDriver struct {\n    client *minio.Client\n    config MinioConfig\n}\n\nfunc (d *MinioDriver) Put(ctx context.Context, bucket, key string, data []byte) error {\n    _, err := d.client.PutObject(ctx, bucket, key,\n        bytes.NewReader(data), int64(len(data)),\n        minio.PutObjectOptions{})\n    return err\n}\n\nfunc (d *MinioDriver) Get(ctx context.Context, bucket, key string) ([]byte, error) {\n    obj, err := d.client.GetObject(ctx, bucket, key, minio.GetObjectOptions{})\n    if err != nil {\n        return nil, err\n    }\n    defer obj.Close()\n    return io.ReadAll(obj)\n}\n\n// ... other methods\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Acceptance Test Setup"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'// tests/acceptance/backends/minio.go\nfunc init() {\n    framework.MustRegisterBackend(framework.Backend{\n        Name:      "MinIO",\n        SetupFunc: setupMinIO,\n        SupportedPatterns: []framework.Pattern{\n            framework.PatternObjectStore,  // New pattern\n        },\n        Capabilities: framework.Capabilities{\n            SupportsObjectStore: true,\n            MaxObjectSize:       5 * 1024 * 1024 * 1024, // 5GB\n        },\n    })\n}\n\nfunc setupMinIO(t *testing.T, ctx context.Context) (interface{}, func()) {\n    // Start MinIO testcontainer\n    minioContainer, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n        ContainerRequest: testcontainers.ContainerRequest{\n            Image:        "minio/minio:latest",\n            ExposedPorts: []string{"9000/tcp"},\n            Env: map[string]string{\n                "MINIO_ROOT_USER":     "minioadmin",\n                "MINIO_ROOT_PASSWORD": "minioadmin",\n            },\n            Cmd: []string{"server", "/data"},\n            WaitingFor: wait.ForHTTP("/minio/health/live").WithPort("9000/tcp"),\n        },\n        Started: true,\n    })\n    require.NoError(t, err)\n\n    // Get connection details\n    endpoint, err := minioContainer.Endpoint(ctx, "")\n    require.NoError(t, err)\n\n    // Create MinIO driver\n    driver := minio.New()\n    config := &plugin.Config{\n        Plugin: plugin.PluginConfig{\n            Name:    "minio-test",\n            Version: "0.1.0",\n        },\n        Backend: map[string]any{\n            "endpoint":   endpoint,\n            "access_key": "minioadmin",\n            "secret_key": "minioadmin",\n            "use_ssl":    false,\n        },\n    }\n\n    err = driver.Initialize(ctx, config)\n    require.NoError(t, err)\n\n    err = driver.Start(ctx)\n    require.NoError(t, err)\n\n    cleanup := func() {\n        driver.Stop(ctx)\n        minioContainer.Terminate(ctx)\n    }\n\n    return driver, cleanup\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"acceptance-test-scenarios",children:"Acceptance Test Scenarios"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'// tests/acceptance/patterns/claimcheck/claimcheck_test.go\nfunc TestClaimCheckPattern(t *testing.T) {\n    tests := []framework.MultiPatternTest{\n        {\n            Name: "LargePayloadClaimCheck",\n            RequiredPatterns: map[string]framework.Pattern{\n                "producer":    framework.PatternProducer,\n                "consumer":    framework.PatternConsumer,\n                "objectstore": framework.PatternObjectStore,\n            },\n            Func:    testLargePayloadClaimCheck,\n            Timeout: 60 * time.Second,\n            Tags:    []string{"claim-check", "large-payload"},\n        },\n        {\n            Name: "ThresholdBoundary",\n            RequiredPatterns: map[string]framework.Pattern{\n                "producer":    framework.PatternProducer,\n                "consumer":    framework.PatternConsumer,\n                "objectstore": framework.PatternObjectStore,\n            },\n            Func:    testThresholdBoundary,\n            Timeout: 30 * time.Second,\n            Tags:    []string{"claim-check", "boundary"},\n        },\n        {\n            Name: "Compression",\n            RequiredPatterns: map[string]framework.Pattern{\n                "producer":    framework.PatternProducer,\n                "consumer":    framework.PatternConsumer,\n                "objectstore": framework.PatternObjectStore,\n            },\n            Func:    testCompression,\n            Timeout: 30 * time.Second,\n            Tags:    []string{"claim-check", "compression"},\n        },\n        {\n            Name: "TTLExpiration",\n            RequiredPatterns: map[string]framework.Pattern{\n                "producer":    framework.PatternProducer,\n                "consumer":    framework.PatternConsumer,\n                "objectstore": framework.PatternObjectStore,\n            },\n            Func:    testTTLExpiration,\n            Timeout: 45 * time.Second,\n            Tags:    []string{"claim-check", "ttl"},\n        },\n        {\n            Name: "ChecksumValidation",\n            RequiredPatterns: map[string]framework.Pattern{\n                "producer":    framework.PatternProducer,\n                "consumer":    framework.PatternConsumer,\n                "objectstore": framework.PatternObjectStore,\n            },\n            Func:    testChecksumValidation,\n            Timeout: 30 * time.Second,\n            Tags:    []string{"claim-check", "security"},\n        },\n    }\n\n    framework.RunMultiPatternTests(t, tests)\n}\n\nfunc testLargePayloadClaimCheck(t *testing.T, drivers map[string]interface{}, caps framework.Capabilities) {\n    ctx := context.Background()\n\n    // Setup producer with claim check\n    prod := setupProducerWithClaimCheck(t, ctx, drivers["producer"], drivers["objectstore"])\n    cons := setupConsumerWithClaimCheck(t, ctx, drivers["consumer"], drivers["objectstore"])\n\n    // Generate 5MB payload (exceeds 1MB threshold)\n    largePayload := make([]byte, 5*1024*1024)\n    rand.Read(largePayload)\n\n    // Publish\n    err := prod.Publish(ctx, "test-topic", largePayload, map[string]string{\n        "content-type": "application/octet-stream",\n    })\n    require.NoError(t, err)\n\n    // Consumer should receive full payload via claim check\n    received := <-cons.Messages()\n    assert.Equal(t, len(largePayload), len(received.Payload))\n    assert.Equal(t, largePayload, received.Payload)\n}\n\nfunc testThresholdBoundary(t *testing.T, drivers map[string]interface{}, caps framework.Capabilities) {\n    ctx := context.Background()\n\n    prod := setupProducerWithClaimCheck(t, ctx, drivers["producer"], drivers["objectstore"])\n    cons := setupConsumerWithClaimCheck(t, ctx, drivers["consumer"], drivers["objectstore"])\n\n    // Payload just under threshold (should NOT use claim check)\n    smallPayload := make([]byte, 1048575) // 1MB - 1 byte\n    err := prod.Publish(ctx, "test-topic", smallPayload, nil)\n    require.NoError(t, err)\n\n    msg1 := <-cons.Messages()\n    assert.Empty(t, msg1.Metadata["prism-claim-check"])\n\n    // Payload exactly at threshold (should use claim check)\n    thresholdPayload := make([]byte, 1048576) // 1MB\n    err = prod.Publish(ctx, "test-topic", thresholdPayload, nil)\n    require.NoError(t, err)\n\n    msg2 := <-cons.Messages()\n    assert.Equal(t, thresholdPayload, msg2.Payload)\n}\n'})}),"\n",(0,a.jsx)(n.h2,{id:"benefits",children:"Benefits"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Handles Large Payloads"}),": No message broker size limits"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Reduces Broker Load"}),": Small messages flow through queue"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Better Performance"}),": Less serialization/deserialization overhead"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cost Optimization"}),": Object storage cheaper than message transfer"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Automatic Cleanup"}),": TTL-based claim expiration prevents storage bloat"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Transparent"}),": Application code unchanged, pattern handles complexity"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Namespace Coordination"}),": Proxy validates producer/consumer compatibility"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"trade-offs",children:"Trade-offs"}),"\n",(0,a.jsx)(n.h3,{id:"advantages",children:"Advantages"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Decouples message flow from payload storage"}),"\n",(0,a.jsx)(n.li,{children:"Scales to multi-GB payloads"}),"\n",(0,a.jsx)(n.li,{children:"Reduces network congestion"}),"\n",(0,a.jsx)(n.li,{children:"Automatic garbage collection via TTL"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"disadvantages",children:"Disadvantages"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Increased latency (additional network hop to object store)"}),"\n",(0,a.jsx)(n.li,{children:"More infrastructure dependencies (object store required)"}),"\n",(0,a.jsx)(n.li,{children:"Potential consistency issues if claim expires before consumption"}),"\n",(0,a.jsx)(n.li,{children:"Additional operational complexity"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"migration-path",children:"Migration Path"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Phase 1"}),": Implement object store interface and MinIO driver"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Phase 2"}),": Add claim check support to producer pattern"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Phase 3"}),": Add claim check support to consumer pattern"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Phase 4"}),": Add namespace validation in proxy"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Phase 5"}),": Create acceptance tests with MinIO"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Phase 6"}),": Document pattern and create examples"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"alternatives-considered",children:"Alternatives Considered"}),"\n",(0,a.jsx)(n.h3,{id:"1-inline-chunking",children:"1. Inline Chunking"}),"\n",(0,a.jsx)(n.p,{children:"Break large messages into multiple small messages."}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Rejected"}),": Adds complexity to consumer (reassembly), doesn't reduce broker load proportionally."]}),"\n",(0,a.jsx)(n.h3,{id:"2-separate-large-message-queue",children:"2. Separate Large Message Queue"}),"\n",(0,a.jsx)(n.p,{children:"Use different queue for large messages."}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Rejected"}),": Requires dual-queue management, ordering issues, more complex routing."]}),"\n",(0,a.jsx)(n.h3,{id:"3-always-use-object-store",children:"3. Always Use Object Store"}),"\n",(0,a.jsx)(n.p,{children:"Store all payloads in object store, regardless of size."}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Rejected"}),": Unnecessary overhead for small messages, increased latency."]}),"\n",(0,a.jsx)(n.h2,{id:"open-questions",children:"Open Questions"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Multipart Upload"}),": Should we support multipart uploads for very large payloads (>5GB)?"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Encryption"}),": Should claims be encrypted in object store? (Separate RFC)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Bandwidth Throttling"}),": Should we rate-limit object store operations?"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cross-Region"}),": How do claims work in multi-region deployments?"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Claim ID Collision"}),": Use UUID v4 or content-addressed (hash-based)?"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://www.enterpriseintegrationpatterns.com/patterns/messaging/StoreInLibrary.html",children:"Enterprise Integration Patterns: Claim Check"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-premium-messaging",children:"Azure Service Bus: Send large messages using claim check pattern"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-filtering.html",children:"AWS EventBridge: Claim check pattern"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://min.io/docs/minio/linux/index.html",children:"MinIO Documentation"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html",children:"S3 API Reference"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"related-documents",children:"Related Documents"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"ADR-051: MinIO for Claim Check Testing (to be created)"}),"\n",(0,a.jsx)(n.li,{children:"ADR-052: Object Store Interface Design (to be created)"}),"\n",(0,a.jsx)(n.li,{children:"ADR-053: Claim Check TTL and Garbage Collection (to be created)"}),"\n",(0,a.jsx)(n.li,{children:"RFC-031: Message Envelope Protocol (encryption)"}),"\n",(0,a.jsx)(n.li,{children:"RFC-008: Proxy-Plugin Architecture"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);