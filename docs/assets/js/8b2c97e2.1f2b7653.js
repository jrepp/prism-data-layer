"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[1677],{8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var r=s(6540);const i={},a=r.createContext(i);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:n},e.children)}},9733:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"container-plugin-model","title":"ADR-025: Container Plugin Model","description":"Context","source":"@site/../docs-cms/adr/025-container-plugin-model.md","sourceDirName":".","slug":"/container-plugin-model","permalink":"/prism-data-layer/adr/container-plugin-model","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/adr/025-container-plugin-model.md","tags":[{"inline":true,"label":"architecture","permalink":"/prism-data-layer/adr/tags/architecture"},{"inline":true,"label":"deployment","permalink":"/prism-data-layer/adr/tags/deployment"},{"inline":true,"label":"containers","permalink":"/prism-data-layer/adr/tags/containers"},{"inline":true,"label":"plugins","permalink":"/prism-data-layer/adr/tags/plugins"},{"inline":true,"label":"backends","permalink":"/prism-data-layer/adr/tags/backends"}],"version":"current","sidebarPosition":25,"frontMatter":{"title":"ADR-025: Container Plugin Model","status":"Accepted","date":"2025-10-07T00:00:00.000Z","deciders":"Core Team","tags":["architecture","deployment","containers","plugins","backends"]},"sidebar":"adrSidebar","previous":{"title":"ADR-024: Layered Interface Hierarchy","permalink":"/prism-data-layer/adr/layered-interface-hierarchy"},"next":{"title":"ADR-026: Distroless Base Images for Container Components","permalink":"/prism-data-layer/adr/distroless-container-images"}}');var i=s(4848),a=s(8453);const t={title:"ADR-025: Container Plugin Model",status:"Accepted",date:new Date("2025-10-07T00:00:00.000Z"),deciders:"Core Team",tags:["architecture","deployment","containers","plugins","backends"]},l=void 0,o={},c=[{value:"Context",id:"context",level:2},{value:"Decision",id:"decision",level:2},{value:"Rationale",id:"rationale",level:2},{value:"Container Architecture",id:"container-architecture",level:3},{value:"Plugin Contract",id:"plugin-contract",level:3},{value:"Environment Configuration",id:"environment-configuration",level:3},{value:"Kafka Plugin Containers",id:"kafka-plugin-containers",level:3},{value:"Kafka Publisher",id:"kafka-publisher",level:4},{value:"Kafka Consumer",id:"kafka-consumer",level:4},{value:"NATS Plugin Containers",id:"nats-plugin-containers",level:3},{value:"NATS Publisher",id:"nats-publisher",level:4},{value:"NATS Consumer",id:"nats-consumer",level:4},{value:"Paged Reader Plugin",id:"paged-reader-plugin",level:3},{value:"Transact Writer Plugins",id:"transact-writer-plugins",level:3},{value:"Transaction Processor",id:"transaction-processor",level:4},{value:"Mailbox Listener",id:"mailbox-listener",level:4},{value:"Docker Deployment",id:"docker-deployment",level:3},{value:"Docker Compose Example",id:"docker-compose-example",level:3},{value:"Kubernetes Deployment",id:"kubernetes-deployment",level:3},{value:"Alternatives Considered",id:"alternatives-considered",level:3},{value:"Consequences",id:"consequences",level:2},{value:"Positive",id:"positive",level:3},{value:"Negative",id:"negative",level:3},{value:"Neutral",id:"neutral",level:3},{value:"References",id:"references",level:2},{value:"Revision History",id:"revision-history",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,i.jsx)(n.p,{children:"Prism needs a standardized way to deploy backend-specific functionality as containers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Kafka requires publisher and consumer containers"}),"\n",(0,i.jsx)(n.li,{children:"NATS requires publisher and consumer containers"}),"\n",(0,i.jsx)(n.li,{children:"Paged reader requires indexed reader consumer"}),"\n",(0,i.jsx)(n.li,{children:"Transact write requires transaction processor and mailbox listener"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Requirements:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Standard interface"}),": All containers follow same contract"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backend-specific logic"}),": Each backend has optimized implementation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Horizontal scaling"}),": Containers can be replicated"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Health checking"}),": Containers report readiness and liveness"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration"}),": Containers configured via environment or config files"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Observability"}),": Standard metrics and logging"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"decision",children:"Decision"}),"\n",(0,i.jsxs)(n.p,{children:["Implement ",(0,i.jsx)(n.strong,{children:"container plugin model"})," with standardized contracts:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Plugin interface"}),": Standard gRPC or HTTP health/metrics endpoints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backend-specific containers"}),": Optimized for each backend"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Role-based deployment"}),": Publisher, Consumer, Processor, Listener roles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration via environment"}),": 12-factor app principles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Docker/Kubernetes-ready"}),": Standard container packaging"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"rationale",children:"Rationale"}),"\n",(0,i.jsx)(n.h3,{id:"container-architecture",children:"Container Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Prism Core Proxy                           \u2502\n\u2502                  (gRPC Server)                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502\n        \u2502                           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Backend Plugins \u2502        \u2502 Backend Plugins  \u2502\n\u2502 (Containers)    \u2502        \u2502 (Containers)     \u2502\n\u2502                 \u2502        \u2502                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502 \u2502   Kafka     \u2502 \u2502        \u2502 \u2502    NATS      \u2502\u2502\n\u2502 \u2502  Publisher  \u2502 \u2502        \u2502 \u2502  Publisher   \u2502\u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                 \u2502        \u2502                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502 \u2502   Kafka     \u2502 \u2502        \u2502 \u2502    NATS      \u2502\u2502\n\u2502 \u2502  Consumer   \u2502 \u2502        \u2502 \u2502  Consumer    \u2502\u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Reader Plugins    \u2502        \u2502 Transact Plugins \u2502\n\u2502 (Containers)      \u2502        \u2502 (Containers)     \u2502\n\u2502                   \u2502        \u2502                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502   Indexed     \u2502 \u2502        \u2502 \u2502  Transaction \u2502 \u2502\n\u2502 \u2502    Reader     \u2502 \u2502        \u2502 \u2502  Processor   \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                   \u2502        \u2502                  \u2502\n\u2502                   \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502                   \u2502        \u2502 \u2502   Mailbox    \u2502 \u2502\n\u2502                   \u2502        \u2502 \u2502   Listener   \u2502 \u2502\n\u2502                   \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.h3,{id:"plugin-contract",children:"Plugin Contract"}),"\n",(0,i.jsx)(n.p,{children:"All container plugins implement standard interface:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:'// proto/prism/plugin/v1/plugin.proto\nsyntax = "proto3";\n\npackage prism.plugin.v1;\n\nimport "google/protobuf/timestamp.proto";\nimport "google/protobuf/struct.proto";\n\n// Health check service (required for all plugins)\nservice HealthService {\n  // Liveness probe\n  rpc Live(LiveRequest) returns (LiveResponse);\n\n  // Readiness probe\n  rpc Ready(ReadyRequest) returns (ReadyResponse);\n}\n\nmessage LiveRequest {}\n\nmessage LiveResponse {\n  bool alive = 1;\n  google.protobuf.Timestamp timestamp = 2;\n}\n\nmessage ReadyRequest {}\n\nmessage ReadyResponse {\n  bool ready = 1;\n  string message = 2;\n  map<string, string> dependencies = 3;  // Dependency status\n}\n\n// Metrics service (required for all plugins)\nservice MetricsService {\n  // Get plugin metrics (Prometheus format)\n  rpc GetMetrics(MetricsRequest) returns (MetricsResponse);\n}\n\nmessage MetricsRequest {}\n\nmessage MetricsResponse {\n  string metrics = 1;  // Prometheus text format\n}\n\n// Plugin info service (required for all plugins)\nservice PluginInfoService {\n  rpc GetInfo(InfoRequest) returns (InfoResponse);\n}\n\nmessage InfoRequest {}\n\nmessage InfoResponse {\n  string name = 1;\n  string version = 2;\n  string role = 3;  // "publisher", "consumer", "processor", "listener"\n  string backend = 4;  // "kafka", "nats", "postgres", etc.\n  map<string, string> capabilities = 5;\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,i.jsx)(n.p,{children:"All plugins configured via environment variables:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Common to all plugins\nPRISM_PROXY_ENDPOINT=localhost:8980\nPRISM_PLUGIN_ROLE=publisher\nPRISM_BACKEND_TYPE=kafka\nPRISM_NAMESPACE=production\nPRISM_LOG_LEVEL=info\nPRISM_LOG_FORMAT=json\nPRISM_METRICS_PORT=9090\n\n# Kafka-specific\nKAFKA_BROKERS=localhost:9092,localhost:9093\nKAFKA_TOPIC=events\nKAFKA_CONSUMER_GROUP=prism-consumer\nKAFKA_AUTO_OFFSET_RESET=earliest\nKAFKA_COMPRESSION=snappy\n\n# NATS-specific\nNATS_URL=nats://localhost:4222\nNATS_SUBJECT=events.>\nNATS_QUEUE_GROUP=prism-consumers\nNATS_STREAM=EVENTS\n\n# Database-specific\nDATABASE_URL=postgres://user:pass@localhost/db\nDATABASE_POOL_SIZE=10\nDATABASE_TABLE=events\n\n# Mailbox-specific\nMAILBOX_TABLE=mailbox\nMAILBOX_POLL_INTERVAL=1s\nMAILBOX_BATCH_SIZE=100\n"})}),"\n",(0,i.jsx)(n.h3,{id:"kafka-plugin-containers",children:"Kafka Plugin Containers"}),"\n",(0,i.jsx)(n.h4,{id:"kafka-publisher",children:"Kafka Publisher"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// containers/kafka-publisher/src/main.rs\n\nuse rdkafka::producer::{FutureProducer, FutureRecord};\nuse tonic::transport::Channel;\nuse prism_proto::queue::v1::queue_service_client::QueueServiceClient;\n\nstruct KafkaPublisher {\n    producer: FutureProducer,\n    topic: String,\n}\n\nimpl KafkaPublisher {\n    async fn run(&self) -> Result<()> {\n        // Connect to Prism proxy\n        let mut client = QueueServiceClient::connect(\n            env::var("PRISM_PROXY_ENDPOINT")?\n        ).await?;\n\n        // Create session\n        let session = client.create_session(/* ... */).await?;\n\n        // Subscribe to internal queue for messages to publish\n        let messages = self.receive_from_internal_queue().await?;\n\n        // Publish to Kafka\n        for message in messages {\n            let record = FutureRecord::to(&self.topic)\n                .payload(&message.payload)\n                .key(&message.key);\n\n            self.producer.send(record, Duration::from_secs(5)).await?;\n        }\n\n        Ok(())\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    tracing_subscriber::fmt::init();\n\n    let publisher = KafkaPublisher::new()?;\n    publisher.run().await\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"kafka-consumer",children:"Kafka Consumer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// containers/kafka-consumer/src/main.rs\n\nuse rdkafka::consumer::{Consumer, StreamConsumer};\nuse rdkafka::Message;\n\nstruct KafkaConsumer {\n    consumer: StreamConsumer,\n    proxy_client: QueueServiceClient<Channel>,\n}\n\nimpl KafkaConsumer {\n    async fn run(&self) -> Result<()> {\n        // Subscribe to Kafka topic\n        self.consumer.subscribe(&[&self.topic])?;\n\n        loop {\n            match self.consumer.recv().await {\n                Ok(message) => {\n                    // Forward to Prism proxy\n                    self.proxy_client.publish(PublishRequest {\n                        topic: message.topic().to_string(),\n                        payload: message.payload().unwrap().to_vec(),\n                        offset: Some(message.offset()),\n                        partition: Some(message.partition()),\n                    }).await?;\n\n                    // Commit offset\n                    self.consumer.commit_message(&message, CommitMode::Async)?;\n                }\n                Err(e) => {\n                    tracing::error!("Kafka error: {}", e);\n                }\n            }\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"nats-plugin-containers",children:"NATS Plugin Containers"}),"\n",(0,i.jsx)(n.h4,{id:"nats-publisher",children:"NATS Publisher"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"// containers/nats-publisher/src/main.rs\n\nuse async_nats::Client;\n\nstruct NatsPublisher {\n    client: Client,\n    subject: String,\n}\n\nimpl NatsPublisher {\n    async fn run(&self) -> Result<()> {\n        // Connect to Prism proxy for source messages\n        let mut proxy_client = PubSubServiceClient::connect(/* ... */).await?;\n\n        // Subscribe to internal stream\n        let mut stream = proxy_client.subscribe(/* ... */).await?.into_inner();\n\n        // Publish to NATS\n        while let Some(event) = stream.message().await? {\n            self.client.publish(&self.subject, event.payload.into()).await?;\n        }\n\n        Ok(())\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h4,{id:"nats-consumer",children:"NATS Consumer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"// containers/nats-consumer/src/main.rs\n\nuse async_nats::{Client, jetstream};\n\nstruct NatsConsumer {\n    client: Client,\n    stream: String,\n    consumer: String,\n}\n\nimpl NatsConsumer {\n    async fn run(&self) -> Result<()> {\n        let jetstream = jetstream::new(self.client.clone());\n\n        let consumer = jetstream\n            .get_stream(&self.stream)\n            .await?\n            .get_consumer(&self.consumer)\n            .await?;\n\n        let mut messages = consumer.messages().await?;\n\n        // Connect to Prism proxy\n        let mut proxy_client = PubSubServiceClient::connect(/* ... */).await?;\n\n        while let Some(message) = messages.next().await {\n            let message = message?;\n\n            // Forward to Prism proxy\n            proxy_client.publish(PublishRequest {\n                topic: message.subject.clone(),\n                payload: message.payload.to_vec(),\n                metadata: Default::default(),\n            }).await?;\n\n            // Ack message\n            message.ack().await?;\n        }\n\n        Ok(())\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"paged-reader-plugin",children:"Paged Reader Plugin"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// containers/indexed-reader/src/main.rs\n\nuse sqlx::PgPool;\n\nstruct IndexedReader {\n    pool: PgPool,\n    table: String,\n    index_column: String,\n}\n\nimpl IndexedReader {\n    async fn run(&self) -> Result<()> {\n        // Connect to Prism proxy\n        let mut proxy_client = ReaderServiceClient::connect(/* ... */).await?;\n\n        // Process read requests\n        loop {\n            // Get read request from internal queue\n            let request = self.receive_read_request().await?;\n\n            // Query database with index\n            let rows = sqlx::query(&format!(\n                "SELECT * FROM {} WHERE {} > $1 ORDER BY {} LIMIT $2",\n                self.table, self.index_column, self.index_column\n            ))\n            .bind(&request.cursor)\n            .bind(request.page_size)\n            .fetch_all(&self.pool)\n            .await?;\n\n            // Stream results back\n            for row in rows {\n                proxy_client.send_page(/* ... */).await?;\n            }\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"transact-writer-plugins",children:"Transact Writer Plugins"}),"\n",(0,i.jsx)(n.h4,{id:"transaction-processor",children:"Transaction Processor"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// containers/transact-processor/src/main.rs\n\nuse sqlx::{PgPool, Transaction};\n\nstruct TransactProcessor {\n    pool: PgPool,\n}\n\nimpl TransactProcessor {\n    async fn process_transaction(&self, req: WriteRequest) -> Result<WriteResponse> {\n        let mut tx = self.pool.begin().await?;\n\n        // Write to data table\n        let data_result = self.write_data(&mut tx, req.data).await?;\n\n        // Write to mailbox table\n        let mailbox_result = self.write_mailbox(&mut tx, req.mailbox).await?;\n\n        // Commit transaction\n        tx.commit().await?;\n\n        Ok(WriteResponse {\n            transaction_id: uuid::Uuid::new_v4().to_string(),\n            committed: true,\n            data_result,\n            mailbox_result,\n        })\n    }\n\n    async fn write_data(&self, tx: &mut Transaction<\'_, Postgres>, data: DataWrite) -> Result<DataWriteResult> {\n        let result = sqlx::query(&data.to_sql())\n            .execute(&mut **tx)\n            .await?;\n\n        Ok(DataWriteResult {\n            rows_affected: result.rows_affected() as i64,\n            generated_values: Default::default(),\n        })\n    }\n\n    async fn write_mailbox(&self, tx: &mut Transaction<\'_, Postgres>, mailbox: MailboxWrite) -> Result<MailboxWriteResult> {\n        let result = sqlx::query(\n            "INSERT INTO mailbox (mailbox_id, message, metadata) VALUES ($1, $2, $3) RETURNING id, sequence"\n        )\n        .bind(&mailbox.mailbox_id)\n        .bind(&mailbox.message)\n        .bind(&mailbox.metadata)\n        .fetch_one(&mut **tx)\n        .await?;\n\n        Ok(MailboxWriteResult {\n            message_id: result.get("id"),\n            sequence: result.get("sequence"),\n        })\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"mailbox-listener",children:"Mailbox Listener"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'// containers/mailbox-listener/src/main.rs\n\nuse sqlx::PgPool;\n\nstruct MailboxListener {\n    pool: PgPool,\n    mailbox_id: String,\n    poll_interval: Duration,\n}\n\nimpl MailboxListener {\n    async fn run(&self) -> Result<()> {\n        let mut last_sequence = 0i64;\n\n        loop {\n            // Poll for new messages\n            let messages = sqlx::query_as::<_, MailboxMessage>(\n                "SELECT * FROM mailbox WHERE mailbox_id = $1 AND sequence > $2 ORDER BY sequence LIMIT $3"\n            )\n            .bind(&self.mailbox_id)\n            .bind(last_sequence)\n            .bind(100)\n            .fetch_all(&self.pool)\n            .await?;\n\n            for message in messages {\n                // Process message\n                self.process_message(&message).await?;\n\n                // Update last sequence\n                last_sequence = message.sequence;\n\n                // Mark as processed\n                sqlx::query("UPDATE mailbox SET processed = true WHERE id = $1")\n                    .bind(&message.id)\n                    .execute(&self.pool)\n                    .await?;\n            }\n\n            tokio::time::sleep(self.poll_interval).await;\n        }\n    }\n\n    async fn process_message(&self, message: &MailboxMessage) -> Result<()> {\n        // Forward to downstream system, trigger workflow, etc.\n        tracing::info!("Processing mailbox message: {:?}", message);\n        Ok(())\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"docker-deployment",children:"Docker Deployment"}),"\n",(0,i.jsx)(n.p,{children:"Each plugin is a separate Docker image:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-dockerfile",children:'# Dockerfile.kafka-publisher\nFROM rust:1.75 as builder\nWORKDIR /app\nCOPY . .\nRUN cargo build --release --bin kafka-publisher\n\nFROM debian:bookworm-slim\nRUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*\nCOPY --from=builder /app/target/release/kafka-publisher /usr/local/bin/\nENTRYPOINT ["kafka-publisher"]\n'})}),"\n",(0,i.jsx)(n.h3,{id:"docker-compose-example",children:"Docker Compose Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# docker-compose.plugins.yml\nversion: \'3.8\'\n\nservices:\n  prism-proxy:\n    image: prism/proxy:latest\n    ports:\n      - "8980:8980"\n      - "9090:9090"\n    environment:\n      - RUST_LOG=info\n\n  kafka-publisher:\n    image: prism/kafka-publisher:latest\n    depends_on:\n      - prism-proxy\n      - kafka\n    environment:\n      - PRISM_PROXY_ENDPOINT=prism-proxy:8980\n      - PRISM_PLUGIN_ROLE=publisher\n      - KAFKA_BROKERS=kafka:9092\n      - KAFKA_TOPIC=events\n    deploy:\n      replicas: 2\n\n  kafka-consumer:\n    image: prism/kafka-consumer:latest\n    depends_on:\n      - prism-proxy\n      - kafka\n    environment:\n      - PRISM_PROXY_ENDPOINT=prism-proxy:8980\n      - PRISM_PLUGIN_ROLE=consumer\n      - KAFKA_BROKERS=kafka:9092\n      - KAFKA_TOPIC=events\n      - KAFKA_CONSUMER_GROUP=prism-consumers\n    deploy:\n      replicas: 3\n\n  nats-publisher:\n    image: prism/nats-publisher:latest\n    depends_on:\n      - prism-proxy\n      - nats\n    environment:\n      - PRISM_PROXY_ENDPOINT=prism-proxy:8980\n      - NATS_URL=nats://nats:4222\n      - NATS_SUBJECT=events.>\n\n  mailbox-listener:\n    image: prism/mailbox-listener:latest\n    depends_on:\n      - prism-proxy\n      - postgres\n    environment:\n      - PRISM_PROXY_ENDPOINT=prism-proxy:8980\n      - DATABASE_URL=postgres://prism:password@postgres/prism\n      - MAILBOX_ID=system\n      - MAILBOX_POLL_INTERVAL=1s\n'})}),"\n",(0,i.jsx)(n.h3,{id:"kubernetes-deployment",children:"Kubernetes Deployment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# k8s/kafka-consumer-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prism-kafka-consumer\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: prism-kafka-consumer\n  template:\n    metadata:\n      labels:\n        app: prism-kafka-consumer\n    spec:\n      containers:\n      - name: kafka-consumer\n        image: prism/kafka-consumer:latest\n        env:\n        - name: PRISM_PROXY_ENDPOINT\n          value: "prism-proxy:8980"\n        - name: KAFKA_BROKERS\n          value: "kafka-0.kafka:9092,kafka-1.kafka:9092"\n        - name: KAFKA_TOPIC\n          value: "events"\n        ports:\n        - containerPort: 9090\n          name: metrics\n        livenessProbe:\n          httpGet:\n            path: /health/live\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: "128Mi"\n            cpu: "100m"\n          limits:\n            memory: "512Mi"\n            cpu: "500m"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"alternatives-considered",children:"Alternatives Considered"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monolithic proxy with all backend logic"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: Simpler deployment"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Tight coupling, hard to scale independently"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Doesn't support horizontal scaling per backend"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Sidecar pattern"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: Co-located with proxy"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Resource overhead, complex orchestration"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Separate containers more flexible"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Embedded plugins (dynamic libraries)"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: No network overhead"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Language lock-in, version conflicts, crash propagation"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Containers provide better isolation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"consequences",children:"Consequences"}),"\n",(0,i.jsx)(n.h3,{id:"positive",children:"Positive"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Horizontal scaling"}),": Scale each plugin independently"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backend optimization"}),": Plugin optimized for specific backend"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isolation"}),": Plugin failures don't crash proxy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Standard deployment"}),": Docker/Kubernetes patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Observability"}),": Standard metrics/health endpoints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Language flexibility"}),": Plugins can be written in any language"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"negative",children:"Negative"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"More containers"}),": Increased deployment complexity"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Network overhead"}),": gRPC calls between proxy and plugins"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Resource usage"}),": Each container has overhead"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"neutral",children:"Neutral"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration"}),": Environment variables (12-factor)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitoring"}),": Standard Prometheus metrics"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://12factor.net/",children:"12-Factor App"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",children:"Kubernetes Deployment Patterns"})}),"\n",(0,i.jsx)(n.li,{children:"ADR-008: Observability Strategy"}),"\n",(0,i.jsx)(n.li,{children:"ADR-024: Layered Interface Hierarchy"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"revision-history",children:"Revision History"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"2025-10-07: Initial draft and acceptance"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);