"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[4800],{28453:(e,a,t)=>{t.d(a,{R:()=>s,x:()=>r});var i=t(96540);const n={},o=i.createContext(n);function s(e){const a=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),i.createElement(o.Provider,{value:a},e.children)}},61638:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"netflix-data-evolve-migration","title":"Schema Evolution & Data Migrations","description":"Netflix\'s Data Gateway and the broader data platform handle schema evolution and data migrations by embracing abstraction, automation, and a schema-first, federated approach. The core principle is to manage these complex processes at the platform level, isolating application developers from the underlying database mechanics and changes.","source":"@site/../docs-cms/netflix/data-evolve-migration.md","sourceDirName":".","slug":"/netflix-data-evolve-migration","permalink":"/prism-data-layer/netflix/netflix-data-evolve-migration","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/netflix/data-evolve-migration.md","tags":[{"inline":true,"label":"netflix","permalink":"/prism-data-layer/netflix/tags/netflix"},{"inline":true,"label":"migration","permalink":"/prism-data-layer/netflix/tags/migration"},{"inline":true,"label":"schema","permalink":"/prism-data-layer/netflix/tags/schema"},{"inline":true,"label":"evolution","permalink":"/prism-data-layer/netflix/tags/evolution"}],"version":"current","sidebarPosition":6,"frontMatter":{"id":"netflix-data-evolve-migration","title":"Schema Evolution & Data Migrations","sidebar_label":"Schema Evolution","sidebar_position":6,"tags":["netflix","migration","schema","evolution"]},"sidebar":"netflixSidebar","previous":{"title":"Write-Ahead Log","permalink":"/prism-data-layer/netflix/netflix-write-ahead-log"},"next":{"title":"Dual-Write Migration","permalink":"/prism-data-layer/netflix/netflix-dual-write-migration"}}');var n=t(74848),o=t(28453);const s={id:"netflix-data-evolve-migration",title:"Schema Evolution & Data Migrations",sidebar_label:"Schema Evolution",sidebar_position:6,tags:["netflix","migration","schema","evolution"]},r=void 0,l={},c=[];function d(e){const a={p:"p",...(0,o.R)(),...e.components};return(0,n.jsx)(a.p,{children:'Netflix\'s Data Gateway and the broader data platform handle schema evolution and data migrations by embracing abstraction, automation, and a schema-first, federated approach. The core principle is to manage these complex processes at the platform level, isolating application developers from the underlying database mechanics and changes.\nSchema evolution at the application layer\nThe Data Gateway provides a stable, versioned API contract to application developers, which decouples them from changes in the underlying database schemas.\nFederated GraphQL: For many services, particularly for their API layer, Netflix uses a federated GraphQL architecture. Each microservice publishes its own schema fragment to a central schema registry. The API gateway aggregates these fragments into a single, federated graph for client consumption.\nDeprecation workflow: When a schema needs to change, the GraphQL deprecation feature is used. The schema registry tracks the usage of every field. Once usage statistics show that a deprecated field is no longer in use, a backward-incompatible change can be safely performed.\nDecoupled APIs: This schema-first approach deliberately decouples the client-facing GraphQL API from the underlying gRPC APIs and database schemas. This allows teams to evolve their services independently without forcing coordinated updates across the entire system.\nSchema evolution in the data platform\nFor the asynchronous data movement pipelines within the Netflix Data Mesh, a more robust and automated system is in place.\nAvro and schema registry: The platform uses Apache Avro for a common, compact data format and maintains a schema registry to manage schema versions. This allows the platform to enforce strict schema validation and compatibility checks.\nCompatibility checks: The platform validates schema changes for compatibility. Incompatible changes, such as removing a field that a consumer depends on, are automatically flagged, and the pipeline is paused to notify the owner. This prevents downstream consumers from breaking unexpectedly.\nAutomated pipeline updates: For compatible changes, the platform is designed to automatically propagate schema changes downstream and update pipelines without manual intervention.\nConsumer opt-in/opt-out: Consumers can choose how they handle schema evolution. They can "opt-in" to automatically accept new fields from the upstream source, or "opt-out" to only use a defined subset of fields. This gives control to the consumer while preserving flexibility.\nHandling data migrations\nMigrations are a necessary reality, whether for replacing a legacy database, updating a schema in place, or moving to a completely new system. Netflix\'s approach uses custom tooling and careful automation to minimize risk.\nShadowing and dual-writes: For migrating from a legacy database to a new one, Netflix employs a dual-write and shadowing strategy. A "data integrator" service (often part of the Data Gateway) writes to both the old and new databases simultaneously. This allows the team to:\nTest the new database with production traffic.\nCompare the data written to both databases to catch discrepancies.\nPhased migration: The migration from Oracle to Cassandra was a multi-year effort that involved replicating data between different services and gradually transitioning functionality. For example, some early cloud migrations involved moving data with custom automation and leveraging services like AWS Database Migration Service.\nCanary deployments: The Data Gateway and other services use canary analysis during deployments. This allows Netflix to detect performance regressions and functional failures in a small, isolated environment before rolling out changes to the entire fleet. For instance, a bug involving multi-partition reads was caught and fixed within the gateway itself, without the application teams even noticing.\nResilience and automation: The overarching strategy is to embrace failure and build resilient, automated tooling. The multi-year, large-scale migrations\u2014like the monolith-to-microservices transition and the cloud migration\u2014succeeded due to investments in sophisticated operational tools and automation'})}function m(e={}){const{wrapper:a}={...(0,o.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}}}]);