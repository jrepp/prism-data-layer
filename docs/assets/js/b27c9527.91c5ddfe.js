"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[2962],{28453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>r});var s=a(96540);const c={},i=s.createContext(c);function t(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:t(e.components),s.createElement(i.Provider,{value:n},e.children)}},62606:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>o,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"adr-010","title":"Caching Layer Design","description":"Context","source":"@site/../docs-cms/adr/adr-010-caching-layer.md","sourceDirName":".","slug":"/adr-010","permalink":"/prism-data-layer/adr/adr-010","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/adr/adr-010-caching-layer.md","tags":[{"inline":true,"label":"performance","permalink":"/prism-data-layer/adr/tags/performance"},{"inline":true,"label":"architecture","permalink":"/prism-data-layer/adr/tags/architecture"}],"version":"current","frontMatter":{"date":"2025-10-05T00:00:00.000Z","deciders":"Core Team","doc_uuid":"5da63362-c053-45d3-a554-b1699120e310","id":"adr-010","project_id":"prism-data-layer","status":"Accepted","tags":["performance","architecture"],"title":"Caching Layer Design"},"sidebar":"adrSidebar","previous":{"title":"Shadow Traffic for Migrations \u2022 ADR-009","permalink":"/prism-data-layer/adr/adr-009"},"next":{"title":"Implementation Roadmap and Next Steps \u2022 ADR-011","permalink":"/prism-data-layer/adr/adr-011"}}');var c=a(74848),i=a(28453);const t={date:new Date("2025-10-05T00:00:00.000Z"),deciders:"Core Team",doc_uuid:"5da63362-c053-45d3-a554-b1699120e310",id:"adr-010",project_id:"prism-data-layer",status:"Accepted",tags:["performance","architecture"],title:"Caching Layer Design"},r=void 0,l={},d=[{value:"Context",id:"context",level:2},{value:"Decision",id:"decision",level:2},{value:"Rationale",id:"rationale",level:2},{value:"Look-Aside Cache Pattern",id:"look-aside-cache-pattern",level:3},{value:"Cache Metrics",id:"cache-metrics",level:3},{value:"Alternatives Considered",id:"alternatives-considered",level:3},{value:"Consequences",id:"consequences",level:2},{value:"Positive",id:"positive",level:3},{value:"Negative",id:"negative",level:3},{value:"Neutral",id:"neutral",level:3},{value:"Implementation Notes",id:"implementation-notes",level:2},{value:"Graceful Degradation",id:"graceful-degradation",level:3},{value:"Cache Warming",id:"cache-warming",level:3},{value:"Cache Backends",id:"cache-backends",level:3},{value:"References",id:"references",level:2},{value:"Revision History",id:"revision-history",level:2}];function h(e){const n={a:"a",b:"b",code:"code",dyn:"dyn",em:"em",h1:"h1",h2:"h2",h3:"h3",item:"item",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",u8:"u8",ul:"ul",...(0,i.R)(),...e.components};return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,c.jsx)(n.p,{children:"Many workloads are read-heavy with repeated access to the same data:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"User profiles fetched on every page load"}),"\n",(0,c.jsx)(n.li,{children:"Configuration data read frequently"}),"\n",(0,c.jsx)(n.li,{children:"Popular content accessed by millions"}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"Caching reduces:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Backend load (fewer database queries)"}),"\n",(0,c.jsx)(n.li,{children:"Latency (memory faster than disk)"}),"\n",(0,c.jsx)(n.li,{children:"Costs (fewer backend resources needed)"}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"Netflix's KV DAL includes look-aside caching with EVCache (memcached)."}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"Problem"}),": Should Prism include caching, and if so, how?"]}),"\n",(0,c.jsx)(n.h2,{id:"decision",children:"Decision"}),"\n",(0,c.jsxs)(n.p,{children:["Implement ",(0,c.jsx)(n.strong,{children:"optional look-aside caching"})," at the proxy layer, configurable per-namespace."]}),"\n",(0,c.jsx)(n.h2,{id:"rationale",children:"Rationale"}),"\n",(0,c.jsx)(n.h3,{id:"look-aside-cache-pattern",children:"Look-Aside Cache Pattern"}),"\n",(0,c.jsx)(n.p,{children:"Read Path:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Client\u2502\u2500\u2500\u2500\u25b6\u2502 Proxy \u2502\u2500\u2500\u2500\u25b6\u2502Cache \u2502\u2500\u2500\u2500\u25b6\u2502 Backend  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502            \u2502              \u2502\n\u2502    Cache   \u2502              \u2502\n\u2502    Hit \u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                           \u2502\n\u2502    Cache Miss \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502                           \u2502\n\u2502    Populate Cache \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502\n\u25bc\nResponse"}),"\n",(0,c.jsx)(n.p,{children:"Write Path:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Client\u2502\u2500\u2500\u2500\u25b6\u2502 Proxy \u2502\u2500\u2500\u2500\u25b6\u2502Backend\u2500\u2500\u2500\u25b6\u2502 (Write)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502            \u2502\n\u2502    Invalidate\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-text",children:"\n### Cache Configuration\n\n"})}),"\n",(0,c.jsx)(n.p,{children:"namespace: user-profiles"}),"\n",(0,c.jsx)(n.p,{children:"cache:\nenabled: true\nbackend: redis  # or memcached\nttl_seconds: 300  # 5 minutes\nmax_item_size_bytes: 1048576  # 1 MB"}),"\n",(0,c.jsx)(n.h1,{id:"invalidation-strategy",children:"Invalidation strategy"}),"\n",(0,c.jsx)(n.p,{children:"invalidation: write_through  # or ttl_only"}),"\n",(0,c.jsx)(n.h1,{id:"connection",children:"Connection"}),"\n",(0,c.jsx)(n.p,{children:"connection:\nendpoints: [redis://cache-cluster-1:6379]\npool_size: 50"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-text",children:"\n### Implementation\n\n"})}),"\n",(0,c.jsxs)(n.p,{children:["#[async_trait]\npub trait CacheBackend: Send + Sync {\nasync fn get(&self, key: &str) -> Result<Option<Vec",(0,c.jsx)(n.u8,{children:">>;\nasync fn set(&self, key: &str, value: &[u8], ttl: Duration) -> Result<()>;\nasync fn delete(&self, key: &str) -> Result<()>;\n}"})]}),"\n",(0,c.jsx)(n.p,{children:"pub struct RedisCache {\npool: redis::aio::ConnectionManager,\n}"}),"\n",(0,c.jsxs)(n.p,{children:["#[async_trait]\nimpl CacheBackend for RedisCache {\nasync fn get(&self, key: &str) -> Result<Option<Vec",(0,c.jsxs)(n.u8,{children:[">> {\nlet mut conn = self.pool.clone();\nlet result: Option<Vec",(0,c.jsx)(n.u8,{children:"> = conn.get(key).await?;\nOk(result)\n}"})]})]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{children:"async fn set(&self, key: &str, value: &[u8], ttl: Duration) -> Result<()> {\n    let mut conn = self.pool.clone();\n    conn.set_ex(key, value, ttl.as_secs() as usize).await?;\n    Ok(())\n}\n\nasync fn delete(&self, key: &str) -> Result<()> {\n    let mut conn = self.pool.clone();\n    conn.del(key).await?;\n    Ok(())\n}\n"})}),"\n",(0,c.jsx)(n.p,{children:"}"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-text",children:"\n### Cache-Aware Backend Wrapper\n\n"})}),"\n",(0,c.jsxs)(n.p,{children:["pub struct CachedBackend<B: KeyValueBackend> {\nbackend: B,\ncache: Option<Arc",(0,c.jsx)(n.dyn,{cachebackend:"",children:">,\nconfig: CacheConfig,\n}"})]}),"\n",(0,c.jsxs)(n.p,{children:["#[async_trait]\nimpl<B: KeyValueBackend> KeyValueBackend for CachedBackend",(0,c.jsxs)(n.b,{children:[" {\nasync fn get(&self, namespace: &str, id: &str, keys: Vec<&[u8]>) -> Result<Vec",(0,c.jsx)(n.item,{children:"> {\nlet cache = match &self.cache {\nSome(c) => c,\nNone => return self.backend.get(namespace, id, keys).await,\n};"})]})]}),(0,c.jsxs)(n.b,{children:["\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{children:'    let mut cached_items = Vec::new();\n    let mut missing_keys = Vec::new();\n\n    // Check cache for each key\n    for key in &keys {\n        let cache_key = format!("{}:{}:{}", namespace, id, hex::encode(key));\n\n        match cache.get(&cache_key).await? {\n            Some(value) => {\n                metrics::CACHE_HITS.inc();\n                cached_items.push(Item {\n                    key: key.to_vec(),\n                    value,\n                    metadata: None,\n                });\n            }\n            None => {\n                metrics::CACHE_MISSES.inc();\n                missing_keys.push(*key);\n            }\n        }\n    }\n\n    // Fetch missing keys from backend\n    if !missing_keys.is_empty() {\n        let backend_items = self.backend.get(namespace, id, missing_keys).await?;\n\n        // Populate cache\n        for item in &backend_items {\n            let cache_key = format!("{}:{}:{}", namespace, id, hex::encode(&item.key));\n            cache.set(&cache_key, &item.value, self.config.ttl).await?;\n        }\n\n        cached_items.extend(backend_items);\n    }\n\n    Ok(cached_items)\n}\n\nasync fn put(&self, namespace: &str, id: &str, items: Vec<Item>) -> Result<()> {\n    // Write to backend first\n    self.backend.put(namespace, id, items.clone()).await?;\n\n    // Invalidate cache\n    if let Some(cache) = &self.cache {\n        for item in &items {\n            let cache_key = format!("{}:{}:{}", namespace, id, hex::encode(&item.key));\n\n            match self.config.invalidation {\n                Invalidation::WriteThrough => {\n                    // Update cache with new value\n                    cache.set(&cache_key, &item.value, self.config.ttl).await?;\n                }\n                Invalidation::TtlOnly => {\n                    // Delete from cache, let next read repopulate\n                    cache.delete(&cache_key).await?;\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n'})}),"\n",(0,c.jsx)(n.p,{children:"}"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-text",children:'\n### Cache Key Design\n\nFormat: {namespace}:{id}:{key_hex}\n\nExamples:\nuser-profiles:user123:70726f66696c65  (key="profile")\nuser-profiles:user123:73657474696e6773 (key="settings")\n'})}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"Why hex encoding"}),"?"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Keys may contain binary data"}),"\n",(0,c.jsx)(n.li,{children:"Redis keys must be strings"}),"\n",(0,c.jsx)(n.li,{children:"Hex is safe, readable"}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"cache-metrics",children:"Cache Metrics"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-rust",children:'lazy_static! {\n    static ref CACHE_HITS: CounterVec = register_counter_vec!(\n        "prism_cache_hits_total",\n        "Cache hits",\n        &["namespace"]\n    ).unwrap();\n\n    static ref CACHE_MISSES: CounterVec = register_counter_vec!(\n        "prism_cache_misses_total",\n        "Cache misses",\n        &["namespace"]\n    ).unwrap();\n\n    static ref CACHE_HIT_RATE: GaugeVec = register_gauge_vec!(\n        "prism_cache_hit_rate",\n        "Cache hit rate (0-1)",\n        &["namespace"]\n    ).unwrap();\n}\n\n// Calculate hit rate periodically\nfn update_cache_hit_rate(namespace: &str) {\n    let hits = CACHE_HITS.with_label_values(&[namespace]).get();\n    let misses = CACHE_MISSES.with_label_values(&[namespace]).get();\n    let total = hits + misses;\n\n    if total > 0 {\n        let hit_rate = hits as f64 / total as f64;\n        CACHE_HIT_RATE.with_label_values(&[namespace]).set(hit_rate);\n    }\n}\n'})}),"\n",(0,c.jsx)(n.h3,{id:"alternatives-considered",children:"Alternatives Considered"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"No Caching"})," (backend only)"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Pros: Simpler"}),"\n",(0,c.jsx)(n.li,{children:"Cons: Higher latency, higher backend load"}),"\n",(0,c.jsx)(n.li,{children:"Rejected: Caching is essential for read-heavy workloads"}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"Write-Through Cache"})," (cache is source of truth)"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Pros: Always consistent"}),"\n",(0,c.jsx)(n.li,{children:"Cons: Cache becomes critical dependency, harder to scale"}),"\n",(0,c.jsx)(n.li,{children:"Rejected: Increases risk"}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"In-Proxy Memory Cache"})," (no external cache)"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Pros: No extra dependency, ultra-fast"}),"\n",(0,c.jsx)(n.li,{children:"Cons: Memory pressure on proxy, no sharing between shards"}),"\n",(0,c.jsx)(n.li,{children:"Rejected: Doesn't scale"}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:["\n",(0,c.jsx)(n.p,{children:(0,c.jsx)(n.strong,{children:"Client-Side Caching"})}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"Pros: Zero proxy overhead"}),"\n",(0,c.jsx)(n.li,{children:"Cons: Inconsistency, cache invalidation complexity"}),"\n",(0,c.jsx)(n.li,{children:"Rejected: Let platform handle it"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"consequences",children:"Consequences"}),"\n",(0,c.jsx)(n.h3,{id:"positive",children:"Positive"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Lower Latency"}),": Cache hits are 10-100x faster than backend"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Reduced Backend Load"}),": Fewer queries to database"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Cost Savings"}),": Smaller backend instances needed"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Optional"}),": Namespaces can opt out if not needed"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"negative",children:"Negative"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Eventual Consistency"}),": Cache may be stale until TTL expires\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.em,{children:"Mitigation"}),": Short TTL for frequently-changing data"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Extra Dependency"}),": Redis/memcached must be available\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.em,{children:"Mitigation"}),": Degrade gracefully on cache failure"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Memory Cost"}),": Cache requires memory\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.em,{children:"Mitigation"}),": Right-size cache, use eviction policies"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"neutral",children:"Neutral"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Cache Invalidation"}),": Classic hard problem\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"TTL + write-through handles most cases"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"implementation-notes",children:"Implementation Notes"}),"\n",(0,c.jsx)(n.h3,{id:"graceful-degradation",children:"Graceful Degradation"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-rust",children:"async fn get_with_cache_fallback(\n    &self,\n    namespace: &str,\n    id: &str,\n    keys: Vec<&[u8]>,\n) -> Result<Vec<Item>> {\n    // Try cache first\n    match self.get_from_cache(namespace, id, &keys).await {\n        Ok(items) => Ok(items),\n        Err(CacheError::Unavailable) => {\n            // Cache down, go straight to backend\n            metrics::CACHE_UNAVAILABLE.inc();\n            self.backend.get(namespace, id, keys).await\n        }\n        Err(e) => Err(e.into()),\n    }\n}\n"})}),"\n",(0,c.jsx)(n.h3,{id:"cache-warming",children:"Cache Warming"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-rust",children:'pub async fn warm_cache(&self, namespace: &str) -> Result<()> {\n    // Preload hot data into cache\n    let hot_keys = self.get_hot_keys(namespace).await?;\n\n    for key in hot_keys {\n        let items = self.backend.get(namespace, &key.id, vec![&key.key]).await?;\n        for item in items {\n            let cache_key = format!("{}:{}:{}", namespace, key.id, hex::encode(&item.key));\n            self.cache.set(&cache_key, &item.value, self.config.ttl).await?;\n        }\n    }\n\n    Ok(())\n}\n'})}),"\n",(0,c.jsx)(n.h3,{id:"cache-backends",children:"Cache Backends"}),"\n",(0,c.jsx)(n.p,{children:"Support multiple cache backends:"}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-rust",children:"pub enum CacheBackendType {\n    Redis,\n    Memcached,\n    InMemory,  // For testing\n}\n\nimpl CacheBackendType {\n    pub fn create(&self, config: &CacheConfig) -> Result<Arc<dyn CacheBackend>> {\n        match self {\n            Self::Redis => Ok(Arc::new(RedisCache::new(config)?)),\n            Self::Memcached => Ok(Arc::new(MemcachedCache::new(config)?)),\n            Self::InMemory => Ok(Arc::new(InMemoryCache::new(config)?)),\n        }\n    }\n}\n"})}),"\n",(0,c.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.a,{href:"https://netflixtechblog.com/",children:"Netflix KV DAL: Caching"})}),"\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.a,{href:"https://redis.io/docs/manual/patterns/",children:"Redis Best Practices"})}),"\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.a,{href:"https://memcached.org/",children:"Memcached Documentation"})}),"\n",(0,c.jsx)(n.li,{children:(0,c.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside",children:"Cache Aside Pattern"})}),"\n",(0,c.jsx)(n.li,{children:"ADR-005: Backend Plugin Architecture"}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"revision-history",children:"Revision History"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"2025-10-05: Initial draft and acceptance"}),"\n"]}),"\n"]})]})}function o(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,c.jsx)(n,{...e,children:(0,c.jsx)(h,{...e})}):h(e)}}}]);