"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[7036],{1948:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>o,frontMatter:()=>t,metadata:()=>c,toc:()=>d});const c=JSON.parse('{"id":"caching-layer","title":"ADR-010: Caching Layer Design","description":"Context","source":"@site/../docs-cms/adr/010-caching-layer.md","sourceDirName":".","slug":"/caching-layer","permalink":"/prism-data-layer/adr/caching-layer","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/adr/010-caching-layer.md","tags":[{"inline":true,"label":"performance","permalink":"/prism-data-layer/adr/tags/performance"},{"inline":true,"label":"architecture","permalink":"/prism-data-layer/adr/tags/architecture"}],"version":"current","sidebarPosition":10,"frontMatter":{"title":"ADR-010: Caching Layer Design","status":"Accepted","date":"2025-10-05T00:00:00.000Z","deciders":"Core Team","tags":["performance","architecture"]},"sidebar":"adrSidebar","previous":{"title":"ADR-009: Shadow Traffic for Migrations","permalink":"/prism-data-layer/adr/shadow-traffic-migrations"},"next":{"title":"ADR-011: Implementation Roadmap and Next Steps","permalink":"/prism-data-layer/adr/implementation-roadmap"}}');var i=a(4848),s=a(8453);const t={title:"ADR-010: Caching Layer Design",status:"Accepted",date:new Date("2025-10-05T00:00:00.000Z"),deciders:"Core Team",tags:["performance","architecture"]},r=void 0,l={},d=[{value:"Context",id:"context",level:2},{value:"Decision",id:"decision",level:2},{value:"Rationale",id:"rationale",level:2},{value:"Look-Aside Cache Pattern",id:"look-aside-cache-pattern",level:3},{value:"Cache Configuration",id:"cache-configuration",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Cache-Aware Backend Wrapper",id:"cache-aware-backend-wrapper",level:3},{value:"Cache Key Design",id:"cache-key-design",level:3},{value:"Cache Metrics",id:"cache-metrics",level:3},{value:"Alternatives Considered",id:"alternatives-considered",level:3},{value:"Consequences",id:"consequences",level:2},{value:"Positive",id:"positive",level:3},{value:"Negative",id:"negative",level:3},{value:"Neutral",id:"neutral",level:3},{value:"Implementation Notes",id:"implementation-notes",level:2},{value:"Graceful Degradation",id:"graceful-degradation",level:3},{value:"Cache Warming",id:"cache-warming",level:3},{value:"Cache Backends",id:"cache-backends",level:3},{value:"References",id:"references",level:2},{value:"Revision History",id:"revision-history",level:2}];function h(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,i.jsx)(n.p,{children:"Many workloads are read-heavy with repeated access to the same data:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"User profiles fetched on every page load"}),"\n",(0,i.jsx)(n.li,{children:"Configuration data read frequently"}),"\n",(0,i.jsx)(n.li,{children:"Popular content accessed by millions"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Caching reduces:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Backend load (fewer database queries)"}),"\n",(0,i.jsx)(n.li,{children:"Latency (memory faster than disk)"}),"\n",(0,i.jsx)(n.li,{children:"Costs (fewer backend resources needed)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Netflix's KV DAL includes look-aside caching with EVCache (memcached)."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Should Prism include caching, and if so, how?"]}),"\n",(0,i.jsx)(n.h2,{id:"decision",children:"Decision"}),"\n",(0,i.jsxs)(n.p,{children:["Implement ",(0,i.jsx)(n.strong,{children:"optional look-aside caching"})," at the proxy layer, configurable per-namespace."]}),"\n",(0,i.jsx)(n.h2,{id:"rationale",children:"Rationale"}),"\n",(0,i.jsx)(n.h3,{id:"look-aside-cache-pattern",children:"Look-Aside Cache Pattern"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Read Path:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Client\u2502\u2500\u2500\u2500\u25b6\u2502 Proxy \u2502\u2500\u2500\u2500\u25b6\u2502Cache \u2502\u2500\u2500\u2500\u25b6\u2502 Backend  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502            \u2502              \u2502\n                \u2502    Cache   \u2502              \u2502\n                \u2502    Hit \u2500\u2500\u2500\u2500\u2518              \u2502\n                \u2502                           \u2502\n                \u2502    Cache Miss \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                           \u2502\n                \u2502    Populate Cache \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n             Response\n\nWrite Path:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Client\u2502\u2500\u2500\u2500\u25b6\u2502 Proxy \u2502\u2500\u2500\u2500\u25b6\u2502Backend\u2500\u2500\u2500\u25b6\u2502 (Write)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502            \u2502\n                \u2502    Invalidate\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502\n"})}),"\n",(0,i.jsx)(n.h3,{id:"cache-configuration",children:"Cache Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"namespace: user-profiles\n\ncache:\n  enabled: true\n  backend: redis  # or memcached\n  ttl_seconds: 300  # 5 minutes\n  max_item_size_bytes: 1048576  # 1 MB\n\n  # Invalidation strategy\n  invalidation: write_through  # or ttl_only\n\n  # Connection\n  connection:\n    endpoints: [redis://cache-cluster-1:6379]\n    pool_size: 50\n"})}),"\n",(0,i.jsx)(n.h3,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"#[async_trait]\npub trait CacheBackend: Send + Sync {\n    async fn get(&self, key: &str) -> Result<Option<Vec<u8>>>;\n    async fn set(&self, key: &str, value: &[u8], ttl: Duration) -> Result<()>;\n    async fn delete(&self, key: &str) -> Result<()>;\n}\n\npub struct RedisCache {\n    pool: redis::aio::ConnectionManager,\n}\n\n#[async_trait]\nimpl CacheBackend for RedisCache {\n    async fn get(&self, key: &str) -> Result<Option<Vec<u8>>> {\n        let mut conn = self.pool.clone();\n        let result: Option<Vec<u8>> = conn.get(key).await?;\n        Ok(result)\n    }\n\n    async fn set(&self, key: &str, value: &[u8], ttl: Duration) -> Result<()> {\n        let mut conn = self.pool.clone();\n        conn.set_ex(key, value, ttl.as_secs() as usize).await?;\n        Ok(())\n    }\n\n    async fn delete(&self, key: &str) -> Result<()> {\n        let mut conn = self.pool.clone();\n        conn.del(key).await?;\n        Ok(())\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"cache-aware-backend-wrapper",children:"Cache-Aware Backend Wrapper"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'pub struct CachedBackend<B: KeyValueBackend> {\n    backend: B,\n    cache: Option<Arc<dyn CacheBackend>>,\n    config: CacheConfig,\n}\n\n#[async_trait]\nimpl<B: KeyValueBackend> KeyValueBackend for CachedBackend<B> {\n    async fn get(&self, namespace: &str, id: &str, keys: Vec<&[u8]>) -> Result<Vec<Item>> {\n        let cache = match &self.cache {\n            Some(c) => c,\n            None => return self.backend.get(namespace, id, keys).await,\n        };\n\n        let mut cached_items = Vec::new();\n        let mut missing_keys = Vec::new();\n\n        // Check cache for each key\n        for key in &keys {\n            let cache_key = format!("{}:{}:{}", namespace, id, hex::encode(key));\n\n            match cache.get(&cache_key).await? {\n                Some(value) => {\n                    metrics::CACHE_HITS.inc();\n                    cached_items.push(Item {\n                        key: key.to_vec(),\n                        value,\n                        metadata: None,\n                    });\n                }\n                None => {\n                    metrics::CACHE_MISSES.inc();\n                    missing_keys.push(*key);\n                }\n            }\n        }\n\n        // Fetch missing keys from backend\n        if !missing_keys.is_empty() {\n            let backend_items = self.backend.get(namespace, id, missing_keys).await?;\n\n            // Populate cache\n            for item in &backend_items {\n                let cache_key = format!("{}:{}:{}", namespace, id, hex::encode(&item.key));\n                cache.set(&cache_key, &item.value, self.config.ttl).await?;\n            }\n\n            cached_items.extend(backend_items);\n        }\n\n        Ok(cached_items)\n    }\n\n    async fn put(&self, namespace: &str, id: &str, items: Vec<Item>) -> Result<()> {\n        // Write to backend first\n        self.backend.put(namespace, id, items.clone()).await?;\n\n        // Invalidate cache\n        if let Some(cache) = &self.cache {\n            for item in &items {\n                let cache_key = format!("{}:{}:{}", namespace, id, hex::encode(&item.key));\n\n                match self.config.invalidation {\n                    Invalidation::WriteThrough => {\n                        // Update cache with new value\n                        cache.set(&cache_key, &item.value, self.config.ttl).await?;\n                    }\n                    Invalidation::TtlOnly => {\n                        // Delete from cache, let next read repopulate\n                        cache.delete(&cache_key).await?;\n                    }\n                }\n            }\n        }\n\n        Ok(())\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"cache-key-design",children:"Cache Key Design"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'Format: {namespace}:{id}:{key_hex}\n\nExamples:\nuser-profiles:user123:70726f66696c65  (key="profile")\nuser-profiles:user123:73657474696e6773 (key="settings")\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why hex encoding"}),"?"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Keys may contain binary data"}),"\n",(0,i.jsx)(n.li,{children:"Redis keys must be strings"}),"\n",(0,i.jsx)(n.li,{children:"Hex is safe, readable"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"cache-metrics",children:"Cache Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'lazy_static! {\n    static ref CACHE_HITS: CounterVec = register_counter_vec!(\n        "prism_cache_hits_total",\n        "Cache hits",\n        &["namespace"]\n    ).unwrap();\n\n    static ref CACHE_MISSES: CounterVec = register_counter_vec!(\n        "prism_cache_misses_total",\n        "Cache misses",\n        &["namespace"]\n    ).unwrap();\n\n    static ref CACHE_HIT_RATE: GaugeVec = register_gauge_vec!(\n        "prism_cache_hit_rate",\n        "Cache hit rate (0-1)",\n        &["namespace"]\n    ).unwrap();\n}\n\n// Calculate hit rate periodically\nfn update_cache_hit_rate(namespace: &str) {\n    let hits = CACHE_HITS.with_label_values(&[namespace]).get();\n    let misses = CACHE_MISSES.with_label_values(&[namespace]).get();\n    let total = hits + misses;\n\n    if total > 0 {\n        let hit_rate = hits as f64 / total as f64;\n        CACHE_HIT_RATE.with_label_values(&[namespace]).set(hit_rate);\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"alternatives-considered",children:"Alternatives Considered"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"No Caching"})," (backend only)"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: Simpler"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Higher latency, higher backend load"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Caching is essential for read-heavy workloads"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Write-Through Cache"})," (cache is source of truth)"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: Always consistent"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Cache becomes critical dependency, harder to scale"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Increases risk"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"In-Proxy Memory Cache"})," (no external cache)"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: No extra dependency, ultra-fast"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Memory pressure on proxy, no sharing between shards"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Doesn't scale"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Client-Side Caching"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pros: Zero proxy overhead"}),"\n",(0,i.jsx)(n.li,{children:"Cons: Inconsistency, cache invalidation complexity"}),"\n",(0,i.jsx)(n.li,{children:"Rejected: Let platform handle it"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"consequences",children:"Consequences"}),"\n",(0,i.jsx)(n.h3,{id:"positive",children:"Positive"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Lower Latency"}),": Cache hits are 10-100x faster than backend"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reduced Backend Load"}),": Fewer queries to database"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost Savings"}),": Smaller backend instances needed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Optional"}),": Namespaces can opt out if not needed"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"negative",children:"Negative"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Eventual Consistency"}),": Cache may be stale until TTL expires","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Mitigation"}),": Short TTL for frequently-changing data"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Extra Dependency"}),": Redis/memcached must be available","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Mitigation"}),": Degrade gracefully on cache failure"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Memory Cost"}),": Cache requires memory","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Mitigation"}),": Right-size cache, use eviction policies"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"neutral",children:"Neutral"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cache Invalidation"}),": Classic hard problem","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"TTL + write-through handles most cases"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"implementation-notes",children:"Implementation Notes"}),"\n",(0,i.jsx)(n.h3,{id:"graceful-degradation",children:"Graceful Degradation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"async fn get_with_cache_fallback(\n    &self,\n    namespace: &str,\n    id: &str,\n    keys: Vec<&[u8]>,\n) -> Result<Vec<Item>> {\n    // Try cache first\n    match self.get_from_cache(namespace, id, &keys).await {\n        Ok(items) => Ok(items),\n        Err(CacheError::Unavailable) => {\n            // Cache down, go straight to backend\n            metrics::CACHE_UNAVAILABLE.inc();\n            self.backend.get(namespace, id, keys).await\n        }\n        Err(e) => Err(e.into()),\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"cache-warming",children:"Cache Warming"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'pub async fn warm_cache(&self, namespace: &str) -> Result<()> {\n    // Preload hot data into cache\n    let hot_keys = self.get_hot_keys(namespace).await?;\n\n    for key in hot_keys {\n        let items = self.backend.get(namespace, &key.id, vec![&key.key]).await?;\n        for item in items {\n            let cache_key = format!("{}:{}:{}", namespace, key.id, hex::encode(&item.key));\n            self.cache.set(&cache_key, &item.value, self.config.ttl).await?;\n        }\n    }\n\n    Ok(())\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"cache-backends",children:"Cache Backends"}),"\n",(0,i.jsx)(n.p,{children:"Support multiple cache backends:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"pub enum CacheBackendType {\n    Redis,\n    Memcached,\n    InMemory,  // For testing\n}\n\nimpl CacheBackendType {\n    pub fn create(&self, config: &CacheConfig) -> Result<Arc<dyn CacheBackend>> {\n        match self {\n            Self::Redis => Ok(Arc::new(RedisCache::new(config)?)),\n            Self::Memcached => Ok(Arc::new(MemcachedCache::new(config)?)),\n            Self::InMemory => Ok(Arc::new(InMemoryCache::new(config)?)),\n        }\n    }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://netflixtechblog.com/",children:"Netflix KV DAL: Caching"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://redis.io/docs/manual/patterns/",children:"Redis Best Practices"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://memcached.org/",children:"Memcached Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside",children:"Cache Aside Pattern"})}),"\n",(0,i.jsx)(n.li,{children:"ADR-005: Backend Plugin Architecture"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"revision-history",children:"Revision History"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"2025-10-05: Initial draft and acceptance"}),"\n"]})]})}function o(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>r});var c=a(6540);const i={},s=c.createContext(i);function t(e){const n=c.useContext(s);return c.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),c.createElement(s.Provider,{value:n},e.children)}}}]);