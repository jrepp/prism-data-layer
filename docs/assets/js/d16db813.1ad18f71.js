"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[5081],{28453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var r=s(96540);const i={},a=r.createContext(i);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:n},e.children)}},69977:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"adr-025","title":"Container Plugin Model","description":"Context","source":"@site/../docs-cms/adr/adr-025-container-plugin-model.md","sourceDirName":".","slug":"/adr-025","permalink":"/prism-data-layer/adr/adr-025","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/adr/adr-025-container-plugin-model.md","tags":[{"inline":true,"label":"architecture","permalink":"/prism-data-layer/adr/tags/architecture"},{"inline":true,"label":"deployment","permalink":"/prism-data-layer/adr/tags/deployment"},{"inline":true,"label":"containers","permalink":"/prism-data-layer/adr/tags/containers"},{"inline":true,"label":"plugins","permalink":"/prism-data-layer/adr/tags/plugins"},{"inline":true,"label":"backends","permalink":"/prism-data-layer/adr/tags/backends"}],"version":"current","frontMatter":{"date":"2025-10-07T00:00:00.000Z","deciders":"Core Team","doc_uuid":"7985b95a-b734-4919-9ba5-9ed44d852e61","id":"adr-025","project_id":"prism-data-layer","status":"Accepted","tags":["architecture","deployment","containers","plugins","backends"],"title":"Container Plugin Model"},"sidebar":"adrSidebar","previous":{"title":"Layered Interface Hierarchy \u2022 ADR-024","permalink":"/prism-data-layer/adr/adr-024"},"next":{"title":"Distroless Base Images for Container Components \u2022 ADR-026","permalink":"/prism-data-layer/adr/adr-026"}}');var i=s(74848),a=s(28453);const t={date:new Date("2025-10-07T00:00:00.000Z"),deciders:"Core Team",doc_uuid:"7985b95a-b734-4919-9ba5-9ed44d852e61",id:"adr-025",project_id:"prism-data-layer",status:"Accepted",tags:["architecture","deployment","containers","plugins","backends"],title:"Container Plugin Model"},l=void 0,o={},c=[{value:"Context",id:"context",level:2},{value:"Decision",id:"decision",level:2},{value:"Rationale",id:"rationale",level:2},{value:"Container Architecture",id:"container-architecture",level:3}];function d(e){const n={channel:"channel",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",writeresponse:"writeresponse",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"context",children:"Context"}),"\n",(0,i.jsx)(n.p,{children:"Prism needs a standardized way to deploy backend-specific functionality as containers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Kafka requires publisher and consumer containers"}),"\n",(0,i.jsx)(n.li,{children:"NATS requires publisher and consumer containers"}),"\n",(0,i.jsx)(n.li,{children:"Paged reader requires indexed reader consumer"}),"\n",(0,i.jsx)(n.li,{children:"Transact write requires transaction processor and mailbox listener"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Requirements:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Standard interface"}),": All containers follow same contract"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backend-specific logic"}),": Each backend has optimized implementation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Horizontal scaling"}),": Containers can be replicated"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Health checking"}),": Containers report readiness and liveness"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration"}),": Containers configured via environment or config files"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Observability"}),": Standard metrics and logging"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"decision",children:"Decision"}),"\n",(0,i.jsxs)(n.p,{children:["Implement ",(0,i.jsx)(n.strong,{children:"container plugin model"})," with standardized contracts:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Plugin interface"}),": Standard gRPC or HTTP health/metrics endpoints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Backend-specific containers"}),": Optimized for each backend"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Role-based deployment"}),": Publisher, Consumer, Processor, Listener roles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration via environment"}),": 12-factor app principles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Docker/Kubernetes-ready"}),": Standard container packaging"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"rationale",children:"Rationale"}),"\n",(0,i.jsx)(n.h3,{id:"container-architecture",children:"Container Architecture"}),"\n",(0,i.jsx)(n.p,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Prism Core Proxy                           \u2502\n\u2502                  (gRPC Server)                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           \u2502\n\u2502                           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Backend Plugins \u2502        \u2502 Backend Plugins  \u2502\n\u2502 (Containers)    \u2502        \u2502 (Containers)     \u2502\n\u2502                 \u2502        \u2502                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502 \u2502   Kafka     \u2502 \u2502        \u2502 \u2502    NATS      \u2502\u2502\n\u2502 \u2502  Publisher  \u2502 \u2502        \u2502 \u2502  Publisher   \u2502\u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                 \u2502        \u2502                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502 \u2502   Kafka     \u2502 \u2502        \u2502 \u2502    NATS      \u2502\u2502\n\u2502 \u2502  Consumer   \u2502 \u2502        \u2502 \u2502  Consumer    \u2502\u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"}),"\n",(0,i.jsx)(n.p,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Reader Plugins    \u2502        \u2502 Transact Plugins \u2502\n\u2502 (Containers)      \u2502        \u2502 (Containers)     \u2502\n\u2502                   \u2502        \u2502                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502   Indexed     \u2502 \u2502        \u2502 \u2502  Transaction \u2502 \u2502\n\u2502 \u2502    Reader     \u2502 \u2502        \u2502 \u2502  Processor   \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                   \u2502        \u2502                  \u2502\n\u2502                   \u2502        \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502                   \u2502        \u2502 \u2502   Mailbox    \u2502 \u2502\n\u2502                   \u2502        \u2502 \u2502   Listener   \u2502 \u2502\n\u2502                   \u2502        \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Plugin Contract\n\nAll container plugins implement standard interface:\n\n"})}),"\n",(0,i.jsx)(n.p,{children:'// proto/prism/plugin/v1/plugin.proto\nsyntax = "proto3";'}),"\n",(0,i.jsx)(n.p,{children:"package prism.plugin.v1;"}),"\n",(0,i.jsx)(n.p,{children:'import "google/protobuf/timestamp.proto";\nimport "google/protobuf/struct.proto";'}),"\n",(0,i.jsx)(n.p,{children:"// Health check service (required for all plugins)\nservice HealthService {\n// Liveness probe\nrpc Live(LiveRequest) returns (LiveResponse);"}),"\n",(0,i.jsx)(n.p,{children:"// Readiness probe\nrpc Ready(ReadyRequest) returns (ReadyResponse);\n}"}),"\n",(0,i.jsx)(n.p,{children:"message LiveRequest {}"}),"\n",(0,i.jsx)(n.p,{children:"message LiveResponse {\nbool alive = 1;\ngoogle.protobuf.Timestamp timestamp = 2;\n}"}),"\n",(0,i.jsx)(n.p,{children:"message ReadyRequest {}"}),"\n",(0,i.jsx)(n.p,{children:"message ReadyResponse {\nbool ready = 1;\nstring message = 2;\nmap<string, string> dependencies = 3;  // Dependency status\n}"}),"\n",(0,i.jsx)(n.p,{children:"// Metrics service (required for all plugins)\nservice MetricsService {\n// Get plugin metrics (Prometheus format)\nrpc GetMetrics(MetricsRequest) returns (MetricsResponse);\n}"}),"\n",(0,i.jsx)(n.p,{children:"message MetricsRequest {}"}),"\n",(0,i.jsx)(n.p,{children:"message MetricsResponse {\nstring metrics = 1;  // Prometheus text format\n}"}),"\n",(0,i.jsx)(n.p,{children:"// Plugin info service (required for all plugins)\nservice PluginInfoService {\nrpc GetInfo(InfoRequest) returns (InfoResponse);\n}"}),"\n",(0,i.jsx)(n.p,{children:"message InfoRequest {}"}),"\n",(0,i.jsx)(n.p,{children:'message InfoResponse {\nstring name = 1;\nstring version = 2;\nstring role = 3;  // "publisher", "consumer", "processor", "listener"\nstring backend = 4;  // "kafka", "nats", "postgres", etc.\nmap<string, string> capabilities = 5;\n}'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Environment Configuration\n\nAll plugins configured via environment variables:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"common-to-all-plugins",children:"Common to all plugins"}),"\n",(0,i.jsx)(n.p,{children:"PRISM_PROXY_ENDPOINT=localhost:8980\nPRISM_PLUGIN_ROLE=publisher\nPRISM_BACKEND_TYPE=kafka\nPRISM_NAMESPACE=production\nPRISM_LOG_LEVEL=info\nPRISM_LOG_FORMAT=json\nPRISM_METRICS_PORT=9090"}),"\n",(0,i.jsx)(n.h1,{id:"kafka-specific",children:"Kafka-specific"}),"\n",(0,i.jsx)(n.p,{children:"KAFKA_BROKERS=localhost:9092,localhost:9093\nKAFKA_TOPIC=events\nKAFKA_CONSUMER_GROUP=prism-consumer\nKAFKA_AUTO_OFFSET_RESET=earliest\nKAFKA_COMPRESSION=snappy"}),"\n",(0,i.jsx)(n.h1,{id:"nats-specific",children:"NATS-specific"}),"\n",(0,i.jsx)(n.p,{children:"NATS_URL=nats://localhost:4222\nNATS_SUBJECT=events.>\nNATS_QUEUE_GROUP=prism-consumers\nNATS_STREAM=EVENTS"}),"\n",(0,i.jsx)(n.h1,{id:"database-specific",children:"Database-specific"}),"\n",(0,i.jsx)(n.p,{children:"DATABASE_URL=postgres://user:pass@localhost/db\nDATABASE_POOL_SIZE=10\nDATABASE_TABLE=events"}),"\n",(0,i.jsx)(n.h1,{id:"mailbox-specific",children:"Mailbox-specific"}),"\n",(0,i.jsx)(n.p,{children:"MAILBOX_TABLE=mailbox\nMAILBOX_POLL_INTERVAL=1s\nMAILBOX_BATCH_SIZE=100"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Kafka Plugin Containers\n\n#### Kafka Publisher\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/kafka-publisher/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use rdkafka::producer::{FutureProducer, FutureRecord};\nuse tonic::transport::Channel;\nuse prism_proto::queue::v1::queue_service_client::QueueServiceClient;"}),"\n",(0,i.jsx)(n.p,{children:"struct KafkaPublisher {\nproducer: FutureProducer,\ntopic: String,\n}"}),"\n",(0,i.jsx)(n.p,{children:'impl KafkaPublisher {\nasync fn run(&self) -> Result<()> {\n// Connect to Prism proxy\nlet mut client = QueueServiceClient::connect(\nenv::var("PRISM_PROXY_ENDPOINT")?\n).await?;'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"    // Create session\n    let session = client.create_session(/* ... */).await?;\n\n    // Subscribe to internal queue for messages to publish\n    let messages = self.receive_from_internal_queue().await?;\n\n    // Publish to Kafka\n    for message in messages {\n        let record = FutureRecord::to(&self.topic)\n            .payload(&message.payload)\n            .key(&message.key);\n\n        self.producer.send(record, Duration::from_secs(5)).await?;\n    }\n\n    Ok(())\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.p,{children:"#[tokio::main]\nasync fn main() -> Result<()> {\ntracing_subscriber::fmt::init();"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"let publisher = KafkaPublisher::new()?;\npublisher.run().await\n"})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n#### Kafka Consumer\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/kafka-consumer/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use rdkafka::consumer::{Consumer, StreamConsumer};\nuse rdkafka::Message;"}),"\n",(0,i.jsxs)(n.p,{children:["struct KafkaConsumer {\nconsumer: StreamConsumer,\nproxy_client: QueueServiceClient",(0,i.jsx)(n.channel,{children:",\n}"})]}),"\n",(0,i.jsx)(n.p,{children:"impl KafkaConsumer {\nasync fn run(&self) -> Result<()> {\n// Subscribe to Kafka topic\nself.consumer.subscribe(&[&self.topic])?;"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'    loop {\n        match self.consumer.recv().await {\n            Ok(message) => {\n                // Forward to Prism proxy\n                self.proxy_client.publish(PublishRequest {\n                    topic: message.topic().to_string(),\n                    payload: message.payload().unwrap().to_vec(),\n                    offset: Some(message.offset()),\n                    partition: Some(message.partition()),\n                }).await?;\n\n                // Commit offset\n                self.consumer.commit_message(&message, CommitMode::Async)?;\n            }\n            Err(e) => {\n                tracing::error!("Kafka error: {}", e);\n            }\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### NATS Plugin Containers\n\n#### NATS Publisher\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/nats-publisher/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use async_nats::Client;"}),"\n",(0,i.jsx)(n.p,{children:"struct NatsPublisher {\nclient: Client,\nsubject: String,\n}"}),"\n",(0,i.jsx)(n.p,{children:"impl NatsPublisher {\nasync fn run(&self) -> Result<()> {\n// Connect to Prism proxy for source messages\nlet mut proxy_client = PubSubServiceClient::connect(/* ... */).await?;"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"    // Subscribe to internal stream\n    let mut stream = proxy_client.subscribe(/* ... */).await?.into_inner();\n\n    // Publish to NATS\n    while let Some(event) = stream.message().await? {\n        self.client.publish(&self.subject, event.payload.into()).await?;\n    }\n\n    Ok(())\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n#### NATS Consumer\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/nats-consumer/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use async_nats::{Client, jetstream};"}),"\n",(0,i.jsx)(n.p,{children:"struct NatsConsumer {\nclient: Client,\nstream: String,\nconsumer: String,\n}"}),"\n",(0,i.jsx)(n.p,{children:"impl NatsConsumer {\nasync fn run(&self) -> Result<()> {\nlet jetstream = jetstream::new(self.client.clone());"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"    let consumer = jetstream\n        .get_stream(&self.stream)\n        .await?\n        .get_consumer(&self.consumer)\n        .await?;\n\n    let mut messages = consumer.messages().await?;\n\n    // Connect to Prism proxy\n    let mut proxy_client = PubSubServiceClient::connect(/* ... */).await?;\n\n    while let Some(message) = messages.next().await {\n        let message = message?;\n\n        // Forward to Prism proxy\n        proxy_client.publish(PublishRequest {\n            topic: message.subject.clone(),\n            payload: message.payload.to_vec(),\n            metadata: Default::default(),\n        }).await?;\n\n        // Ack message\n        message.ack().await?;\n    }\n\n    Ok(())\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Paged Reader Plugin\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/indexed-reader/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use sqlx::PgPool;"}),"\n",(0,i.jsx)(n.p,{children:"struct IndexedReader {\npool: PgPool,\ntable: String,\nindex_column: String,\n}"}),"\n",(0,i.jsx)(n.p,{children:"impl IndexedReader {\nasync fn run(&self) -> Result<()> {\n// Connect to Prism proxy\nlet mut proxy_client = ReaderServiceClient::connect(/* ... */).await?;"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'    // Process read requests\n    loop {\n        // Get read request from internal queue\n        let request = self.receive_read_request().await?;\n\n        // Query database with index\n        let rows = sqlx::query(&format!(\n            "SELECT * FROM {} WHERE {} > $1 ORDER BY {} LIMIT $2",\n            self.table, self.index_column, self.index_column\n        ))\n        .bind(&request.cursor)\n        .bind(request.page_size)\n        .fetch_all(&self.pool)\n        .await?;\n\n        // Stream results back\n        for row in rows {\n            proxy_client.send_page(/* ... */).await?;\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Transact Writer Plugins\n\n#### Transaction Processor\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/transact-processor/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use sqlx::{PgPool, Transaction};"}),"\n",(0,i.jsx)(n.p,{children:"struct TransactProcessor {\npool: PgPool,\n}"}),"\n",(0,i.jsxs)(n.p,{children:["impl TransactProcessor {\nasync fn process_transaction(&self, req: WriteRequest) -> Result",(0,i.jsx)(n.writeresponse,{children:" {\nlet mut tx = self.pool.begin().await?;"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'    // Write to data table\n    let data_result = self.write_data(&mut tx, req.data).await?;\n\n    // Write to mailbox table\n    let mailbox_result = self.write_mailbox(&mut tx, req.mailbox).await?;\n\n    // Commit transaction\n    tx.commit().await?;\n\n    Ok(WriteResponse {\n        transaction_id: uuid::Uuid::new_v4().to_string(),\n        committed: true,\n        data_result,\n        mailbox_result,\n    })\n}\n\nasync fn write_data(&self, tx: &mut Transaction<\'_, Postgres>, data: DataWrite) -> Result<DataWriteResult> {\n    let result = sqlx::query(&data.to_sql())\n        .execute(&mut **tx)\n        .await?;\n\n    Ok(DataWriteResult {\n        rows_affected: result.rows_affected() as i64,\n        generated_values: Default::default(),\n    })\n}\n\nasync fn write_mailbox(&self, tx: &mut Transaction<\'_, Postgres>, mailbox: MailboxWrite) -> Result<MailboxWriteResult> {\n    let result = sqlx::query(\n        "INSERT INTO mailbox (mailbox_id, message, metadata) VALUES ($1, $2, $3) RETURNING id, sequence"\n    )\n    .bind(&mailbox.mailbox_id)\n    .bind(&mailbox.message)\n    .bind(&mailbox.metadata)\n    .fetch_one(&mut **tx)\n    .await?;\n\n    Ok(MailboxWriteResult {\n        message_id: result.get("id"),\n        sequence: result.get("sequence"),\n    })\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n#### Mailbox Listener\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"// containers/mailbox-listener/src/main.rs"}),"\n",(0,i.jsx)(n.p,{children:"use sqlx::PgPool;"}),"\n",(0,i.jsx)(n.p,{children:"struct MailboxListener {\npool: PgPool,\nmailbox_id: String,\npoll_interval: Duration,\n}"}),"\n",(0,i.jsx)(n.p,{children:"impl MailboxListener {\nasync fn run(&self) -> Result<()> {\nlet mut last_sequence = 0i64;"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'    loop {\n        // Poll for new messages\n        let messages = sqlx::query_as::<_, MailboxMessage>(\n            "SELECT * FROM mailbox WHERE mailbox_id = $1 AND sequence > $2 ORDER BY sequence LIMIT $3"\n        )\n        .bind(&self.mailbox_id)\n        .bind(last_sequence)\n        .bind(100)\n        .fetch_all(&self.pool)\n        .await?;\n\n        for message in messages {\n            // Process message\n            self.process_message(&message).await?;\n\n            // Update last sequence\n            last_sequence = message.sequence;\n\n            // Mark as processed\n            sqlx::query("UPDATE mailbox SET processed = true WHERE id = $1")\n                .bind(&message.id)\n                .execute(&self.pool)\n                .await?;\n        }\n\n        tokio::time::sleep(self.poll_interval).await;\n    }\n}\n\nasync fn process_message(&self, message: &MailboxMessage) -> Result<()> {\n    // Forward to downstream system, trigger workflow, etc.\n    tracing::info!("Processing mailbox message: {:?}", message);\n    Ok(())\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"}"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Docker Deployment\n\nEach plugin is a separate Docker image:\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"dockerfilekafka-publisher",children:"Dockerfile.kafka-publisher"}),"\n",(0,i.jsx)(n.p,{children:"FROM rust:1.75 as builder\nWORKDIR /app\nCOPY . .\nRUN cargo build --release --bin kafka-publisher"}),"\n",(0,i.jsx)(n.p,{children:'FROM debian:bookworm-slim\nRUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*\nCOPY --from=builder /app/target/release/kafka-publisher /usr/local/bin/\nENTRYPOINT ["kafka-publisher"]'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Docker Compose Example\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"docker-composepluginsyml",children:"docker-compose.plugins.yml"}),"\n",(0,i.jsx)(n.p,{children:"version: '3.8'"}),"\n",(0,i.jsx)(n.p,{children:'services:\nprism-proxy:\nimage: prism/proxy:latest\nports:\n- "8980:8980"\n- "9090:9090"\nenvironment:\n- RUST_LOG=info'}),"\n",(0,i.jsx)(n.p,{children:"kafka-publisher:\nimage: prism/kafka-publisher:latest\ndepends_on:\n- prism-proxy\n- kafka\nenvironment:\n- PRISM_PROXY_ENDPOINT=prism-proxy:8980\n- PRISM_PLUGIN_ROLE=publisher\n- KAFKA_BROKERS=kafka:9092\n- KAFKA_TOPIC=events\ndeploy:\nreplicas: 2"}),"\n",(0,i.jsx)(n.p,{children:"kafka-consumer:\nimage: prism/kafka-consumer:latest\ndepends_on:\n- prism-proxy\n- kafka\nenvironment:\n- PRISM_PROXY_ENDPOINT=prism-proxy:8980\n- PRISM_PLUGIN_ROLE=consumer\n- KAFKA_BROKERS=kafka:9092\n- KAFKA_TOPIC=events\n- KAFKA_CONSUMER_GROUP=prism-consumers\ndeploy:\nreplicas: 3"}),"\n",(0,i.jsx)(n.p,{children:"nats-publisher:\nimage: prism/nats-publisher:latest\ndepends_on:\n- prism-proxy\n- nats\nenvironment:\n- PRISM_PROXY_ENDPOINT=prism-proxy:8980\n- NATS_URL=nats://nats:4222\n- NATS_SUBJECT=events.>"}),"\n",(0,i.jsx)(n.p,{children:"mailbox-listener:\nimage: prism/mailbox-listener:latest\ndepends_on:\n- prism-proxy\n- postgres\nenvironment:\n- PRISM_PROXY_ENDPOINT=prism-proxy:8980\n- DATABASE_URL=postgres://prism:password@postgres/prism\n- MAILBOX_ID=system\n- MAILBOX_POLL_INTERVAL=1s"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Kubernetes Deployment\n\n"})}),"\n",(0,i.jsx)(n.h1,{id:"k8skafka-consumer-deploymentyaml",children:"k8s/kafka-consumer-deployment.yaml"}),"\n",(0,i.jsx)(n.p,{children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: prism-kafka-consumer\nspec:\nreplicas: 3\nselector:\nmatchLabels:\napp: prism-kafka-consumer\ntemplate:\nmetadata:\nlabels:\napp: prism-kafka-consumer\nspec:\ncontainers:\n- name: kafka-consumer\nimage: prism/kafka-consumer:latest\nenv:\n- name: PRISM_PROXY_ENDPOINT\nvalue: "prism-proxy:8980"\n- name: KAFKA_BROKERS\nvalue: "kafka-0.kafka:9092,kafka-1.kafka:9092"\n- name: KAFKA_TOPIC\nvalue: "events"\nports:\n- containerPort: 9090\nname: metrics\nlivenessProbe:\nhttpGet:\npath: /health/live\nport: 8081\ninitialDelaySeconds: 10\nperiodSeconds: 10\nreadinessProbe:\nhttpGet:\npath: /health/ready\nport: 8081\ninitialDelaySeconds: 5\nperiodSeconds: 5\nresources:\nrequests:\nmemory: "128Mi"\ncpu: "100m"\nlimits:\nmemory: "512Mi"\ncpu: "500m"'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n### Alternatives Considered\n\n1. **Monolithic proxy with all backend logic**\n   - Pros: Simpler deployment\n   - Cons: Tight coupling, hard to scale independently\n   - Rejected: Doesn't support horizontal scaling per backend\n\n2. **Sidecar pattern**\n   - Pros: Co-located with proxy\n   - Cons: Resource overhead, complex orchestration\n   - Rejected: Separate containers more flexible\n\n3. **Embedded plugins (dynamic libraries)**\n   - Pros: No network overhead\n   - Cons: Language lock-in, version conflicts, crash propagation\n   - Rejected: Containers provide better isolation\n\n## Consequences\n\n### Positive\n\n- **Horizontal scaling**: Scale each plugin independently\n- **Backend optimization**: Plugin optimized for specific backend\n- **Isolation**: Plugin failures don't crash proxy\n- **Standard deployment**: Docker/Kubernetes patterns\n- **Observability**: Standard metrics/health endpoints\n- **Language flexibility**: Plugins can be written in any language\n\n### Negative\n\n- **More containers**: Increased deployment complexity\n- **Network overhead**: gRPC calls between proxy and plugins\n- **Resource usage**: Each container has overhead\n\n### Neutral\n\n- **Configuration**: Environment variables (12-factor)\n- **Monitoring**: Standard Prometheus metrics\n\n## References\n\n- [12-Factor App](https://12factor.net/)\n- [Kubernetes Deployment Patterns](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)\n- ADR-008: Observability Strategy\n- ADR-024: Layered Interface Hierarchy\n\n## Revision History\n\n- 2025-10-07: Initial draft and acceptance\n\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);