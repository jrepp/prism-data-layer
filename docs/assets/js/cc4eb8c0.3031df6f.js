"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[98307],{28453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>c});var t=a(96540);const i={},r=t.createContext(i);function s(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(r.Provider,{value:n},e.children)}},69879:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"rfc-007","title":"Cache Strategies for Data Layer","description":"Status: Draft","source":"@site/../docs-cms/rfcs/rfc-007-cache-strategies.md","sourceDirName":".","slug":"/rfc-007","permalink":"/prism-data-layer/rfc/rfc-007","draft":false,"unlisted":false,"editUrl":"https://github.com/jrepp/prism-data-layer/tree/main/docs-cms/../docs-cms/rfcs/rfc-007-cache-strategies.md","tags":[],"version":"current","frontMatter":{"author":"System","created":"2025-10-08T00:00:00.000Z","doc_uuid":"ecc97cc2-2ed4-4709-9f6f-07ce9fba5fe9","id":"rfc-007","project_id":"prism-data-layer","sidebar_label":"RFC-007 Cache Strategies","status":"Draft","title":"Cache Strategies for Data Layer"},"sidebar":"rfcSidebar","previous":{"title":"RFC-006 Admin CLI","permalink":"/prism-data-layer/rfc/rfc-006"},"next":{"title":"RFC-008 Plugin Architecture","permalink":"/prism-data-layer/rfc/rfc-008"}}');var i=a(74848),r=a(28453);const s={author:"System",created:new Date("2025-10-08T00:00:00.000Z"),doc_uuid:"ecc97cc2-2ed4-4709-9f6f-07ce9fba5fe9",id:"rfc-007",project_id:"prism-data-layer",sidebar_label:"RFC-007 Cache Strategies",status:"Draft",title:"Cache Strategies for Data Layer"},c="RFC-007: Cache Strategies for Data Layer",l={},d=[{value:"Abstract",id:"abstract",level:2},{value:"Motivation",id:"motivation",level:2},{value:"Why Cache Strategies Matter",id:"why-cache-strategies-matter",level:3},{value:"Real-World Scenarios",id:"real-world-scenarios",level:3},{value:"Goals",id:"goals",level:2},{value:"Non-Goals",id:"non-goals",level:2},{value:"Cache Strategies Overview",id:"cache-strategies-overview",level:2},{value:"Strategy Comparison",id:"strategy-comparison",level:3},{value:"Look-Aside (Cache-Aside) Pattern",id:"look-aside-cache-aside-pattern",level:2},{value:"Overview",id:"overview",level:3},{value:"Architecture Diagram",id:"architecture-diagram",level:3},{value:"Protobuf Configuration",id:"protobuf-configuration",level:3},{value:"Namespace Configuration Example",id:"namespace-configuration-example",level:3},{value:"Rust Implementation",id:"rust-implementation",level:3},{value:"Write-Through Cache Pattern",id:"write-through-cache-pattern",level:2},{value:"Overview",id:"overview-1",level:3},{value:"Architecture Diagram",id:"architecture-diagram-1",level:3},{value:"Protobuf Configuration",id:"protobuf-configuration-1",level:3},{value:"Namespace Configuration Example",id:"namespace-configuration-example-1",level:3},{value:"Rust Implementation",id:"rust-implementation-1",level:3},{value:"Use Case: Table Reader with Look-Aside Cache",id:"use-case-table-reader-with-look-aside-cache",level:2},{value:"Scenario",id:"scenario",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Client Usage",id:"client-usage",level:3},{value:"Performance",id:"performance",level:3},{value:"Use Case: Object Storage Metadata with Write-Through Cache",id:"use-case-object-storage-metadata-with-write-through-cache",level:2},{value:"Scenario",id:"scenario-1",level:3},{value:"Configuration",id:"configuration-1",level:3},{value:"Client Usage",id:"client-usage-1",level:3},{value:"Monitoring and Observability",id:"monitoring-and-observability",level:2},{value:"Cache Metrics",id:"cache-metrics",level:3},{value:"Prometheus Metrics",id:"prometheus-metrics",level:3},{value:"Grafana Dashboard Queries",id:"grafana-dashboard-queries",level:3},{value:"Cache Invalidation Strategies",id:"cache-invalidation-strategies",level:2},{value:"Invalidation Comparison",id:"invalidation-comparison",level:3},{value:"Manual Invalidation via Admin CLI",id:"manual-invalidation-via-admin-cli",level:3},{value:"Migration Path",id:"migration-path",level:2},{value:"Phase 1: Look-Aside Implementation (Week 1-2)",id:"phase-1-look-aside-implementation-week-1-2",level:3},{value:"Phase 2: Write-Through Implementation (Week 3-4)",id:"phase-2-write-through-implementation-week-3-4",level:3},{value:"Phase 3: Advanced Features (Week 5-6)",id:"phase-3-advanced-features-week-5-6",level:3},{value:"Phase 4: Additional Patterns (Future)",id:"phase-4-additional-patterns-future",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"Performance Targets",id:"performance-targets",level:2},{value:"Related RFCs and ADRs",id:"related-rfcs-and-adrs",level:2},{value:"References",id:"references",level:2},{value:"Appendix: Cache Strategy Decision Tree",id:"appendix-cache-strategy-decision-tree",level:2}];function o(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"rfc-007-cache-strategies-for-data-layer",children:"RFC-007: Cache Strategies for Data Layer"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Status"}),": Draft\n",(0,i.jsx)(n.strong,{children:"Author"}),": System\n",(0,i.jsx)(n.strong,{children:"Created"}),": 2025-10-08\n",(0,i.jsx)(n.strong,{children:"Updated"}),": 2025-10-08"]}),"\n",(0,i.jsx)(n.h2,{id:"abstract",children:"Abstract"}),"\n",(0,i.jsxs)(n.p,{children:["Caching is fundamental to achieving low-latency, high-throughput data access. This RFC defines standard cache strategies implemented in Prism's data layer, focusing on ",(0,i.jsx)(n.strong,{children:"look-aside (cache-aside)"})," and ",(0,i.jsx)(n.strong,{children:"write-through"})," patterns for common use cases like table readers and object storage metadata caching."]}),"\n",(0,i.jsx)(n.p,{children:"By standardizing cache strategies at the proxy level, applications benefit from transparent caching without implementing cache logic in every service. Prism manages cache consistency, expiration (ADR-031), and invalidation automatically based on declarative configuration."}),"\n",(0,i.jsx)(n.h2,{id:"motivation",children:"Motivation"}),"\n",(0,i.jsx)(n.h3,{id:"why-cache-strategies-matter",children:"Why Cache Strategies Matter"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance"}),": Sub-millisecond responses for cached data vs. 10-100ms database queries"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost Reduction"}),": Fewer database queries reduce compute and I/O costs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scalability"}),": Cache absorbs read traffic, allowing databases to scale independently"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Availability"}),": Cached data remains available during backend outages (stale reads)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Consistency"}),": Different strategies offer different consistency guarantees"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"real-world-scenarios",children:"Real-World Scenarios"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Table Readers"}),": Frequently accessed reference tables (countries, categories, product catalogs)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object Metadata"}),": File metadata from object storage (size, content-type, ETag)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User Profiles"}),": High-read, low-write data accessed on every request"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration Data"}),": Application settings queried repeatedly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Computed Results"}),": Expensive aggregations or ML model outputs"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"goals",children:"Goals"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Define standard cache strategies with clear consistency semantics"}),"\n",(0,i.jsx)(n.li,{children:"Implement look-aside and write-through patterns for common use cases"}),"\n",(0,i.jsx)(n.li,{children:"Support cache warmup, invalidation, and expiration"}),"\n",(0,i.jsx)(n.li,{children:"Provide configuration-driven cache behavior (no code changes required)"}),"\n",(0,i.jsx)(n.li,{children:"Enable observability into cache hit rates, latency, and consistency"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"non-goals",children:"Non-Goals"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Custom Cache Logic"}),": Not implementing application-specific cache policies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Distributed Cache Coordination"}),": Not solving distributed cache coherence (use Redis cluster instead)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cache-Aside in Clients"}),": Clients use Prism APIs; caching is transparent"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"cache-strategies-overview",children:"Cache Strategies Overview"}),"\n",(0,i.jsx)(n.h3,{id:"strategy-comparison",children:"Strategy Comparison"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Strategy"}),(0,i.jsx)(n.th,{children:"Read Path"}),(0,i.jsx)(n.th,{children:"Write Path"}),(0,i.jsx)(n.th,{children:"Consistency"}),(0,i.jsx)(n.th,{children:"Use Case"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Look-Aside"})}),(0,i.jsx)(n.td,{children:"Check cache first"}),(0,i.jsx)(n.td,{children:"Write to DB only"}),(0,i.jsx)(n.td,{children:"Eventual"}),(0,i.jsx)(n.td,{children:"Read-heavy, tolerate stale reads"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Write-Through"})}),(0,i.jsx)(n.td,{children:"Check cache first"}),(0,i.jsx)(n.td,{children:"Write to cache + DB"}),(0,i.jsx)(n.td,{children:"Strong"}),(0,i.jsx)(n.td,{children:"Read-heavy, require fresh reads"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Write-Back"})}),(0,i.jsx)(n.td,{children:"Check cache first"}),(0,i.jsx)(n.td,{children:"Write to cache only"}),(0,i.jsx)(n.td,{children:"Weak"}),(0,i.jsx)(n.td,{children:"Write-heavy, tolerate data loss"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Refresh-Ahead"})}),(0,i.jsx)(n.td,{children:"Check cache first"}),(0,i.jsx)(n.td,{children:"Background refresh"}),(0,i.jsx)(n.td,{children:"Eventual"}),(0,i.jsx)(n.td,{children:"Predictable access patterns"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Read-Through"})}),(0,i.jsx)(n.td,{children:"Cache or fetch"}),(0,i.jsx)(n.td,{children:"Write to DB only"}),(0,i.jsx)(n.td,{children:"Eventual"}),(0,i.jsx)(n.td,{children:"Simplify read logic"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"This RFC focuses on Look-Aside and Write-Through"})," as they cover 90% of use cases."]}),"\n",(0,i.jsx)(n.h2,{id:"look-aside-cache-aside-pattern",children:"Look-Aside (Cache-Aside) Pattern"}),"\n",(0,i.jsx)(n.h3,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Look-aside"})," is the most common caching pattern:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Read"}),": Check cache; if miss, fetch from DB, store in cache"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Write"}),": Update DB; optionally invalidate cache"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Simple to reason about"}),"\n",(0,i.jsx)(n.li,{children:"Cache failures don't affect writes"}),"\n",(0,i.jsx)(n.li,{children:"Flexible invalidation strategies"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Cache misses cause latency spikes"}),"\n",(0,i.jsx)(n.li,{children:"Potential for stale reads"}),"\n",(0,i.jsx)(n.li,{children:"Thundering herd on cold cache"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"architecture-diagram",children:"Architecture Diagram"}),"\n",(0,i.jsx)(n.mermaid,{value:'sequenceDiagram\n    participant Client\n    participant Proxy as Prism Proxy<br/>(Look-Aside)\n    participant Cache as Redis Cache\n    participant DB as PostgreSQL<br/>(Source of Truth)\n\n    Note over Client,DB: Read Path (Cache Hit)\n    Client->>Proxy: GET /users/123\n    Proxy->>Cache: GET users:123\n    Cache--\x3e>Proxy: Data (hit)\n    Proxy--\x3e>Client: Response (2ms)\n\n    Note over Client,DB: Read Path (Cache Miss)\n    Client->>Proxy: GET /users/456\n    Proxy->>Cache: GET users:456\n    Cache--\x3e>Proxy: nil (miss)\n    Proxy->>DB: SELECT * FROM users WHERE id=456\n    DB--\x3e>Proxy: User data\n    Proxy->>Cache: SET users:456 data TTL=300s\n    Proxy--\x3e>Client: Response (25ms)\n\n    Note over Client,DB: Write Path\n    Client->>Proxy: PUT /users/123 {name: "Updated"}\n    Proxy->>DB: UPDATE users SET name=... WHERE id=123\n    DB--\x3e>Proxy: OK\n    Proxy->>Cache: DEL users:123\n    Cache--\x3e>Proxy: OK\n    Proxy--\x3e>Client: Updated (15ms)'}),"\n",(0,i.jsx)(n.h3,{id:"protobuf-configuration",children:"Protobuf Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:"message LookAsideCacheConfig {\n  // Cache backend (redis, in-memory)\n  string cache_backend = 1;\n\n  // Cache key prefix\n  string key_prefix = 2;\n\n  // TTL for cached entries (see ADR-031)\n  int64 ttl_seconds = 3 [default = 300];\n\n  // Invalidation strategy\n  enum InvalidationStrategy {\n    INVALIDATE_ON_WRITE = 0;  // Delete cache entry on write\n    NO_INVALIDATION = 1;       // Rely on TTL expiration\n    BACKGROUND_REFRESH = 2;    // Refresh cache asynchronously\n  }\n  InvalidationStrategy invalidation = 4;\n\n  // Warmup strategy\n  bool enable_warmup = 5;\n  string warmup_query = 6;  // SQL query to pre-populate cache\n\n  // Thundering herd prevention\n  bool enable_locking = 7;   // Lock during cache fill to prevent duplicate fetches\n  int64 lock_timeout_ms = 8 [default = 1000];\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"namespace-configuration-example",children:"Namespace Configuration Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'namespaces:\n  - name: user-profiles\n    backend: postgres\n    pattern: keyvalue\n    cache:\n      strategy: look_aside\n      cache_backend: redis\n      key_prefix: "users:"\n      ttl_seconds: 300\n      invalidation: INVALIDATE_ON_WRITE\n      enable_locking: true\n\n  - name: product-catalog\n    backend: postgres\n    pattern: keyvalue\n    cache:\n      strategy: look_aside\n      cache_backend: redis\n      key_prefix: "products:"\n      ttl_seconds: 3600  # 1 hour\n      invalidation: NO_INVALIDATION  # Read-only catalog\n      enable_warmup: true\n      warmup_query: "SELECT id, data FROM products WHERE active=true"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"rust-implementation",children:"Rust Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'pub struct LookAsideCache {\n    cache: RedisBackend,\n    database: PostgresBackend,\n    config: LookAsideCacheConfig,\n}\n\nimpl LookAsideCache {\n    pub async fn get(&self, key: &str) -> Result<Option<Bytes>> {\n        let cache_key = format!("{}{}", self.config.key_prefix, key);\n\n        // Step 1: Check cache\n        if let Some(data) = self.cache.get(&cache_key).await? {\n            metrics::increment_counter!("cache_hits", "namespace" => &self.config.namespace);\n            return Ok(Some(data));\n        }\n\n        metrics::increment_counter!("cache_misses", "namespace" => &self.config.namespace);\n\n        // Step 2: Thundering herd prevention\n        if self.config.enable_locking {\n            let lock_key = format!("{}:lock", cache_key);\n\n            // Try to acquire lock\n            if !self.cache.set_nx(&lock_key, b"1", Duration::from_millis(self.config.lock_timeout_ms)).await? {\n                // Another request is fetching; wait and retry\n                tokio::time::sleep(Duration::from_millis(50)).await;\n                return self.get(key).await; // Retry (cache should be populated)\n            }\n        }\n\n        // Step 3: Fetch from database\n        let data = self.database.get(key).await?;\n\n        // Step 4: Populate cache\n        if let Some(ref data) = data {\n            self.cache\n                .set_ex(&cache_key, data, self.config.ttl_seconds as usize)\n                .await?;\n        }\n\n        // Step 5: Release lock\n        if self.config.enable_locking {\n            let lock_key = format!("{}:lock", cache_key);\n            self.cache.del(&lock_key).await?;\n        }\n\n        Ok(data)\n    }\n\n    pub async fn set(&self, key: &str, value: &[u8]) -> Result<()> {\n        let cache_key = format!("{}{}", self.config.key_prefix, key);\n\n        // Step 1: Write to database (source of truth)\n        self.database.set(key, value).await?;\n\n        // Step 2: Invalidate cache\n        match self.config.invalidation {\n            InvalidationStrategy::InvalidateOnWrite => {\n                self.cache.del(&cache_key).await?;\n            }\n            InvalidationStrategy::NoInvalidation => {\n                // Do nothing; rely on TTL\n            }\n            InvalidationStrategy::BackgroundRefresh => {\n                // Trigger async refresh (not blocking write)\n                let cache = self.cache.clone();\n                let db = self.database.clone();\n                let key = key.to_string();\n                tokio::spawn(async move {\n                    if let Ok(Some(data)) = db.get(&key).await {\n                        let _ = cache.set_ex(&cache_key, &data, 300).await;\n                    }\n                });\n            }\n        }\n\n        Ok(())\n    }\n\n    pub async fn warmup(&self) -> Result<usize> {\n        if !self.config.enable_warmup || self.config.warmup_query.is_empty() {\n            return Ok(0);\n        }\n\n        let rows = self.database.query(&self.config.warmup_query).await?;\n        let mut count = 0;\n\n        for row in rows {\n            let key: String = row.get("id");\n            let data: Vec<u8> = row.get("data");\n            let cache_key = format!("{}{}", self.config.key_prefix, key);\n\n            self.cache\n                .set_ex(&cache_key, &data, self.config.ttl_seconds as usize)\n                .await?;\n            count += 1;\n        }\n\n        Ok(count)\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"write-through-cache-pattern",children:"Write-Through Cache Pattern"}),"\n",(0,i.jsx)(n.h3,{id:"overview-1",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Write-through"})," ensures cache consistency by writing to both cache and database synchronously:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Read"}),": Check cache; if miss, fetch from DB, store in cache"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Write"}),": Update cache AND database atomically"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Cache is always consistent with DB"}),"\n",(0,i.jsx)(n.li,{children:"No stale reads"}),"\n",(0,i.jsx)(n.li,{children:"Simpler consistency model"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Write latency (cache + DB)"}),"\n",(0,i.jsx)(n.li,{children:"Write failures affect both cache and DB"}),"\n",(0,i.jsx)(n.li,{children:"More complex error handling"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"architecture-diagram-1",children:"Architecture Diagram"}),"\n",(0,i.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Client\n    participant Proxy as Prism Proxy<br/>(Write-Through)\n    participant Cache as Redis Cache\n    participant DB as PostgreSQL<br/>(Source of Truth)\n\n    Note over Client,DB: Read Path (Cache Hit)\n    Client->>Proxy: GET /config/feature-flags\n    Proxy->>Cache: GET config:feature-flags\n    Cache--\x3e>Proxy: Data (hit)\n    Proxy--\x3e>Client: Response (1ms)\n\n    Note over Client,DB: Read Path (Cache Miss)\n    Client->>Proxy: GET /config/new-flag\n    Proxy->>Cache: GET config:new-flag\n    Cache--\x3e>Proxy: nil (miss)\n    Proxy->>DB: SELECT * FROM config WHERE key='new-flag'\n    DB--\x3e>Proxy: Config data\n    Proxy->>Cache: SET config:new-flag data\n    Proxy--\x3e>Client: Response (20ms)\n\n    Note over Client,DB: Write Path (Atomic)\n    Client->>Proxy: PUT /config/feature-flags {value: true}\n    Proxy->>Proxy: Begin Transaction\n    Proxy->>DB: UPDATE config SET value=...\n    DB--\x3e>Proxy: OK\n    Proxy->>Cache: SET config:feature-flags {value: true}\n    Cache--\x3e>Proxy: OK\n    Proxy->>Proxy: Commit Transaction\n    Proxy--\x3e>Client: Updated (18ms)\n\n    Note over Client,DB: Write Path (DB Failure)\n    Client->>Proxy: PUT /config/bad-key {value: \"invalid\"}\n    Proxy->>Proxy: Begin Transaction\n    Proxy->>DB: UPDATE config SET value=...\n    DB--\x3e>Proxy: Error: Constraint violation\n    Proxy->>Proxy: Rollback (do NOT update cache)\n    Proxy--\x3e>Client: Error 400 (10ms)"}),"\n",(0,i.jsx)(n.h3,{id:"protobuf-configuration-1",children:"Protobuf Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:"message WriteThroughCacheConfig {\n  // Cache backend\n  string cache_backend = 1;\n\n  // Cache key prefix\n  string key_prefix = 2;\n\n  // TTL (optional; can be infinite for permanent config)\n  optional int64 ttl_seconds = 3;\n\n  // Write ordering\n  enum WriteOrder {\n    CACHE_THEN_DB = 0;  // Write cache first (faster, risk of inconsistency)\n    DB_THEN_CACHE = 1;  // Write DB first (slower, safer)\n  }\n  WriteOrder write_order = 4 [default = DB_THEN_CACHE];\n\n  // Rollback on failure\n  bool enable_rollback = 5 [default = true];\n\n  // Async write to cache (improves write latency)\n  bool async_cache_write = 6 [default = false];\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"namespace-configuration-example-1",children:"Namespace Configuration Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'namespaces:\n  - name: application-config\n    backend: postgres\n    pattern: keyvalue\n    cache:\n      strategy: write_through\n      cache_backend: redis\n      key_prefix: "config:"\n      ttl_seconds: null  # Infinite TTL (configuration data)\n      write_order: DB_THEN_CACHE\n      enable_rollback: true\n\n  - name: user-settings\n    backend: postgres\n    pattern: keyvalue\n    cache:\n      strategy: write_through\n      cache_backend: redis\n      key_prefix: "settings:"\n      ttl_seconds: 86400  # 24 hours\n      write_order: DB_THEN_CACHE\n      async_cache_write: false  # Synchronous for consistency\n'})}),"\n",(0,i.jsx)(n.h3,{id:"rust-implementation-1",children:"Rust Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'pub struct WriteThroughCache {\n    cache: RedisBackend,\n    database: PostgresBackend,\n    config: WriteThroughCacheConfig,\n}\n\nimpl WriteThroughCache {\n    pub async fn get(&self, key: &str) -> Result<Option<Bytes>> {\n        let cache_key = format!("{}{}", self.config.key_prefix, key);\n\n        // Check cache first\n        if let Some(data) = self.cache.get(&cache_key).await? {\n            metrics::increment_counter!("cache_hits");\n            return Ok(Some(data));\n        }\n\n        metrics::increment_counter!("cache_misses");\n\n        // Fetch from database\n        let data = self.database.get(key).await?;\n\n        // Populate cache\n        if let Some(ref data) = data {\n            let ttl = self.config.ttl_seconds.unwrap_or(0);\n            if ttl > 0 {\n                self.cache.set_ex(&cache_key, data, ttl as usize).await?;\n            } else {\n                self.cache.set(&cache_key, data).await?;\n            }\n        }\n\n        Ok(data)\n    }\n\n    pub async fn set(&self, key: &str, value: &[u8]) -> Result<()> {\n        let cache_key = format!("{}{}", self.config.key_prefix, key);\n\n        match self.config.write_order {\n            WriteOrder::DbThenCache => {\n                // Step 1: Write to database (source of truth)\n                if let Err(e) = self.database.set(key, value).await {\n                    // DB write failed; do NOT update cache\n                    return Err(e);\n                }\n\n                // Step 2: Write to cache (DB succeeded)\n                if self.config.async_cache_write {\n                    // Async update (improves write latency)\n                    let cache = self.cache.clone();\n                    let cache_key = cache_key.clone();\n                    let value = value.to_vec();\n                    tokio::spawn(async move {\n                        let _ = cache.set(&cache_key, &value).await;\n                    });\n                } else {\n                    // Sync update (ensures consistency)\n                    if let Err(e) = self.cache.set(&cache_key, value).await {\n                        // Cache write failed; log but don\'t fail request\n                        // (DB is source of truth)\n                        warn!("Cache update failed: {}", e);\n                    }\n                }\n\n                Ok(())\n            }\n\n            WriteOrder::CacheThenDb => {\n                // Step 1: Write to cache (fast path)\n                self.cache.set(&cache_key, value).await?;\n\n                // Step 2: Write to database\n                if let Err(e) = self.database.set(key, value).await {\n                    // DB write failed; rollback cache if enabled\n                    if self.config.enable_rollback {\n                        let _ = self.cache.del(&cache_key).await;\n                    }\n                    return Err(e);\n                }\n\n                Ok(())\n            }\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"use-case-table-reader-with-look-aside-cache",children:"Use Case: Table Reader with Look-Aside Cache"}),"\n",(0,i.jsx)(n.h3,{id:"scenario",children:"Scenario"}),"\n",(0,i.jsxs)(n.p,{children:["Frequently accessed reference table (e.g., ",(0,i.jsx)(n.code,{children:"countries"}),", ",(0,i.jsx)(n.code,{children:"categories"}),", ",(0,i.jsx)(n.code,{children:"product_catalog"}),") that rarely changes."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Low read latency (< 5ms P99)"}),"\n",(0,i.jsx)(n.li,{children:"Tolerate stale reads up to 1 hour"}),"\n",(0,i.jsx)(n.li,{children:"Handle 10,000 RPS peak load"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'namespaces:\n  - name: product-catalog\n    backend: postgres\n    pattern: keyvalue\n    cache:\n      strategy: look_aside\n      cache_backend: redis\n      key_prefix: "catalog:"\n      ttl_seconds: 3600  # 1 hour\n      invalidation: NO_INVALIDATION  # Read-only data\n      enable_warmup: true\n      warmup_query: |\n        SELECT id::text,\n               row_to_json(products)::text as data\n        FROM products\n        WHERE active = true\n'})}),"\n",(0,i.jsx)(n.h3,{id:"client-usage",children:"Client Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from prism_sdk import PrismClient\n\nclient = PrismClient(namespace="product-catalog")\n\n# Read (cache hit: ~2ms, cache miss: ~25ms)\nproduct = client.get("product:12345")\n\n# Warmup cache (run on deployment)\nclient.warmup()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"performance",children:"Performance"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Metric"}),(0,i.jsx)(n.th,{children:"Look-Aside Cache"}),(0,i.jsx)(n.th,{children:"Direct DB Query"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"P50 Latency"})}),(0,i.jsx)(n.td,{children:"1.5ms"}),(0,i.jsx)(n.td,{children:"15ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"P99 Latency"})}),(0,i.jsx)(n.td,{children:"3.2ms"}),(0,i.jsx)(n.td,{children:"35ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Cache Hit Rate"})}),(0,i.jsx)(n.td,{children:"95%"}),(0,i.jsx)(n.td,{children:"N/A"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"DB Load"})}),(0,i.jsx)(n.td,{children:"500 QPS"}),(0,i.jsx)(n.td,{children:"10,000 QPS"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"use-case-object-storage-metadata-with-write-through-cache",children:"Use Case: Object Storage Metadata with Write-Through Cache"}),"\n",(0,i.jsx)(n.h3,{id:"scenario-1",children:"Scenario"}),"\n",(0,i.jsx)(n.p,{children:"Object metadata (size, content-type, ETag, last-modified) accessed on every file operation but infrequently updated."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Metadata always consistent with object storage"}),"\n",(0,i.jsx)(n.li,{children:"Low read latency (< 3ms P99)"}),"\n",(0,i.jsx)(n.li,{children:"Handle 5,000 metadata queries/sec"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"configuration-1",children:"Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'namespaces:\n  - name: object-metadata\n    backend: postgres  # Metadata in PostgreSQL\n    pattern: keyvalue\n    cache:\n      strategy: write_through\n      cache_backend: redis\n      key_prefix: "obj_meta:"\n      ttl_seconds: 86400  # 24 hours\n      write_order: DB_THEN_CACHE\n      enable_rollback: true\n'})}),"\n",(0,i.jsx)(n.h3,{id:"client-usage-1",children:"Client Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'client = PrismClient(namespace="object-metadata")\n\n# Write metadata (updates cache + DB atomically)\nclient.set("bucket/file.jpg", {\n    "size_bytes": 1024000,\n    "content_type": "image/jpeg",\n    "etag": "abc123",\n    "last_modified": 1696780800,\n})\n\n# Read metadata (from cache: ~1ms)\nmetadata = client.get("bucket/file.jpg")\nprint(f"File size: {metadata[\'size_bytes\']} bytes")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"monitoring-and-observability",children:"Monitoring and Observability"}),"\n",(0,i.jsx)(n.h3,{id:"cache-metrics",children:"Cache Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:'message CacheMetrics {\n  string namespace = 1;\n  string strategy = 2;  // "look_aside", "write_through"\n\n  // Hit/Miss rates\n  int64 cache_hits = 3;\n  int64 cache_misses = 4;\n  float hit_rate = 5;  // cache_hits / (cache_hits + cache_misses)\n\n  // Latency\n  float read_latency_p50_ms = 6;\n  float read_latency_p99_ms = 7;\n  float write_latency_p50_ms = 8;\n  float write_latency_p99_ms = 9;\n\n  // Cache operations\n  int64 cache_evictions = 10;\n  int64 cache_invalidations = 11;\n  int64 warmup_count = 12;\n\n  // Consistency\n  int64 write_failures = 13;\n  int64 rollback_count = 14;\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"prometheus-metrics",children:"Prometheus Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Cache hit rate\nprism_cache_hits_total{namespace="product-catalog", strategy="look_aside"}\nprism_cache_misses_total{namespace="product-catalog", strategy="look_aside"}\n\n# Latency histograms\nprism_cache_read_duration_seconds{namespace="product-catalog", quantile="0.5"}\nprism_cache_read_duration_seconds{namespace="product-catalog", quantile="0.99"}\n\n# Cache size\nprism_cache_items_total{namespace="product-catalog"}\nprism_cache_bytes_total{namespace="product-catalog"}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"grafana-dashboard-queries",children:"Grafana Dashboard Queries"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-promql",children:"# Cache hit rate\nrate(prism_cache_hits_total[5m]) /\n(rate(prism_cache_hits_total[5m]) + rate(prism_cache_misses_total[5m]))\n\n# P99 read latency\nhistogram_quantile(0.99, rate(prism_cache_read_duration_seconds_bucket[5m]))\n\n# Database load reduction\nrate(prism_database_queries_total[5m]) vs. rate(prism_cache_misses_total[5m])\n"})}),"\n",(0,i.jsx)(n.h2,{id:"cache-invalidation-strategies",children:"Cache Invalidation Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"invalidation-comparison",children:"Invalidation Comparison"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Strategy"}),(0,i.jsx)(n.th,{children:"Consistency"}),(0,i.jsx)(n.th,{children:"Latency"}),(0,i.jsx)(n.th,{children:"Use Case"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"TTL Expiration"})}),(0,i.jsx)(n.td,{children:"Eventual"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Read-only or rarely updated data"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"On-Write Invalidate"})}),(0,i.jsx)(n.td,{children:"Strong"}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"Frequent writes, require fresh"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Background Refresh"})}),(0,i.jsx)(n.td,{children:"Eventual"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Predictable updates (e.g., nightly)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Manual Invalidate"})}),(0,i.jsx)(n.td,{children:"Strong"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Admin-triggered cache clear"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"manual-invalidation-via-admin-cli",children:"Manual Invalidation via Admin CLI"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Invalidate specific cache entry\nprism cache invalidate product-catalog --key "product:12345"\n\n# Invalidate by prefix\nprism cache invalidate product-catalog --prefix "category:"\n\n# Flush entire namespace cache\nprism cache flush product-catalog\n\n# Trigger cache warmup\nprism cache warmup product-catalog\n'})}),"\n",(0,i.jsx)(n.h2,{id:"migration-path",children:"Migration Path"}),"\n",(0,i.jsx)(n.h3,{id:"phase-1-look-aside-implementation-week-1-2",children:"Phase 1: Look-Aside Implementation (Week 1-2)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Redis Integration"}),": Implement cache backend (ADR-010)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LookAsideCache"}),": Rust implementation with thundering herd prevention"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Namespace Config"}),": Add cache configuration to namespace schema"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Metrics"}),": Cache hit rate, latency, evictions"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Deliverable"}),": Look-aside cache for KeyValue pattern"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-2-write-through-implementation-week-3-4",children:"Phase 2: Write-Through Implementation (Week 3-4)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"WriteThroughCache"}),": Rust implementation with rollback"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration"}),": Add write_order, rollback options"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integration Tests"}),": Consistency validation tests"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Documentation"}),": Cache strategy selection guide"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Deliverable"}),": Write-through cache with consistency guarantees"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-3-advanced-features-week-5-6",children:"Phase 3: Advanced Features (Week 5-6)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cache Warmup"}),": Background warmup on startup"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Background Refresh"}),": Async cache refresh for long-lived data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Admin CLI"}),": Cache management commands"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitoring"}),": Grafana dashboards for cache observability"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Deliverable"}),": Production-ready caching with operational tools"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-4-additional-patterns-future",children:"Phase 4: Additional Patterns (Future)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Write-Back Cache"}),": For write-heavy workloads"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Refresh-Ahead"}),": Predictive cache refresh"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multi-Level Cache"}),": Local + distributed cache tiers"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cache Replication"}),": Geo-distributed cache"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cache Poisoning"}),": Validate data before caching"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PII in Cache"}),": Apply encryption for sensitive data (see ADR-031)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cache Isolation"}),": Namespace-level cache isolation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TTL Enforcement"}),": Prevent unbounded cache growth"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Access Control"}),": Cache operations require namespace permissions"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"performance-targets",children:"Performance Targets"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Pattern"}),(0,i.jsx)(n.th,{children:"Operation"}),(0,i.jsx)(n.th,{children:"P50 Latency"}),(0,i.jsx)(n.th,{children:"P99 Latency"}),(0,i.jsx)(n.th,{children:"Throughput"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Look-Aside"})}),(0,i.jsx)(n.td,{children:"Read (hit)"}),(0,i.jsx)(n.td,{children:"< 2ms"}),(0,i.jsx)(n.td,{children:"< 5ms"}),(0,i.jsx)(n.td,{children:"50k RPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Look-Aside"})}),(0,i.jsx)(n.td,{children:"Read (miss)"}),(0,i.jsx)(n.td,{children:"< 20ms"}),(0,i.jsx)(n.td,{children:"< 50ms"}),(0,i.jsx)(n.td,{children:"5k RPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Look-Aside"})}),(0,i.jsx)(n.td,{children:"Write"}),(0,i.jsx)(n.td,{children:"< 15ms"}),(0,i.jsx)(n.td,{children:"< 40ms"}),(0,i.jsx)(n.td,{children:"2k RPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Write-Through"})}),(0,i.jsx)(n.td,{children:"Read (hit)"}),(0,i.jsx)(n.td,{children:"< 2ms"}),(0,i.jsx)(n.td,{children:"< 5ms"}),(0,i.jsx)(n.td,{children:"50k RPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Write-Through"})}),(0,i.jsx)(n.td,{children:"Write"}),(0,i.jsx)(n.td,{children:"< 25ms"}),(0,i.jsx)(n.td,{children:"< 60ms"}),(0,i.jsx)(n.td,{children:"1k RPS"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"related-rfcs-and-adrs",children:"Related RFCs and ADRs"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"RFC-004: Redis Integration (cache backend)"}),"\n",(0,i.jsx)(n.li,{children:"RFC-005: ClickHouse Integration (aggregated cache)"}),"\n",(0,i.jsx)(n.li,{children:"ADR-031: TTL Defaults (cache expiration)"}),"\n",(0,i.jsx)(n.li,{children:"ADR-032: Object Storage Pattern (metadata caching)"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://aws.amazon.com/caching/best-practices/",children:"Caching Strategies and Patterns"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://redis.io/docs/manual/patterns/cache/",children:"Redis as a Cache"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.usenix.org/conference/atc13/technical-sessions/presentation/bronson",children:"Facebook TAO: Cache-Aside at Scale"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Cache_(computing)#Writing_policies",children:"Write-Through vs Write-Back"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"appendix-cache-strategy-decision-tree",children:"Appendix: Cache Strategy Decision Tree"}),"\n",(0,i.jsx)(n.p,{children:"What's your access pattern?\n\u251c\u2500 Read-heavy (90%+ reads)\n\u2502  \u251c\u2500 Can tolerate stale reads? \u2192 Look-Aside\n\u2502  \u2514\u2500 Need fresh reads? \u2192 Write-Through\n\u2514\u2500 Write-heavy (50%+ writes)\n\u251c\u2500 Can tolerate data loss? \u2192 Write-Back\n\u2514\u2500 Need durability? \u2192 Write-Through"}),"\n",(0,i.jsx)(n.p,{children:"What's your consistency requirement?\n\u251c\u2500 Eventual consistency OK \u2192 Look-Aside + TTL\n\u251c\u2500 Strong consistency \u2192 Write-Through\n\u2514\u2500 Real-time consistency \u2192 Write-Through + short TTL"}),"\n",(0,i.jsx)(n.p,{children:"What's your data update frequency?\n\u251c\u2500 Rarely (hourly+) \u2192 Look-Aside + long TTL + warmup\n\u251c\u2500 Occasionally (minutes) \u2192 Look-Aside + short TTL\n\u2514\u2500 Frequently (seconds) \u2192 Write-Through"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\n---\n\n**Status**: Draft\n**Next Steps**:\n1. Implement LookAsideCache in Rust proxy\n2. Add cache configuration to namespace schema\n3. Implement WriteThroughCache with rollback\n4. Add cache metrics to monitoring\n5. Document cache strategy best practices\n\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(o,{...e})}):o(e)}}}]);